{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Order of Operation\n",
    "1. import\n",
    "2. read in training data \n",
    "3. clean data \n",
    "4. stem words with snowball stemmer\n",
    "5. pipeline tfidf vectorizer, [selected classifier]\n",
    "6. choose best pipeline\n",
    "7. gridsearchcv on pipeline to find best tuned classifier\n",
    "8. test on other data i.e. Kaggle, friends, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project, I try to optimize a supervised machine learning algorithm to predict Myers-Briggs personality profiles of Kaggle forum users based on the [(MBTI) Myers-Briggs Personality Type Dataset](https://www.kaggle.com/datasnaek/mbti-type) on Kaggle. \n",
    "\n",
    "This notebook was forked from [this](https://www.kaggle.com/lbronchal/what-s-the-personality-of-kaggle-users) Kaggle kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../mbti-project/mbti_1.csv')\n",
    "user_data = pd.read_csv('../mbti-project/Users.csv')\n",
    "forum_data = pd.read_csv('../mbti-project/ForumMessages.csv')\n",
    "mbti = {'I':'Introversion', 'E':'Extroversion', 'N':'Intuition', \n",
    "        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling', \n",
    "        'J':'Judging', 'P': 'Perceiving'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of personality profile types in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAENCAYAAABO7NDIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2986d97b2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_count = train_data['type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(type_count.index, type_count.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Types', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The personality types seems to be heavily skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there are missing values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forum Missing Values:\n",
      "Id                           0\n",
      "ForumTopicId                 0\n",
      "AuthorUserId                 0\n",
      "PostDate                     0\n",
      "Message                    581\n",
      "ReplyToForumMessageId    70620\n",
      "TopicMessagePosition         0\n",
      "RawMarkdown              60694\n",
      "Score                        0\n",
      "FlaggedCount                 0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "User Missing Values:\n",
      "Id                     0\n",
      "UserName          267200\n",
      "DisplayName           21\n",
      "RegisterDate           0\n",
      "Points            510138\n",
      "Ranking           510138\n",
      "Tier                   0\n",
      "HighestRanking    510132\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Training Missing Values:\n",
      "type     0\n",
      "posts    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Forum Missing Values:')\n",
    "print(forum_data.isnull().sum())\n",
    "print('\\n')\n",
    "print('User Missing Values:')\n",
    "print(user_data.isnull().sum())\n",
    "print('\\n')\n",
    "print('Training Missing Values:')\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values for `forum_data['Message']` with blank space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forum Missing Values:\n",
      "Id                           0\n",
      "ForumTopicId                 0\n",
      "AuthorUserId                 0\n",
      "PostDate                     0\n",
      "Message                      0\n",
      "ReplyToForumMessageId    70620\n",
      "TopicMessagePosition         0\n",
      "RawMarkdown              60694\n",
      "Score                        0\n",
      "FlaggedCount                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "forum_data['Message'] = forum_data['Message'].fillna('')\n",
    "\n",
    "print('Forum Missing Values:')\n",
    "print(forum_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258      1459\n",
      "993       1353\n",
      "2242      1191\n",
      "59561     1011\n",
      "5309       913\n",
      "114978     699\n",
      "1828       679\n",
      "100236     604\n",
      "6696       510\n",
      "24266      499\n",
      "317687     488\n",
      "75837      451\n",
      "2505       436\n",
      "140793     390\n",
      "368        377\n",
      "23831      376\n",
      "3716       375\n",
      "263583     362\n",
      "111776     341\n",
      "147404     323\n",
      "1335       320\n",
      "4398       315\n",
      "37404      310\n",
      "111640     284\n",
      "102203     264\n",
      "381        263\n",
      "2194       253\n",
      "10035      239\n",
      "2036       239\n",
      "131576     237\n",
      "          ... \n",
      "138735       1\n",
      "2839         1\n",
      "201524       1\n",
      "217916       1\n",
      "111072       1\n",
      "405968       1\n",
      "80305        1\n",
      "391593       1\n",
      "231655       1\n",
      "116975       1\n",
      "80113        1\n",
      "170245       1\n",
      "49422        1\n",
      "55030        1\n",
      "10515        1\n",
      "31001        1\n",
      "233764       1\n",
      "366885       1\n",
      "397037       1\n",
      "217404       1\n",
      "145130       1\n",
      "158043       1\n",
      "637281       1\n",
      "51599        1\n",
      "405904       1\n",
      "358082       1\n",
      "155303       1\n",
      "131478       1\n",
      "389544       1\n",
      "14329        1\n",
      "Name: AuthorUserId, Length: 13340, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(forum_data['AuthorUserId'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a given user might have posted more than once on Kaggle forums, I will group all `'Message'` together for each unique user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg = forum_data.groupby('AuthorUserId')['Message'].agg(lambda col: ' '.join(col)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71677     1\n",
      "151016    1\n",
      "494738    1\n",
      "2708      1\n",
      "126473    1\n",
      "121486    1\n",
      "19084     1\n",
      "27272     1\n",
      "605816    1\n",
      "33413     1\n",
      "43648     1\n",
      "643711    1\n",
      "518776    1\n",
      "137846    1\n",
      "45683     1\n",
      "47730     1\n",
      "43632     1\n",
      "348783    1\n",
      "62059     1\n",
      "326250    1\n",
      "21284     1\n",
      "27240     1\n",
      "397927    1\n",
      "203366    1\n",
      "33381     1\n",
      "23198     1\n",
      "144035    1\n",
      "129706    1\n",
      "105158    1\n",
      "552523    1\n",
      "         ..\n",
      "406442    1\n",
      "277709    1\n",
      "13516     1\n",
      "595094    1\n",
      "449793    1\n",
      "617783    1\n",
      "58666     1\n",
      "320822    1\n",
      "294197    1\n",
      "301551    1\n",
      "118067    1\n",
      "77103     1\n",
      "146733    1\n",
      "13612     1\n",
      "38022     1\n",
      "345378    1\n",
      "87328     1\n",
      "7108      1\n",
      "629725    1\n",
      "40435     1\n",
      "202008    1\n",
      "58646     1\n",
      "51550     1\n",
      "96258     1\n",
      "285969    1\n",
      "61922     1\n",
      "9486      1\n",
      "460042    1\n",
      "138505    1\n",
      "327680    1\n",
      "Name: AuthorUserId, Length: 13340, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['AuthorUserId'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean `train_data['posts']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to clean data\n",
    "def clean_text(text):\n",
    "    #get rid of html and seperators\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r'  ', text) \n",
    "    text = re.sub(r'http\\S+', r'  ', text)\n",
    "    #get rid of punctuation\n",
    "    text = text.replace('.', '  ')\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    #get rid of numbers\n",
    "    text = ''.join(i for i in text if not i.isdigit())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['clean_posts'] = train_data['posts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg['clean_messages'] = forum_data_agg['Message'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The public leaderboard is only indicative because competitors can use information on their score to get information on a portion of the test dataset   The final results are a quite different and b better reflect actual performance   Hi Tanya Kaggle will maintain a rating system   If you win but youre ineligible for prize money you will still get a strong rating  Anthony GiovanniThanks for your feedback   Using the forum to give feedback is a good idea   It allows others to see and comment on suggestions   We might set up a proper feedback forum but for the moment this topic will have to suffice   I also agree that the forum is a bit clunky   However we have a large list of feature requests and only limited resources for the moment  it might take us some time to address this   Apologies   I dont think the prize money in this competition is that relevant the prize is relatively small   Correct me if Im wrong but I think contestants are driven by intrinsic factors  A karma system that rewards forum posts is a good idea   Again apologies for any delay in implementing this there are lots of features on our to do list  Anthony Manish thanks for the feedback   The site is hosted on an Amazon EC server on the east coast of America  Its a fast server but the site has been more popular than we expected  Were currently working on speeding up the site by reducing the number database queries   We may have to implement auto scaling if the site keeps growing so rapidly   Anthony Just made a change which should speed things up   Let me know if it has made a difference for you   Jonathan thanks for your feedback x   Were currently working on caching database queries   There are a lot of good suggestions here that well try before autoscaling    Colin the choice of scoring system was quite deliberate   Will the competition host considered using Area Under the ROC Curve where participants submit probabilities but  said that he deals with physicians who just want to know the proportion of predictions that are correct  Rajstennaj and Colin were really pleased that you believe that theres value to the project   Let me know if there is anyway that we can help to facilitate a community   We did set up the general Kaggle forum under CommunityForum\r\n",
      "  with such a community in mind  does it provide sufficient infrastructure You are free to start any new threads on that forum  RegardsAnthony Thanks for participating in this competition   Ive attached the solution file to this post  \n",
      "UPDATE The solution is no longer attached but youre welcome to make submissions to this competition   Hi MattI believe that Will the competition host is preparing a blog post that discusses some of the methods that people applied to this competition  based on the feedback we received   Is this the sort of thing you had in mindAnthony Here are some papers that analyze Eurovision voting patterns   You might find some of them helpful   Gatherer Comparison of Eurovision Song Contest Simulation with Actual Results Reveals Shifting Patterns of Collusive Voting Alliances      Eurovision Song Contest Is Voting Political or Cultural Ginburgh and Noury    Suleman Efstathiou and Johnson    Eurovision Song Contest as a ‘Friendship’ Network\r\n",
      "Dekker   \n",
      " More research       enjoyLove thy Neighbor Love thy Kin Voting Biases in the Eurovision Song Contest   culture and religion Explaining the bias in Eurovision song contest voting   Hybrid System Approach to Determine the Ranking of a Debutant Country in Eurovision   Eurovision   Judgment Versus Public Opinion – Evidence from the Eurovision Song Contest   Here is the solution file for anybody interested    I accidentally deleted the following post made by another user   Im reposting it on their behalfAre there categorical andor binary variables in the data set Other than the target variable For instance VariableOpen in test data seems to have categories          If there are categorical variables do we get to know what the categories meanThank You Just to clarify  the results page will show the leaderboard for all competitors regardless of whether they used future information or not   We will make an honourable mention to the leading competitor who doesnt use future information however their entry will be audited   Kaggle is currently developing a league table that ranks competitors   When it comes to this competition your position on the leaderboard which is indifferent to the use of future information will be what counts towards your Kaggle ranking    INFORMS can offer an awardhonourable mention to those who dont use future data   However the Kaggle leaderboard will not seperate those who use future information from those who dont   Given the way the competition has been setup theres no way to prevent people from using future data   Even if the winner presents a model that doesnt include future data they may have overfitted to replicate the predictions of a model that does include future data   In theory yes   The problem is that theres no way to be certain that the winner didnt use future information   Even when we check the winning model its possible they have used a model with future information to probe the test dataset   Sali Mali has pointed out that there is an error in the AUC\r\n",
      "calculation for entries with tied scores that is when two or more scores have\r\n",
      "precisely the same value   We will look at the problem over the next  hours and will rescore all entries   ApologiesAnthony The AUC calculation glitch has been fixed and all entries have been rescored   Sali Mali thanks again for pointing this out   Hi PG   Not sure that I fully understand the question   Are you referring to the situation where a classifier returns only  or  rather than a score or probability Perhaps you can use an example to illustrate the question Regards Anthony Hi PG   You should give the score for all timestamps  a higher score means the instance is more likely to be a member of the positive    AUC measures your classifiers ability to split the classes  so you dont need to decide which scores predict positive instances  and which predict negative instances    Have I addressed your concern Vateesh thanks for sending the files   The files that you sent are actually different   I also had a look at your submissions and you have a few files with the same name but different numbers   Also I was not able to replicate the problem as you describe it   Perhaps you can try again and let me know if youre still experiencing the error Hi Vess   This should not be a problem given the way submissions are stored   Seyhan the leaderboard portion of the test dataset is selected randomly   It is somewhat representative of the overall standings   Cole sorry for the slow response   In this competition all your submissions count   In future we will ask participants to nominate  submissions   Phil that is correct   You must remember that Kaggle hopes to do more than just host fun competitions we want to help solve real problems   This is why were reluctant to force participants to choose just one model they may make a poor choice and the compettion host may end up with a suboptimal model   Our compromise position is to allow partipants to nominate five entries a feature which well roll out for future competitions    Phil number  is correct   Luck will play a part but I suspect the test dataset is large enough to limit its impact    I agree in a competition like this one   But as mentioned above we want to host competitions that are useful as well as fun   An upcoming competition will require participants to predict who has prostate cancer based on  variables   In a competition like that it would be a shame to miss out on the best model   Requiring participants to nominate five submissions seems like a good compromise    Hi ColeApologies for the ambiguity   The time is as it appears on the competition summary page   adjusts according to the timezone on your computer clock so itll be Saturday or Sunday depending on your timezone  You can also see a countdown on the Kaggle home page  Anthony  Durai apologies for the slow response   All up  countries were represented   Here is the list in order of most participants to fewest United States United Kingdom Australia Canada Thailand India Germany Spain China Netherlands France Italy New Zealand South Africa Sweden Argentina Croatia Ecuador Greece Indonesia Iran Ireland Mexico Poland Portugal Russia Singapore Turkey and Ukraine Ricardo you are correct  I gave the country list for the wrong competition    countries were represented United States Colombia India Australia United Kingdom France Thailand Canada Germany Argentina Japan Afghanistan Albania Austria Belgium Chile China Croatia Ecuador Finland Greece Hong Kong Iran Poland Portugal Slovak Republic Venezuela Sorry for the slow response  Ive been flat out with the new site launch   Below is the list of rows used to calculate the public leaderboard Phil I made an error in the ten per cent listed above try scoring with the following rows YuchunApologies for this error   The public leaderboard is portion of the test dataset is actually the first  per cent because we hadnt implemented the code to select a random portion of the leaderboard yet   For info the reason we kept getting different  per cents is because the random seed in the database was set to zero which told our code to choose a random random seed  Anthony Please use this topic to give us feedback   If youd rather do so in private email me at anthony  goldbloomkaggle  com   Thanks for the feedback   \r\n",
      "\r\n",
      " What sort of features do you have in mind Or can you point to a forum that you we should emulate I just added a quick reply box to make the forum less clunky  \r\n",
      "\r\n",
      " Great suggestion   I have put this on our extensive features to add list   Hi MattThanks for the nice words and the suggestion   Ive posted the solution file   Good suggestion   Were open to ideas on how we can facilitate this   My thinking is the best thing to do is to implement a more functional forum which were doing   We can then encourage those who are still working on the problem to continue to use the competition forum as a way to collaborate   Use this topic to discuss any competitions you would like us to run   If you would rather contact me privately email anthony  goldbloomkaggle  com      out of   thats pretty impressive Pity they didnt enter the Kaggle comp   I think youre right  some competitions exhibit more regularities than others   Soccer may be a difficult sport to model   David this is a great suggestion   The HIV competition shows that Kagglers can do great things    My initial concern with any public dataset is that people can look up the answers   We would need researchers to withhold a small portion of the dataset for evaluation   I think the first step is to get in touch with those who set up the Alzheimers project   It also makes sense to contact the Michael J Fox foundation   If anybody has any connection to either of these projects please let me know  Otherwise Ill keep you posted on any progress  Anthony Hi DavidI have written to the Alzheimers Disease Neuroimaging Initiative ADNI and the Michael J Fox Foundation   I am scheduling meetings with both for September   Will keep you posted on any progress   Can you put up a link to the datapaper you foundThanks again for the suggestion   Its great if we can use the power of this platform to tackle meaningful problems   RegardsAnthony Thanks for the nice wishes   Of course Kaggle wouldnt exist without a brilliant community of data scientists who can solve really challenging problems   Looking forward to seeing what we can do in  This is the photo from the Kaggle office   This lunch was one of the highlights of my six years of Kaggle   Not something I will forget in a hurry    Hi DirkThe Elo Benchmark is based on the training dataset only   Having had many email conversations with Jeff I can tell you that the seed ratings matter a lot   Youll notice that Jeff made two submissions for the Elo benchmark  thats because hes refining his seeding method   I believe he plans to make a few more refinements  Jeff uses an iterative process to seed the rating system   For example he might start by giving everybody  and then letting Elo run for  months   He then seeds Elo with the  month ratings and runs Elo again   He does several iterations of this  Does this helpAnthony  Has anybody tried Trueskill yet   probably a better starting point than Elo   This blog post does a nice job of stepping through Trueskill   Hi JohnHave just confirmed with Jeff methodologies will be shared publicly   RegardsAnthony The competition has been designed to make cheating really difficult   At the end of the competition the winners methodologies will be replicated to help ensure everything is above board   Hi MattThe reason we prevent participants from submitting an unlimited number of times is because otherwisea our servers may not be able to handle all the traffic anda it would be easier to decode the portion of the test dataset thats used to calculate the public leaderboard   The technique you describe often referred to as cross validation is very sensible and we encourage others to use it   Anthony Uri you raise an interesting point   However is five months long enough for somebodys rating to move enough for you to notice this JPL a competition using internet chess data is a good suggestion   For interest the reason we are running the competition using top players is because Elo ratings matter most for top players since it is used to determine who can play in which tournaments   Jase the score on the full dataset is calculated onthefly  so we actually know who is winning based on the full test dataset  Ron the submission that is performing best on the public leaderboard may be different from the submission that is performing best on the full test dataset   We dont link the best submission on the public leaderboard to the best overall submission so that participants dont become confusedconcerned if their scoreposition on the public leaderboard worsens  Leigh my thinking as well   In a tradeoff between having a veracious public leaderboard and a veracious end result  the end result is most important  Jeff good suggestion    Ive put together an Excel sheet that might be helpful for cross validation   You paste your predictions for months  into column G and it aggregates by player by month and then calculates the RMSE   Hope its helpful  Anthony BenThe evaluation method was chosen because Jeff has found that scoring based individual games with RMSE unduly favours systems that predict a draw   Mark Glickman raised another issue  RMSE is better suited to normally distributed rather than binary  outcomes   So in order to use RMSE aggregation is preferable   Of course we could have evaluated on a game by game basis using a different metric  My biggest problem with the current evaluation method is that counting a draw as half a win seems a little arbitrary   However in order to benchmark Elo such an assumption is necessary   Mark and Jeff argue that a draw is generally worth half a win  so this assumption isnt too problematic   Anyway hope this gives you some insight into our thinking   RegardsAnthony Jeff please correct me if Im mistaken but I believe systems that predict draws are favoured because a high proportion of games are draws at the top level  per cent in the training dataset   Of course you can do better  but a system that predicts    for every game will perform better than it should   Matt am interested in your thinking on this   Why MAE over MSE or RMSE Is it just that the metric is more intuitive or something subtler Out of interest has anybody entered this competition using Glicko Glicko or Chessmetrics Are either of you happy to send me your unmodified Glicko submission It would be good to add a Glicko Benchmark team to the leaderboard   My email address is anthony  goldbloomkaggle  com  Would like to do the same for Glicko and Chessmetrics if anybody has tried those   I have also contacted Ron about using his Trueskill submission as a Trueskill Benchmark   Jase I posted a link to your Glicko code on the hints page   Its very good of you to share it   Im really surprised that Glicko is performing worse than the Elo benchmark   Do you think this is because Jeff put lots of work into optimally seeding the Elo benchmark Or is Glicko just not as good Was just chatting to Jeff   Time permitting he is going to benchmark some of these other systems   This way they will all be benchmarked on a consistent basis using the same seeding procedure and the same degree of tuning    Uri the correlation between the public leaderboard score and overall score is significantly higher now   Uri Im reluctant to release confidence interval information because I want to minimize the advantage to early submitters   Early submitters already have the small advantage of having seen their submissions on two different public leaderboards   By releasing confidence interval information Im giving early submitters access to information that isnt available to later entrants   Jase aside from changing the size of the public leaderboard portion of the test dataset we also selected it more sensibly  so it better represents the overall test dataset    Hi Edward   You will appear on the leaderboard as soon as you make your first submission   Hi Edward   Try using examplesubmission  csv available at    and replacing the score column with your predicted scores   If youre still having trouble email the file to me anthony  goldbloomkaggle  com and Ill have a look   Uri thanks for pointing out the problem   Were currently working on a big upgrade to the website the new site should be launched by the end of this month   The upgrade will involve a more functional forum   In the meantime I will try and fix this problem   Anthony Uri Im not able to replicate the error either on the live site or on the development version   Can you let me know if you experience it again Hi Hans which post Still cant replicate the bug       intermittent problems are really annoying As mentioned were doing a massive site upgrade at the moment  so thats taking up the majority of our development time   How serious is the problem Can we live with it for the next few weeks until we deploy Kaggle    I would really like to be more active in the forums  looks like theres some lively discussion happening Ive been flat out working on the site upgrade which is only a few weeks away from launch  Anyway Id like to share a few thoughts on this discussion  First off there is quite a strong correlation between the public leaderboard and the overall standings   Secondly the lack of relationship between the  scores and the  scores might indicate overfitting   This may be the case if youre experiencing a larger improvement on the  dataset than the  dataset    On a related point I notice that youre all performing very well   It could be that youve reached a local maximum i  e   the best possible score given the techniques youre using    Eric thanks for the feedback   Theres not really any reason to insist on a particular file extension   Were currently doing a big site upgrade so Ill add this to our list of feature requests   Just to reemphasis Jeffs point you should pay more attention to your cross validation than to the leaderboard   The leaderboard is calculated on a very small amount of data so it is only indicative   PhillippSorry for the delay in doing this I havent had computer access over the last few days   The Spearman correlation between public scores and overall scores is     I also calculated the correlation for different submission quintiles to make sure the relationship holds at the top it doesTop                   Its also worth mentioning that the trouble participants are having  reflects realworld difficulties in formulating a chess rating system   This competition is not just a game but a genuine attempt to explore new approaches to rating chess players  Anthony Out of interest why arent people rerunning old approaches that had previously been scored on the new cross validation dataset Wil if you can get historical data from freechess  org possibly by agreeing to share the winning method with them wed be happy to host a comp here   This way you could specify that the winning method must be an instant gratification system   It would also result in a system thats tuned to lower ranked players   Thanks for pointing out the error   It has now been fixed   Apologies for any confusion   Uri makes a very good point   One way we could run a competition without knowing future matchups is to have participants rate every  player   Once we know the matchups we can infer predictions based on players ratings  The only downsides to this approach are   It doesnt allow for probabilistic predictions since there are many ways to map ratings into probabilities     We couldnt show a live leaderboard  which helps to motivate participants   Interested in others thoughts on this particularly the importance of a live leaderboard    Philipp I dont fully understand your suggestion   Do you mind trying to explain it again Possibly by reference to an exampleAs a general principle tne problem with attempting to prevent people from using neural networks and the like is that participants use them anyway and then overfit other systems to replicate the neural networks results   I actually think that having neural networks et al in the competition is valuable   Even if they wont be implemented as rating systems they may have some benchmarking value   Assuming they predict most accurately they give a sense for what level of predictive accuracy is possible from any given dataset   As an aside if we require participants to submit ratings and dont \r\n",
      "give them access to the matchups that theyll be scored on this should\r\n",
      " force participants to create a rating system       shouldnt it\n",
      " BTW Jeff re   I have been and continue to be amazed by the level of participation so far    I had no idea so many people would participate   Congratulations on organising such a popular competition PEW what criteria would you use to evaluate such systemsBTW I think youd be surprised at the proportion of the top  who are building rating systems    Ron this is fantastic Looks like a sizable proportion of the black dots are sitting in a vertical line   Though Im sure the Elo Benchmark would look much worse      Out of interest what software did you use to generate the viz ps   Im guessing the anomalies that this viz highlights e  g   that white is a smaller advantage for lower rated players could inform future versions of your rating system   Philipp thanks for your nice words Hopefully having a more professional look and feel will help us attract interesting competitions with bigger prize pools    Philipp thanks for pointing out this bug   The error was only aesthetic  had been accidently hardcoded into the new theme   The platform was still only permitting two submissions   Anyway the error has been fixed    Unfortunately the movie isnt out in Australia yet weve still got another week to wait   Jason theres a bug that prevents users seeing previous scores when they have longish technique descriptions   We are aware of the problem and will fix it as soon as we can  Diogo thanks for pointing out this error   We will setup pagination on the submission page shortly    Diogo thanks for pointing out this bug   Few minor teething problems with the new site  we should have them sorted out before long    Hi allJust to let you know that we have extended the deadline for this competition by just over a week   Both Jeff and I will be travellng around mid November so wouldnt be able to deal with the competitions conclusion  Anhony Apologies I hadnt antipicated that this might be an unpopular move   I should have canvassed opinion first   If others also disapprove I will changed back the deadline Kaggle is not a dictatorship  The downside of changing back the deadline is that it limits our ability to generate publicity   This bothers me becausea   top performers deserve recognitionb   publicity for the competition is publicity for Kaggle and more publicity  more members  more competitions andc   it lessens the chances of getting FIDEs attention  A compromise might be to extend the previous deadline by three days to Wednesday November  when Jeff is offline but I am available   Thoughts Hi PhilippThe Chessbase articles were written by Jeff he has a relationship with the editor   Jeff being away when the competition finishes means that its unlikely that Chessbase will report on the end of the competition a real pity if we hope to grab FIDEs attention   It is unfortunate that were both away when the competition ends Obviously not foreseen when it launched otherwise we would have set a different deadline   Anthony Jeff we must have posted simultaneously   You raise a good point   If Philipp and others are OK with the th then we should go with the compromise date   This would mean that Ill be available to report preliminary results and should mean were ready to report the final results by the time you return   Preliminary will be unconfirmed results from the raw leaderboard   Final results after the top ten have all agreed to share their methodology   Ive changed the deadline to the th   As for Uri breathing down your neck remember that the public leaderboard is only indicative and that the final standings may be different    Apologies Uri and LT  seems that any reply is redundant now   Also big thanks to all those who participated in forum discussions   You helped make this a far more interesting competition    This first chart how the leading score has changed on a daybyday basis   The red line shows the Elo benchmark and the blue line shows the leading score   The Elo benchmark was outperformed within  hours which is why its always above the best entry   Interesting to see some recent progress after a period of stagnation well done Philipp   My guess is that any major improvement from this point on will be the result of somebody trying something quite different  This chart shows the number of daily entries   Higher early but seems to have stabilised at around  per day   Happy to put up other charts if people have requests    Philipp theres certainly a largish gap between the top five   Of course this is purely indicative   What really matters is the score difference on the final leaderboard        Philipp great suggesion Weve got a stack of features we want to implement but Ill put this in our long term wish list    I tried puting up a general forum for such discussions but found that it was very lightly used   Features in the pipeline include   fixing bugs or incomplete features on the new site   upgrades to Kaggle infrastructure to allow us to score very large entries   Kaggle ranking system  an Elo for Kagglers based on Microsoft Trueskill   extended social networking features including live chat recent activity feeds          Philipps  competition analytics suggetion and possibly some other data viz toolsCompetitions in the pipeline include predicting social network connections predicting the likely success of grant applications for a large Australian University forecasting travel times for freeways in Melbourne Australia predicting prostate cancer from a high dimensional dataset subject to ethics approval diagnosing breast cancer from mammographics density images also subject to ethics approvalAny other suggestions Any thoughts on what our priorities ought to be JasonLT are you thinking along the lines of karma points for participating in forum discussions Or would you like the forums to be more of a QA with Stackoverflow style ratingsI like the idea of guest blog posts and community tutorials   After the chess competition ends some might be interested in posting details of their workflowmethodcode  LT the general forum has been taken down for the moment   When I get a little time I will attempt to revive it and start encouraging people to use it    Philipp  it may not matter that people only compete in a handful of competitions because each competition contains quite a lot of information   Unlike a single chess game participants are competing against many players   Regardless well do plenty of testing with Trueskill before implementation   As for the points system points seem a little abitrary   I like the idea of ratings that account for the strength of a competitions participants   I tend to agree with your point on forum participation points   The Stackoverflow approach seem like a nice way around the problem  There are lots of directions we could take Kaggle   But for the moment were focused on competiitons    JC I agree that those who enter early have an advantage   However the main source of advantage comes from the fact that they have had the opportunity to spend longer on the problem and try more things   Philipp the current leader has made  entries   If this competition took ternary scores loss win draw this would amount to  possible combinations  making Phillips  entries  a drop in the ocean   In fact the test dataset is richer because participants predict the probability of victory  Nonetheless for future competitions we will ask participants to nominate five entries that count towards the final standings    PEW we are not requiring participants to guess but rather encouraging them to rely on their cross validation when determining which models to choose   The problem with allowing people to enter many times and try many parameter tweaks is that they are more likely to accidentally overfit on the test dataset   By this I mean they are more likely to find a parameter tweak that works well on the test dataset but doesnt work as well for future chess games  On your second point you are correct to say that I am worried about statistical guessing   The requirement that participants submit code does not obviate this concern because models can be overfitted once the answers are known   In the extreme case somebody could fit a decision tree that classifies every game perfectly if they know the answers   Showing the standings but not the scores makes statistical guessing only slightly more difficult because participants are close enough that the leaderboard ordering gives meaningful feedback on which guesses are better and which are worse  As an aside it seems that I have failed to convey the message that the public leaderboard is purely indicative and that cross validation is  important   I would even go so far as to say that it may be problematic if the public leaderboard bears too close a resemblance to the overall standings    I like Uris suggestion   It gets around the problem that LT mentons while potentially encouraging people to try things beyond parameter tweaks   Couple of potential problems   A participant exhausts the submission limit and another entrant makes and shares a breakthrough eg the use of Chessmetrics in this competition  Anybody who has exhausted the submission limit wont have the opportunity to build on the breakthrough   This seems less than ideal given that we want to get the best results possible     It might encourage people to make all their entries at the end so that they dont reveal the strength of their hand   What do others think Philipp Kaggle has been experiencing a massive lift in site visits and\r\n",
      " signups since the new site launched from  unique visitors to    This accounts for the increase in entries   Thanks everyone for making this an amazing competitionBig congratulations to the winner Outis   Also to the runner up Jeremy Howard who only joined the competition late in the piece and to Martin Reichert who finished third  Hopefully well get some of the top ten to tell us about their methods on the blog   In the meantime I encourage you all to tell us a little about what you tried on the forums   Also for interest heres a chart that shows how the best score evolved over time   Rapid improvements initially but after a month progress stalled as participants approached the fronteir of what is possible from this dataset   I think I can help with this I dont give names just score combinationsscore publicscore                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Jeff can I post the test labels on the forum I only seem to have the aggregate solution on hand attached   Jeff do you have the game by game labelsEdit looks like you posted a minute before me Really nice feedback  very thought provoking   The API suggestion is nice   It does seem that it would prevent people from using the future to predict the present   However the testtraining split is still necessary to prevent overfitting and we could still only give partial leaderboard feedback the API doesnt secure against overfitted parameter tweaks   Also the API approach would add new problems    models will take longer to run because of the delay in receiving data points   as you say it would add a huge load on Kaggles servers As for the problems you list here are my responsesPredictions can’t use all available prior data since the test data doesn’t provide resultsThis is necessary to ensure against overfitting   If all the data is used to calibrate a model its impossible to know if the model will fit future datasets as well    Limited training and test data creates too much variance between the public score and actual scoreThe mistake made in the first competition was with the size of the public leaderboard portion of the test dataset my fault not Jeffs   It was too small which lead to the low correlation between public and overall scores   For the RTA competition we raised the proportion to ensure a stronger correlation   This proportion was calibrated after some testing of the correlation between the two parts of the test dataset   We intend to continue this practice going forward   Model parameters can’t be tuned because actual scores aren’t provided If we allowed parameter feedback on the whole test dataset this would almost definitely lead to overfilling parameter tweaks that work on the test dataset but wont work for for future datasets   Number of submissions is severely limited because they are so large this will become a bigger problem as larger test datasets are created I dont think more daily submissions are necessary because the majority of model building should be done with reference to a cross validation dataset   Leaderboard doesn’t reflect actual leadersAgain this was my mistake   I made the public leaderboard portion of the test dataset too small   This is not a flaw with the general approach   Future data can be used to predict the pastJeff suggested a really nice solution to this test set includes some spurious games so that people can’t mine the test set for useful data about the future   These spurious games wouldnt be used in final evaluation   The API also provides a really nice answer to this problem   Hi DirkWeve updated the data description  thanks for the pointer   \r\n",
      "The competition does require participants to forecast the next four observations   Weve updated the format of tourismdata  csv so that there is always a value in the last row   Regards Anthony Hi GregApologies there was a bug that cut off the last  characters   The problem has been fixed but unfortunately the fix will only apply future submissions   Thanks for pointing this out and sorry for the inconvinience   Anthony Greg thanks for pointing this out   Im currently traveling but will look into this over the weekend   Greg this problem has now been fixed   Thanks again for pointing it out   Dirk I just changed the file posted on the Data page to a unix format   Hope this solves the problem   Hi allWondering why the benchmark is still leading when it is publically available    Have people had trouble replicating the authors methodology Or is everybody trying their own approaches Anthony Something was amiss   There was an error in the data uploaded on Kaggle Kaggles fault not the authors  The changes are not particularly big so models that performed well on the previous dataset should continue to perform well   To give you the opportunity to rerun your models and make new entries we have extended the competition deadline by two weeks and lifted the daily submission limit to three per day   And I believe George intends to release the code used to create the benchmark   Apologies for the error Dont hesitate to ask if you have any questions   Hi JesseYou are correct this is instruction is wrong   The monthly columns  mm should be  lines long including the header and the quarterly columns qq should be  lines long  The examplesubmission  csv file available on the data page gives an example   Im at a conference today but will correct the instruction as soon as I get the opportunity   Dirk Ive changed the line break format   Let me know if this doesnt fix the problem    Tim Kaggle is currently in the process of putting together a  league table which ranks participants based on competition performances  If you perform well in this competition it will count towards your  ranking    Hi Markus I can help out on the second part of your query Ive posted some PHP AUC code on another forum post   software packages like R have easy to use packages that calculate AUC   Anthony Steffen you can enter using a model coded in any language   JohnDrew I presume those who enter using software other than R are still eligible for prizes  Hi ArtemFor the intuiton behind AUC have a read of the evaluation page   Kaggle implementation of AUC works roughly as follows   Sort submissions from highest to lowest   Goes down the sorted list and for each prediction plot a \r\n",
      "point on a graph that represents the cummulative percentage of class A predictions against the \r\n",
      "cummulative percentage of class B predictions      Join up all the points to form a \r\n",
      "curve   The AUC is the area under this curve  \r\n",
      "HT Phil Brierley for this explanation  William no thresholding is required which is part of the beauty of AUC   In fact given that the algorithm works by sorting participants make submissions containing any real number  higher means more confidence that the observation is of the positive class  Hope this response doesnt serve to confuse people  Anthony Artem Ive gone through the steps using your example data   Let me know if Ive made any errors  The Kaggle algorithm basically works as followsFirst order the data predicted            real     Then calculate the totals for each class in the totals  totals  Initialise the cumulative percentagespercentslast  percentslast  Iterate for each solutionsubmission pair counts  counts  counts  counts  percents  countstotalspercents   countstotalsrectangle  percentspercentslastpercentslasttriangle  percentspercentslastpercentspercentslast area  area  rectangle  trianglepercentslast  percentspercentslast  percentsSo in your exampleFirst submissionsolution paircounts  counts  percents    percents  triangle  rectangle  Cumulative area  percentslast    percentslast  counts    counts  percents    percents  triangle  rectangle    Cumulative area    percentslast    percentslast  counts    counts  percents    percents  triangle  rectangle  Cumulative area    percentslast    percentslast  counts    counts  percents  percents  triangle  rectangle  Cumulative area    AUC     Also heres Kaggles PHP code to calculate AUCprivate function AUCsubmission solution         arraymultisortsubmission SORTNUMERIC SORTDESC solution        total  arrayA B        foreach solution as s             if s                  totalA            elseif s                  totalB                nextissame           thispercentA             thispercentB             area             countA          countB          index           foreach submission as k             index              if nextissame                  lastpercentA  thispercentA                lastpercentB  thispercentB                        ifsolutionindex                   countA                else                 countB                           nextissame              ifindex  countsolution                   ifsubmissionindex   submissionindex                    nextissame                       mycount                                          if nextissame                   thispercentA  countA  totalA                 thispercentB  countB  totalB                 triangle  thispercentB  lastpercentB  thispercentA  lastpercentA                     rectangle  thispercentB  lastpercentB  lastpercentA                 A  rectangle  triangle                 area  A                             AUC  area         return AUC Thanks B Yang   The benefit of publishing code is that you get sensible suggestions in return    Hi JonIts a fixed  per cent chosen randomly  Anthony Hi TamasAs your results suggest the order does matter and the IDs dont   Anthony You can email me the file if you like anthony  goldbloomkaggle  com   Id be happy to take a look at it    William thanks for the question      Teams are allowed to merge     One individual cannot be part of several teams our systems ensure this anyway        as long as somebody doesnt have multiple accounts  Agree that we should make this more explicit in the future   As for finding people who submit from multiple accounts we are actually in the process of implementing rules that alert us when it looks like this is happening   In the future for large prize money competitions we may look at verifying identities    Apologies Will   I was on a plane and only just got your message   Will make the adjustment this afternoon  Id also like to congratulate the top teams and congratulate Dirk for running an excellent competition    Thanks to everybody who participated and a big thanks to Dirk for putting together a really nicely designed competition   The test labels are attached to this post   B Yang first off congratulations again on a fantastic performanceYour frustration is understandable but we cannot enforce rules that dont exist  what is common sense to some is not common sense to others   As Jeremy points out in the RTA competition the rules say The winning entry has to be a general algorithm that can be implemented by the RTA   An algorithm that involved looking up future answers could not be implemented by the RTA    Hi NickYoure welcome to bring additional data as long as its publicly available  Anthony This is something that should be dealt with on a case by case basis   If you find a dataset youd like to use ask on the forum and Ill run it by the RTA   For information Im trying to get hold of some incident data   Will keep you posted on this    Vitalie the volumes data is used to calculate travel time  see this post for more info   Our priority at the moment is to get the incident loop error and route length data together   However I can find out if this data can be made available if you think it might be useful   As Dennis says itll be highly correlated with travel time and we obviously wouldnt release it for the blanked out times    Jeremy I wasnt aware that public documents with traffic details were available   To the extent that any information is available for blanked out times this would most definitely be considered cheating  As for question  I am aware of this in fact the issue came up in another post   The rules state that the winning model must be implementable by the RTA in order to be eligible for the prize   The averaging model passes this test   As an aside I dont believe the temporal leakage invalidates the algorithms developed in this competition    Alexander to me this means that the algorithm can take a timestamp as an input and can generate forecasts for the next mins mins etc    Lee thanks for pointing this out  This post   post   Jose do you want me to ask if its permissible to use NOAA data If so are you asking about the data that Brad mentions above Jose and Joseph just spoke to the RTA about this   The answer is no because it might allow future weather conditions to be used to predict the present   Attached is some sample code that can be used to constuct an entry that generates a forecast based on the average travel time on a given route on a given day of the week at a given time   Mmm       file didnt attached   Heres the codephprh  fopenRTAData  csv r File to read fromwh  fopensampleHistorical  csv w Write the entry to this filedatedefaulttimezonesetGMT Purely to prevent the interpreter from raising a warningtimeStamp  array                               an Array with the humping off pointsforecastHorizon  array forecast horizon in lots of  minutes e  g      minutes  minutes   hour   This is used for calculating the forecast time stampsforeach timeStamp as ts      foreach forecastHorizon as f          forecastTimeStamp  dateN H istrtotimetsf find day of week hour and minute that corresponds to each of the timestamps     row  while data  fgetcsvrh    FALSE  loop through the datafile    if row    Write the header         colCount  countdata         for c c  colCount c             fwritewh   datac        fwritewhn        if  inarray dateN H i strtotimedataforecastTimeStamp    if the day of week hour and minute that corresponds to a forecast timestamp is found then save to an array called tsArray         for c c  countdata c             if  emptydatac  datac  x                  tsArraydateN H i strtotimedatac  datac            rowforeach timeStamp as ts      foreach forecastHorizon as f          fwritewh dateYmd Histrtotimetsf        for c c  colCount   c             fwritewh    arraysumtsArraydateN H istrtotimetsfccounttsArraydateN H istrtotimetsfc writes the average for a given day of the week hour and minute to the submission file         fwritewhn    fcloserhfclosewh  This code does generate a sample entry   To use it a download the PHP interpreterb create a file name xxx  php copy the code above and download the data files to the same directoryc run the command PHP xxx  php Youre correct  the future is used to predict the present   However I dont think the temporal leakage invalidates the algorithms developed in this competition    Attached is some sample Python code that generates forecasts based on the last known travel time   Im new to Python so happy to hear any feedback on the code   File didnt attached   Heres the codeimport csvimport datetimerhopenRTAData  csvr read in the data whopensampleNaivePython  csvw create a file where the entry will be savedrhCSV  csv  readerrhtimeStamp                                 an Array with the cutoff pointsforecastHorizon   forecast horizon in lots of  minutes e  g      minutes  minutes   hour   This is used for calculating the forecast time stampsrow   inialise the row variablefor data in rhCSV loop through the data    if row   if the first row then write the header        for j in rangelendata            wh  write  dataj        wh  writen    if data in timeStamp if the row is a cutoff point            for i in forecastHorizon for each forecast horizon write the cutoff travel time as the forecast the definition of Naive                 dateStr  strdatetime  datetimeintdataintdataintdataintdataintdata  datetime  timedeltai calculte the time stamp given the forecast horizin                 wh  writedateStr write the timestamp to the first column of the CSV                for j in rangelendata                    wh  write  dataj write the cutoff travel time to the subsequent columns                 wh  writen    row  rh  closewh  close Lee this is great Dirk did the same thing with some Python sample code I wrote for the social networking competition   If you guys keep showing me how things can be done better I may become a half decent coder   Toppy thanks for the pointer   A higher priority at the moment is to get forum attachments working again   Hi Peter Ill follow up in this   At the very least we should be able to provide information on the length of different routes   Anthony Armin I agree   Makes more sense for me compile this information once for everybody   Will try and get it done this week   Eleni just uploaded RouteLengthApprox  csv which has approximate route length data    Martin Dane is correct the information in RouteLengthApprox  csv is in metres   So route  is approximately   km    Martin when I open the file it shows  and    What application are you usingAnthony Dirk thanks for pointing this out   Ive written to the RTA about this and they responded sayingIndeed  our control room have confirmed significant increase in traffic volumes following the removal of the tolls   This has had an impact on the overall travel times across the M  Something to be aware of when using the older data    Hi Dennis The  per cent doesnt count towards the final standings and is selected at random across the  timestamps and  routes   As for the SMTP error its been fixed   The problem was the result of a flood of signups which caused Google to shut off our mail server   Were now using our own mail server   Anthony The number directly to the left of the team name is the teams position and the number to the right of the team name is the teams score or Root Mean Squared Error RMSE    Apologies for the error its deciseconds not centiseconds  so  is    seconds   Ive fixed the description    Hi Carlos Unfortunately not   Clause   c in Kaggles Terms and Conditions saysc            employees or agents of the Competition Host are not \r\n",
      "eligible to participate in any Competition posted by the Competition \r\n",
      "Host\r\n",
      "\tTo answer the second question we would more information about the nature of the business and what your friend does  Anthony Frank this is great I particularly like the heatmap  is it possible to zoomAlso itd be neat to see some animation on the M map  showing how travel times evolve over the course of a dayweek dots getting bigger and smaller   Though I suspect this might be a lot of work  Anthony  C does seem to be an expressive language   Im a Linux user though so not inclined to pick it up    Daniel Dennis is correct in saying that averaging the values leads to floating point numbers   The answers are integers but the RMSE is calculated using floating point arithmetic    Alexander there is no truncation of floats    David I believe that when loops the measuring device fail travel times are estimated   Im working towards putting together data on when travel time readings are suspect    Andrew good discovery   Ill pass the question onto the RTA  Edit Wouldnt it be obvious if they werent making the adjustment since peak traffic times would change Paresh thanks for the thought provoking question   I agree with Dennis I am more interested in the time delay than the percentage delay   On a related matter we think it is more important to predict correctly when travel times are volatile e  g   before and after work   To favour models that predict more accurately during high volatility times we selected more high volatility cutoff points so youll notice more cutoff points during the morning and afternoon   Phil thanks for sharing this   Just got to find a Windows machine to run it on        Aidan have asked the RTA about this   This was the response   The cutoff is due to free flow conditions imposed by the system during data unavailability  Ive written again asking for a little more detail   Will post the response when it comes    I have some information on suspect loop readings that Im working to release   This has information on when loop readings may be unreliable for various reasons   I dont yet know whether or not this will help with the free flow issue   Anyway I will upload them as soon as I can get it into a useful format  I suspect the reason the free flow times are different is because route lengths are different   Rob on your point about missing data it might be helpful if I explain how I put the files together   I received data in the following formatroute IDtimestamptravel time xxx xxxI transposed them into in the hope that theyd be more manageable   When timestamps were missing I just filled in a blank row   Aaron another good question   Have also passed this on to the RTA    Daniel and Dennis are correct   Keep in mind that the  per cent is a random selection of the  that doesnt count towards the final standings which are calculated based on the other  per cent   burak the times in sampleEntry  csv are the times you need to generate forecasts for   Theres more info on how the  cutoff points were selected in this forum post   Mmm       my message seems to have disappeared from the board   Anyway heres a repeat  Aaron the units are deciseconds  Nick actually its a hybrid approach   You can nominate five entries that count towards the final standings   You do this from the submissions page  the last five are chosen by default   At the end of the competition the best of your five nominated entries counts towards your final position   And Nick on your new question the one of the five you nominate that scores best on the  per cent counts   The  per cent is meaningless as far as the final standings are concerned    The cutoff times are all between am and pm   They were selected using a simple formula that favoured high volatility cutoff times over low volatility cutoff times   So youll see more peak hour morning and afternoon cutoff times   The rationale behind this is that its more important to predict accurately during high volatility times so we want to favour models that do best at these times   That explains why the RMSE is higher than for randomly chosen cutoff points   Thomas I selected specific cutoff times randomly but chose timeday combinations that are volatile across the dataset   Rasmus apologies I deleted the wrong post   Anyway you asked how travel times are measured   There are regularly spaced loops along the M   These loops measure each cars speed and the number of cars that travel across the loop every three minutes  travel times are then calculated using a formula   The formula has been tested and calibrated using test cars that travel along the freeway and record their travel times    Benjamin once we get the incident data I will put in a request for this data    Hassan the most important file is RTAData  csv   You can create a sample entry by   downloading RTAData  csv and createHistorical  php attached to the same directory   navigating to that directory in the terminalcommand prompt   running php createHistorical  php This will create an entry based on a historical average for that timeday and is a good starting point   BJB very generous of you to upload a Java code   Ive now enabled   java file uploads so you should be able to upload the file    Aaron you raise a good point   According to the route definitions I have route  extends from loop A to loop A while route  extends from A to A so  should encompass all of    Denniss observation that sometimes  has longer throughput times than  is strange   Ill double check the definitions with the RTA    Konstantin just uploaded RTAError  csv the is valid data   Its available on the data page   Mooma I appreciate your frustration but sensor malfunctions  are part and parcel of dealing with realworld data   If we had the data ready at the outset we might have excluded failed sensors and downweighted the impact of partially failed sensors when evaluating predictions    Konstantin Dennis is correct it is not safe to assume that there is no errors in the control data    Ahmed just got an answer from the RTA on this   Heres the responseThe answer is  maybe   RTA would request that anyone wishing to use the data for further research purposes write to the RTA and make their case  describing what they wish to do ie the purpose of the research and how they would use the data   The RTA will consider each application on its merits   Let me know if youd like me to pass on the relevant email address   Im reluctant to do it in the forum but will offer an introduction to anybody who asks   Rob thanks for jumping in    Dielson good pick up   Dennis is correct  the date format doesnt matter   What is important is that you put the correct data in the correct cells   Many thanks to everyone for all your great activity on this fascinating problem  insightful questions and comments on the forum good early results on the leaderboard and interesting discussions There have been a lot of questions about exactly what constitutes an acceptable model for the RTA   So far my guidance on this matter has possibly been too fuzzy and I hear a lot of you looking for more definite rules   Therefore we have come up with the following specific rule regarding the allowed model inputs Your model can be of any form you like as long as it takes its input only from the following parameters Time of prediction Day of week Is holiday Month of year Route number to be predicted The time taken for route r for datetime t where  r is any route and t is any time less than the datetime being predicted for as  many routes and datetimes as you wish The sensor accuracy measurements for any routes r and datestimes t defined as above The estimated route distances as provided by KaggleTo clarify the following are not permitted The use of any data other than those provided by Kaggle for this competition and the list of NSW holidays   The time taken for any routes in the future compared to the prediction being made  your model can still be trained using all data as long as the resultant model only uses the inputs listed above  Furthermore the algorithm must not be encumbered by patent or other IP issues and must be fully documented such that the RTA can completely replicate it without relying on any black box libraries or systems   Hi Alexander   No   Using full timestamp makes it possible for a model to implicitly incorporate external data and future data     You may also use holiday data extracted from the PDF file that you linked to in order to get holiday information for previous years   However we will not be providing a file of this information directly     This is correct  Anthony As Jeremy Howard pointed out earlier in this thread the key point that answers most of these questions is that the limitation is only on the functional form of the final model   More specifically Xiaoshi Lu You can build your model  filtering aggregating etc  using all the datetime information you like   The final functional form that you end up with however should only use the predictors listed above   Mooma The inputs listed include this The time taken for route r for datetime t where  r is any route and t is any time less than the datetime being predicted for as many routes and datetimes as you wish   So what you ask is specifically allowed   Of course for you to create your input file which includes for example the time taken one hour earlier you will need to use the full datetime   However the resultant model will not directly use this  instead it will only use the time taken on that route as allowed by the rules   Alexander Groznetsky Imagine using a very flexible model neural net for instance which trains with all datetime info included in the input parameters   It might implicitly end up using the route times later in the day to predict those earlier This is an example of how a model could be useless in practice even although it appears highly predictive on the competition data    Matthew   Using GPL code is fine      The isholiday variable can be a direct input rather than a variable that is derived by reference to a timestamp      You contact me directly at anthony  goldbloomkaggle  com   Dennis you can use isspringbreak rather than isholiday    Nicholas a Matlab solution is fine as long you dont include libraries that use patented or undocumentedsecret algorithms    Rafael  and  are fine    is also fine as long as the data is derived entirely from the time series as you say     JoseI notice that you are now on the leaderboard   It can take a few minutes before you show up   Anthony David its really neat  For info it works in Safari but the page videos are aligned a little strangely   The In the Money indicator is based on the public leaderboard only   It doesnt reveal anything about the final standings   Reginald please email your submission to anthony  goldbloomkaggle  com and Ill have a look   Wu Wei a route is made up of several loops   A figure of    means that  per cent of the loops in the given route are giving suspect readings    For anybody interest heres the actual solution   Nathaniel is right  the data is correct its just a problem with heading formatting   Will fix this shortly and reupload the data    Finally  fixed the headings   Just to reiterate all the data are correct  its just the capitalization in the headings that caused trouble  As for the inconsistent numbers of delimiters also fixed  my software package stopped printing delimiters when there were no more values or NAs in a row   Jack the country  of  birth issue is now fixed   Please download the latest version of the data    Attached is some R code to create a GLM entry for this competition   As always happy to hear feedback from others about how this could have been done more elegantly   Anthony personIDs refers to all the columns that have investigator IDs e  g   column  has investigator  column  has investigator    Ignore the comment numerical values that should be     No   Towards the end of this competition you will be asked to nominate five entries that count towards the final result    P  V  Kiran it means that if your solution is implemented using a software package that is not available to the University of Melbourne it must be possible to translate your solution into a different packagelanguage    Just elaborate a little the types of solutions that cant be implemented are those that are encumbered by patents or other intellectual property restrictions   Nathaniel thanks for pointing this out   Definitely worth investigating   The Number of Successful Grants and Number of Unsuccessful Grants  fields dont change in the test dataset for obvious reasons   The journal citations also remain constant in the test dataset to prevent participants using the future to predict the past   Nathaniel I have looked at the problem in some detail and have spoken to the University of Melbourne   They are looking into it and hope to have an answer for us tomorrow before they break for Christmas    The university has spent the last two days on the problem   They suspect its an internal inconsistency in their database the figures are drawn from different parts of their database   Well have to wait until the end of the Christmas break to get a final verdict    Deepak thanks for pointing this out   We will ask  the university about this as well   Unfortunately we cant expect an answer until early next year    The university has done an investigation and has found that the issue arises from an inconsistency in their database   Michelangelo truth is that you can submit any real number we suggest a number between  and  because of the convenient interpretation   AUC ranks your scores  the higher the score the more confident you are that the instance is a member of the positive class   I believe it refers to grants made when the researcher was at another university    Edith thanks for the feedback   We agree with your comments and we are working on making the terms more competitor friendly    Michelangelo the  per cent comes from the test dataset   Eu Jin Lok the sampling is done randomly    Hi GregThe answers will be made available on the forum   I can ask whether the data can be used for publishing research if you likeKind RegardsAnthony  Hi Greg and SuhendarThe university doesnt want the data to be used for any purpose other than for this competition  Anthony Hi GregIt would be nice if the dataset could be used for other work   However if we dont allow competition hosts to place restrictions on the use of their data then we wouldnt get access to it in the first place   Will post the solution file now  RegardsAnthony The solution file is attached to this post  Thanks all for participatingAnthony  Apologies I didnt clarify this with Mahmoud before the launch but we have discussed this offline  This competition requires you to choose five entries that count towards the final result   To choose five entries visit your submissions page and click the star next to the relevant entry to select it   If you do not choose any entries your last five entries will be chosen by default   Hi allSubmitting from multiple accounts is most definitely against the rules   We have done some analysis and found that it happens very rarely   However we are working to put the systems in place to identify and block those who attempt to do it  Kind RegardsAnthony HarriThanks for the thoughtful post   The IJCNN people agree with you and have decided not to disqualify Shen   As mentioned above Kaggle will soon have the systems in place to detect multiple accounts in real time so that such issues dont arise  Anthony I have sympathy for peoples frustrations   In this case the competition host decided that the results should stand  so we are facilitating their decision  Chris makes a good point about the rules being scattered throughout the site   We will be sure to address this in future competitions   We will also ensure that they are tightly enforced   For information a lot of effort has gone into framing the Heritage Health Prize rules  Finally thanks for the feedback   Its discussions like this that will help us improve Kaggle   Kaggle has received legal advice after the controversy surrounding this competition   We have been advised that it sets a dangerous precedent for us to ignore our own terms and conditions notably clause    preventing multiple signups   We have therefore acted in accordance with this clause disqualifying those who clearly submitted from multiple accounts  Thank you all for your patience on this issue and rest assured that we are working to ensure that it is not a feature of future competitions   The solution is attached  Thanks all for participatingAnthony Entries made before we fixed the leaderboard were scored incorrectly   I have now rescored the relevant entries   The error was the fault of Kaggle and not the competition organizers   ApologiesAnthony Hi CerinApologies for the errors   They all stemmed from the fact that the servers hard drive filled up   Ive cleared some space   For information were currently rewriting the entire site for the Heritage Health Prize   You can expect the next version to be faster and include many more features  Thanks for your patienceAnthony Hi CerinAli is right your entries will count towards the final standings   Anthony Also covered by Slate and Forbes\n",
      "  \n",
      "  \n",
      "and the Wall Street Journal a couple of weeks ago\n",
      "   And Smarter Planet\n",
      "   Dorofino\r\n",
      "\r\n",
      "Great idea Forming a team is a really good way to learn   \r\n",
      "\r\n",
      "Are you affiliated with the New York R Users Group For info Ive heard rumblings about them setting up a team   \r\n",
      "  \r\n",
      "\r\n",
      "Good luck with this\r\n",
      "\r\n",
      "Anthony Apologies this was an error   Thanks for drawing our attention to it  \r\n",
      "\r\n",
      "The missing values are for those people who have been in hospital for more than two weeks   They should be replaced with a    You can either do this yourself or download the updated dataset   \r\n",
      "\r\n",
      "For information members who have in hospital for more than two weeks have been grouped for privacy reasons they are rare so may otherwise be identifiable   The implication of this grouping is that if you expect somebody to be in hospital for more than two weeks you should predict  days   \r\n",
      "\r\n",
      "This grouping should not have a big impact because\r\n",
      "a   members who are in hospital for more than two weeks are rare about one per cent of members\r\n",
      "b   the evaluation metric favors algorithms that accurately predict fewer days in hospital on the assumption that these are more preventable   Hi Rich\r\n",
      "\r\n",
      "Just spoke to HPN about this   For the moment they dont want to provide general guidance and ask that you make a request through the contact us form   Your request should detail the topic of your proposed research   Definitely worth making it clear that youre just looking to publish the method that you use to enter the competition   \r\n",
      "\r\n",
      "Anthony Wgn the intention is not to rule out the publication of research   Ive passed on your message to HPN and a clarification will be forthcoming  \r\n",
      " ashojaee the clarifications havent been made yet    Apologies for the missing values it was an error   You can either replace the missing values with  or download the updated data set   \r\n",
      "\r\n",
      "If youre interested in the reason for the missing data see\r\n",
      "   Y Y Y etc refer to different years   We havent revealed which years to help keep the data private    Agree   See the updated evaluation page\r\n",
      "   The years are sequential   We are not revealing what years Yn refer to nor whether or not they refer to calendar years for data privacy reasons   Just to clarify when Jeremy says we cleaned it as much as we can we didnt do much to the claims data on purpose   We figure it makes more sense for you to make your own cleaning assumptions rather than have us impose them on you   \r\n",
      " The criteria was that somebody had to\r\n",
      "   make at least one claim in Y \r\n",
      "   be eligible to make a claim in Y\r\n",
      "\r\n",
      "Outliers have been removed from the dataset as well as those suffering from stigmatized diseases   \r\n",
      " Not only are patients who died in Y not in the dataset but patients who died in Y are also not in the dataset because they didnt remain eligible to claim for the whole of Y    rudychev received an answer from HPN on this   A patient who visits a clinic outside the network should be captured in this dataset   Of course as Jeremy keeps reiterating there is always a disconnect between reality and the contents of a database   Hi bacg\r\n",
      "\r\n",
      "   DaysInHospital refers to Y the second year while the claims refer to Y the first year  \r\n",
      "\r\n",
      "   Not everything that has a length of stay counts as a hospitalization   In fact you dont have enough detail in the Claims table to calculate DaysInHospital   The detail has been suppressed for privacy reasons  \r\n",
      "\r\n",
      "Anthony Hi mbenjam\r\n",
      "\r\n",
      "We would have loved to release more detailed data but have to be mindful of data privacy   \r\n",
      "\r\n",
      "Anthony mgomari one issue we have to keep in mind are the tradeoffs in releasing data   For data privacy reasons HPN have a granularity threshold which theyre not willing to breach   The data anonymization team represented by keleman in the forums are trying to release CPTCodes probably at an aggregated level   Apparently its pretty lineball and releasng DaysInHospitalY might put this in jeopardy   I describe the data privacy considerations like a waterbed you push down on one part of the bed and it creates a bulge somewhere else  \r\n",
      "\r\n",
      "After May  youll be able to use DaysInHospitalY and DaysInHospitalY to predict DaysInHospitalY  \r\n",
      "\r\n",
      "ogenex even if we release DaysInHospitalY you wont be able to do a consistency check   Not all length of stays count as hospitalizations as calculated for this competition and you dont have enough detail in this dataset to work out which count and which dont   SSRC mapping LOS to DIH is impossible   Not every LOS entry corresponds with a DIH e  g  hospice stay One reason somebody may have DIH in y but no claims is if they werent eligible to claim in Y in which case their Y claims wouldve been removed   Have received advice from the HPN lawyers   Im really sad to say that the answer is no on all accounts     The lawyers are taking a conservative stance on this issue   Apologies its really disappointing to have people ruled for this reason    flsdcom I have a meeting with them in  minutes   I will be sure to raise this point   In response to ashashos original question I have sought a reexamination of the issue   The HPN lawyers explained that the reason for the hard line is that they have no way to verify that residency permits comply with US legislation   Im really sorry to say that theres not more I can do   cybaea many thanks for a great discovery After doing some digging weve discovered that the oddeven observation is an artifact of the cleaning procedure   \r\n",
      "\r\n",
      "We have worked out a remedy and it will be applied to the dataset that will be released on May    In the meantime it shouldnt make a huge different to models that are currently being developed   boegel yes   On May  we will be issuing significantly more data   DayInHospitalY  csv will be changed then   Eu Jin youve obviously not seen this\r\n",
      "   frankthedefalcos  com or the women who have been treated for erectile dysfunction   Tom SF Haines Jeremy is not the author of the rules   He is merely trying his best to point people to the section that makes the rules as competitor friendly as possible given HPNs requirements  \n",
      "Also if you would like to publish your algorithm I strongly encourage you to put in a research request using the Contact Us form   The decision to predict days in hospital was made to make the test dataset richer  so we can better sort out good algorithms from bad   The logarithm in the evaluation metric was chosen to favor models that predict short stays more accurately as these are assumed to be more readily preventable   \r\n",
      "\r\n",
      "As for the question of nefarious intentions I can tell you what I know about Dr Richard Merkin the man behind the prize   He is a big philanthropist who devotes time and resources to funding scientific projects schools and the arts  \r\n",
      "\r\n",
      "In my opinion HPN did not need to put up  million to get an amazing algorithm   Kaggle has found in its own competitions that with prizes as small as  or a chess DVD participants approach the limit of whats possible on a dataset   In our communications with HPN we have been told that the  million prize is an attempt to draw mass attention to this prize and the issue in general   Dr Merkin wants to promote the potential for medical data mining in lowering healthcare costs   The prize also serves to introduce a large number of talented data scientists to medical data  \r\n",
      "\r\n",
      "Finally rest assured that HPN are working hard behind the scenes to clarify the IP issue   alexx the HPN lawyers are working on a clarification   This will be released by the time entries can be made on May      Hi Drew\r\n",
      "\r\n",
      "It will be in place by May  when entries are accepted   Anybody who accepted the existing rules will receive the notification via email   \r\n",
      "\r\n",
      "Anthony The accuracy threshold will be announced when we release the full claims dataset on May    \r\n",
      " This is a sample of the final dataset but the final dataset is not in the Terabyte range   To the best of my knowledge this dataset is on the larger side for medical datasets which tend to be quite small  \r\n",
      "\r\n",
      "This algorithm will not need to operate in a realtime environment and so there is no restriction on execution time     I want to reassure everyone that HPN is working hard behind the scenes to clarify the IP issue   It is not their intention to prevent people from using standard tools nor to discourage anyone from applying their innovative ideas to this problem   \n",
      "For background at Mondays launch event Dr Richard Merkin the man behind the prize spoke of the long tradition of innovation that has resulted from past prizes   He spoke of\n",
      "\n",
      "the Longitude Prize     apparently Newton and Galileo had attempted to solve this problem but the winner was a self educated clockmaker from Yorkshire\n",
      "Napoleons food preservation prize  won by a confectioner and resulted in the invention of canned food\n",
      "the Orteig Prize to fly nonstop from New York to Paris     won by the unlikely Charles Lindbergh   \n",
      "\n",
      "It is his hope that this prize will spur similar innovation to solve one of Americas most vexing problems  \n",
      "We appreciate your patience while we await clarification  \n",
      "Kind Regards\n",
      "Anthony For those who dont know jphoward was Kaggles most successful competitor before joining the team   His tutorial gives really clear explanations of the tools and techniques that made him such a successful competitor    Hi Jim\r\n",
      "\r\n",
      "That is correct   For information the reason for the misnomer is that it was days when we sent it to the anonymization team but they had to group the days to ensure the required level of data privacy  \r\n",
      "\r\n",
      "Anthony  sciolist yes teams are required to publish publicly    mkarbowski as jphoward keeps pointing out theres often a massive disconnect between reality and the contents of a transactional database   See ejloks humorous post for even odder records\r\n",
      "  \r\n",
      " We intentionally decided against cleaning the data so as not to impose our assumptions on participants    We want the forum to be tightly integrated into the site e  g   to be able to link to forum posts from profiles and vice versa   YAF is the best   NET forum software out there and integrating it into Kaggle is more trouble than its worth   \r\n",
      "\r\n",
      "Also moserware is a brilliant programmer so its the type of thing he could put together in less than a week   DIH includes inpatient admissions and emergency room visits   As mentioned previously you dont have enough detail to calculate it from the claims table   RalphH DaysInHospital counts days not nights   So if DaysInHospital is  then they have not been to the hospital at all   If they were in and out of the ER then DaysInHospital would be    Domcastro one of Kaggles first suggestions was to remove the registration fee   \r\n",
      "\r\n",
      "For info the registration fee wasnt ever to raise money but to try and deter people who werent serious from downloading this sensitive data   Kaggle pointed out that anybody with malevolent intentions would probably still pay the modest registration fee so its effect would be to deter people who didnt think they had a chance of winning   Kaggle went on to argue that these people may also come from interesting backgrounds and may be the ones most likely to apply creative thinking to the problem   Realworld data is messy \r\n",
      "\r\n",
      "Well put up a data dictionary soon   DaysInHospital is calculated based on the LengthOfStay variable   However you dont have enough detail to calculate DaysInHospital from LengthOfStay    quotedaveime\n",
      "Seriously I understand the need for randomizing and anoymizing the data but unless they have some way to unrandomize it afterwards any algorithms we create will serve no real world application  \n",
      "quote\n",
      "daveime the data is messy not because its been peturbed but because its realworld data   Anonymization focused on generalizing again not peturbing     The the nineyear old pregnant males actually exist in the raw data  \n",
      "For info Im told that this is one of the cleaner medical claims datasets around   mgomari the difference between  and  is counted as two days  \r\n",
      "\r\n",
      "Overlaps were accounted for so were not double counted    fjn Pi does not have to be an integer    blonchar youre correct HPN are limited in what it can release by the need to protect patient privacy    liveflow I may be misunderstanding the question but the competition requires participants to use data from Y Y and Y to predict Y   No   Some Y patients are no longer eligible in Y   We still provide Y patients who arent eligible in Y because theyre useful to train on  \r\n",
      " DougieD every member listed in DaysInHospitalY is eligible to claim in Y  so if they have  DIH  they are  above   The same will apply for the members listed in DaysInHospitalY and DaysInHospitalY when we release those files    jesensky you will be able to use DaysInHospitalY and DaysInHospitalY as an input to DaysInHospitalY  \r\n",
      "\r\n",
      "I like your thinking on the USE OF OTHER DATA loophole if the answer had been no   Creative thinking    mgomari the answer to both questions is yes    Information Man that is not the intent of the rule   The HPN lawyers are working on clarifying this at the moment    No   Again for privacy reasons    irwint good pickup  thanks Now fixed    gschmidt not sure if this answers your question but the geographic spread is limited to the area in which HPN operates southern California I believe   \r\n",
      "\r\n",
      "As to whether patients change doctors on May  youll have a few years worth of data so will be able to work this out   You will get some procedure code information in the May  release   I understand the frustration but data privacy is a priority for HPN   metaxab the competition was designed this way to replicate how the model might be used in real life   In a real life situation you wouldnt be able to predict hospitalization with contemporaneous claims    DaysInHospitalY is derived from the claims table where a hospital stay includes an inpatient stay or an emergency visit   Note you dont have enough information to calculate DaysInHospitalY from the claims table    In this dataset missing PayDelay either means unknown or greater than    In the May  release the anonymization team will topcode PayDelay so there will be fewer missing values and  will mean    For generating features I recommend SQLLite  though MySQL does the same thing   I know Jeremy and Jeff like Cs Linq   For building models I use R   The rules do not prohibit Oracle Data Miner    rks we will post a sample entry with the rest of the data on May    trezza and RHM Y contains data for a  period   trezza unfortunately not   The anonymization team have identified this as a data privacy risk   Hi Allan\n",
      "Thats because some members have had claims suppressed   In release  coming soon well make it clear which members this applies to  \n",
      "Anthony  Hi Domcastro  \n",
      "   Can I use R\n",
      "Yes\n",
      "   Can I use Weka\n",
      "Yes\n",
      "   Can I use Excel\n",
      "Yes\n",
      "   If I organise the data in a novel way and just use a standard processing algorithm such as Naive Bayes is this OK\n",
      "Yes You must preserve the order in Target  csv   Unfortunately not   Apologies for any inconvenience   Darragh its a list of all members in the dataset   Release  zip does supersede Release  zip     Chris just heard back from the data anonymization team   Members have been renumbered   No   cacross HPN had a granularity threshold that they wanted to remain below   Some LOSs had to be suppressed to achieve this target   If there is a blank LOS and SupLOS is  then this is how it was when it came out of the HPN dataset   If there is a blank\r\n",
      " LOS and SupLOS is  then the LOS has been suppressed   Hope that helps   mkwan you fill in the team wizard when you make your first entry   Team mergers will be granted at the organizers discretion   ChrisR nice to see you competing in this   Sampling is random   Yes   Bernhard your interpretation sounds about right to me    We cant give you an HPN benchmark because theyve not tackled this problem before    boegel DaysInHospitalY contains members who made a claim in Y and were eligible to make a claim in Y   DaysInHospitalY contains members who made a claim in Y and were eligible to make a claim in Y   Similarly target  csv contains members who made\r\n",
      " a claim in Y and were eligible to make a claim in Y   To be eligible means to be an HPN member regardless of whether or not a claim was made  \n",
      "Therefore the  members in DaysInHospitalY are not missing from target  csv but rather didnt make a claim in Y or werent eligible to make a claim in Y   Therefore all members in target  csv were eligible to make a claim in Y  so we have an answer\r\n",
      " for each of these members  \n",
      "JESENSKY by my calculation  members appear in DaysInHospitalY and DaysInHospitalY but not DaysInHospitalY perhaps you can confirm this figure   These members are missing from DaysInHospitalY because they didnt make a claim in Y despite\r\n",
      " being eligible  \n",
      "Apologies if we didnt communicate this effectively in the description pages   ProTester theres nothing in the raw data that distinguishes a death from a patient that leaves HPN for another provider   DanB youre right about the selection bias   But because HPN are releasing almost no information on the members themselves theres nothing to model on for patients without claims   George there are  members in the dataset but you are only tested on  members   Thats because the extra  members arent eligible to claim in Y or didnt claim in Y   They have only been provided to help you train your model   Further to Wills point those who followed the Netflix Prize will remember the jump from the Simon Funk discovery     is the maximum   Ive said this before but I think \r\n",
      "Jeremys tutorial is really excellent although it is not focussed on HHP   He is hoping to get the opportunity to do an HHP tutorial in the next few months     Darragh I passed your question onto HPN   Heres the reply\n",
      "Is there a delay between the scheduling of the surgery and when it takes place  Yes    But that is just a matter of scheduling not something forced by the government    It would also of course depend on how urgent the surgery is   She will be added in the next release    The intent of that provision is to prevent the data being shared with those who have not agreed to the competition rules   Jeff was just referring to the measures he would take to ensure the data isnt accessible to others   Jose thanks for your diligence on this   Its difficult for us to give specific guidelines   Again HPN is just trying to prevent the data from being accessible to those who havent accepted the rules   Jim its being assessed against Y hospitalizations   Thanks Dave   The data description has been fixed   Hi Bobby\n",
      "Can you clarify what you mean by this Are you asking if they are obliged to share their model if they finish in first place\n",
      "Anthony I have checked with HPN and a milestone prize winner can choose not to disclose their method but will not be eligible for the milestone prizes  \r\n",
      "    Correct Hi Willem\n",
      "\n",
      "to what extend the results have to be identical for example small differences in the random number generator may give different results although they should be similar\r\n",
      "\n",
      "They do need to be identical   You can give your random number generator a seed to make sure the resultls are the same each time  \n",
      "\n",
      "in how much time should the results be reproduceable my current best result is a mix of many models each may take minutes to hours to generate\r\n",
      "\n",
      "There is no rule about execution time     \n",
      "\n",
      "the algorithm should produce similar results on a new dataset this doesnt sound very realistic I dont think there is any way to win this competition without optimizing for this specific dataset   Results on other datasets may be very bad with the\r\n",
      " given optimizations   Probably very good results can be produced by the same algorithm after some tuning but this is a process that requires a lot of knowledge about the used algorithms and a lot of time and patience  \r\n",
      "\n",
      "Not sure I follow why this is an issue   Remember the Milestone prize is judged in a portion of the test dataset that participants have not been given any feedback on   Perhaps Im misunderstanding the concern  \n",
      "HTH\n",
      "Antthony Regarding the requirement that solutions be identical\n",
      "Willem it would be better to have participants spend time on innovation rather than reproducibility however its important to have strict rules so that the competition remains as fair as possible  \n",
      "B Yang with regards to the compiler issue we can address it if the issue arises   For example we might start by ensuring that the same compiler is used for verification  \n",
      "Sali Mali it is exceptable to describe the algorithm and not how it is derived   We are seeking clarification from HPN on the inconsistency that you describe   Apologies for the delay  \n",
      "Regarding the requirement that the algorithm perform similarly on a separate dataset\n",
      "This is best answered by explaining the rationale behind the rule   It is there to catch any cheating or blatant overfitting   If youre not blatantly overfitting then youre likely to be on safe ground    Hi all\n",
      "Not ignoring this thread   Just seeking clarification from HPN on one issue   \n",
      "Anthony Sorry for the delay on this was just clarifying some issues with HPN  \n",
      "\n",
      "Is it inconsistent as Sali Mali pointed out in another thread to require documentation of the winning algorithms be publicly disclosed to all competitors given Rule  Entrant Representations  It seems that this disclosure will encourage other competitors\r\n",
      " to use aspects of the winning Prediction Algorithm which cause violation directly or otherwise of i  iii and possibly iv of that Rule  \r\n",
      "\n",
      "Rule  does not apply to the extent that it prevents a competitors other than a milestone prizewinner from using code published by a milestone prizewinner in accordance with competition rules and b a milestone prizewinner from competing subsequently\r\n",
      " in the competition using code for which it was awarded the milestone prize  \n",
      "\n",
      "Can you clarify that code libraries and software specifications are not required to be publicly disclosed to competitors  These materials and intellectual property appear to be referenced separately from Prediction Algorithm and documentation  \r\n",
      "\n",
      "\n",
      "Chris correctly points to Jeremys response in an earlier forum post\n",
      "“Only the paper describing the algorithm will be posted publicly   The paper must fully describe the algorithm   If other competitors find that its missing key information or doesnt behave as advertised then they can appeal   The idea of course is that\r\n",
      " progress prize winners will fully share the results theyve used to that point so that all competitors can benefit for the remainder of the comp and so that the overall outcome for health care is improved  ”\n",
      "\n",
      "\n",
      "\n",
      "Will Kaggle or Heritage have a moderation or appeals process for handling competitor complaints  From the winning entrants pointofview they would not want to be forced through the review process to allow backdoor answers to code and libraries which\r\n",
      " accelerate a competitors integration of the winning solution   \n",
      "\n",
      "Kaggle and the HHP judging panel will moderate the appeals process  \n",
      "\n",
      "\n",
      "Can you comment on the spirit and fairness of the public disclosure of the Prediction Algorithm documentation and its impact on competitiveness  In particular if the documentation truly does meet the requirement of enabling a skilled computer science\r\n",
      " practitioner to reproduce the winning result then this places the winning team at an unfair disadavantage all competitors will have access to their algorithms and research in addition to the winning algorithm  \r\n",
      "\n",
      "\n",
      "This rule is in place to promote collaboration   Those who would prefer not to share can opt out of the prize  \n",
      "\n",
      "\n",
      "Can you provide more detailed clarification on the level of documentation required by conditional milestone winners  The guideline provided by the rules would cover a range of details and description spanning from lecture notes to detailed tutorial\r\n",
      " to whitepaper to conference paper etc   \n",
      "\n",
      "Hopefully this was adequately dealt with in Jeremys response requoted above   Let me know if further clarification is needed  \n",
      "\n",
      "\n",
      "Can you comment on the reproducibility requirement  For example it is possible to construct algorithms with stochastic elements that may not be precisely reproducible even using the same random seed is it sufficient for these algorithms to reproduce\r\n",
      " the submission approximately  What if they dont reproduce exactly or reproduce at a prediction accuracy that is worse than the submission score possibly worse than other competitor submissions  \r\n",
      "\n",
      "\n",
      "Exactly reproducibility is required    John\n",
      "Only the lowest of the five entries count   Note for the milestone prize only one can be selected  \n",
      "Anthony If you were  per cent sure that somebody would spend  days in hospital in Y and  per cent sure they would spend  day in hospital than you might predict that they spend would    days in hospital   pham you do not have enough detail in the claims data to reproduce the DIH properly   Youve likely reproduced DIH from claims data as accurately as is possible    SirGuessalot thanks for the pointer   Its been added to our issue tracker   I must admit we have higher priority issues to tackle but well get there eventually  \r\n",
      " Just to keep you all in the loop the plan is to announce the milestone prize winners at OReillys Strataconf    Will let you know the exact date as soon as\r\n",
      " were told     Full milestone prize rankings will be released after the announcement is made   Provisional milestone prize winners will receive an email over the weekend   An announcement will be made at Strataconf on September \n",
      "   Correct   Congratulations team Market Makers and Willem Great coverage in the Wall Street Journal here\r\n",
      "   For those interested heres the footage from the award ceremony\r\n",
      "   Jason the anonymization guys have withheld this information intentionally to make the data set more secure   Sorry Hi all  \n",
      "HPN are currently looking for data scientists\n",
      "Heritage Provider Network  the sponsor of the Heritage Health Prize  is looking to hire data scientists to take its data and analytics department to the next level    If you are interested in healthcare join the largest physicians group in California\r\n",
      " and one of the largest in the United States and use your data mining skills to make a difference in the provision of health care to individuals throughout Southern California  \n",
      "If interested please send an email indicating your interest to \r\n",
      "datascientistheritagemed  com  \n",
      "Anthony  Does being a member of HPN mean you usually referred to an innetwork provider of say lab testing unless obviosuly it is some specialty unavailable Yes  Can you be a member of HPN and have govt sponsored insurance eg Medicare MediCal Yes for\r\n",
      " Medicare   I can follow up on MediCal if you like Have passed these questions onto HPN   Will respond as soon as I get an answer    \n",
      "We are aware that the rules havent been as clear as we might have liked   Please be reminded that\n",
      "\n",
      "you cannot sign up to Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and\r\n",
      "privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  \r\n",
      "\n",
      "Weve reached out to several teams about this issue   Please let us know ASAP if you have multiple accounts and weve not reached out to you  \n",
      " Entrants are welcome to use other data to develop and test their algorithms and entries until  UTC on April   if the data are i freely available to all other Entrants’ and i published or a link provided to the data in the “External Data” on this Forum topic within one  week of an entry submission using the other data    Entrants may not use any data other than the Data Sets after  UTC on April   without prior approval   On October  the judges in their sole discretion decide whether or not the documentation is sufficient taking account of the comments made on this forum   If they decide the documentation is not sufficient they can impel the winners to address their\r\n",
      " concerns in the seven days following October    If the winners are asked to resubmit participants have another  days from November  to raise any additional complaints   \n",
      "The judging panel are experienced academic reviewers\n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  Hi all\n",
      "We are in the process of liaising with the judges   Well report their decision as soon as we have everybodys feedback   Hi guys \n",
      "Glad you like   This dataset reminds me of the RTA data which was really popular  \n",
      "On the IP question when no rules are explicitly stated the Kaggle \r\n",
      "terms and conditions prevail   Specifically clause   \n",
      "By accepting an Award you agree to grant a license to the Competition Host to use any Model used or consulted by You in generating Your Entry in any way the Competition Host thinks fit   This license will be nonexclusive unless otherwise specified  \n",
      "Anthony libraryrandomForestsetwdCUsersantgoldbloomDropboxKaggleCompetitionsCredit Scoringtraining  read  csvcstraining  csvRF  randomForesttrainingctrainingSeriousDlqinyrs                   sampsizecdo  traceTRUEimportanceTRUEntreeforestTRUEtest  read  csvcstest  csvpred  data  framepredictRFtestcnamespred  SeriousDlqinyrswrite  csvpredfilesampleEntry  csv Alec setting the random seed is a good idea  \n",
      "Domcastro your hypothesis is correct    Youre correct   Shouldnt include headers    We have made a slight change to the Terms and Conditions adding   \n",
      "\n",
      "No individual or entity may share solutions or code for any competition or collaborate in any way with any other individual or entity that is participating as a separate individual or entity for the same competition   The foregoing shall not apply to any\r\n",
      " public communications such as forum participation or blog posts  \n",
      "\r\n",
      "We are also aware that the rules havent been as clear as we might have liked   From now on before you download the data for any new competition you will be reminded that\n",
      "\n",
      "you cannot sign up to Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and\n",
      "privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  \n",
      "\n",
      "Weve reached out to several teams about this issue   Please let us know ASAP if you have multiple accounts and weve not reached out to you   It is a mistake  were sorry for it but weve decided not to correct it because it might not be fair to some contestants if we change the data midstream  \n",
      "Shouldnt be too importantonly happened to  chunks  \n",
      "Its the same mistake that caused a few chunks to have some missing data within the chunks\r\n",
      "\r\n",
      "   Sounds like theres a thriving community in Melb which looks to have been the strongest performing city   Congrats all Donovan weve looked into this and it turns out that a bug with our process meant that we hadnt received the past few weeks of queries   Weve found your email and you will receive a response shortly as will others who slipped through the cracks   Apologies\r\n",
      " to you and others who have not received a response as a result of this error   Why does lower bound get mentioned so much more than upper bound Thanks for the thoughtful comments   \n",
      "First off as always we will not make retrospective changes to how we handle past competitions including this one   When issues like this come up we use it as an opportunity to evaluate how we might improve in the future  \n",
      "Internally our debate focused on three issues  \n",
      "\n",
      "recognition for those who completed stage one but not stage two \n",
      "achievements and how the competition appears on profiles th out of  looks more impressive than th out of   \n",
      "how points are handled  \n",
      "\n",
      "   recognition for those who completed stage one but not stage two\n",
      "We need to view the stage one leaderboard as having no weight if it gets a weight we incentivize overfitting or hand labeling for stage one  \n",
      "   achievements and how the competition appears on profiles\n",
      "If we did what Julian suggests and add stage one participants to the bottom of the stage two leaderboard we undermine our rankings by making it very easy for somebody to get an impressivelooking top  achievement by finishing th out of  with a naive submission   \n",
      "     how points are handled \n",
      "The one change we will make in future is the way points are handled   We will add a multiplier to the number of points for a twostage competition   We have not settled on a formula for doing this yet but commit to communicating it clearly in the rules of the next twostage competition  \n",
      "These are difficult issues but we think this approach strikes the best balance between competing considerations    Just a heads up that were still working through the winners solutions   Will need more time to before announcing the final results as official    Quick update We will announce the official results on Wednesday March  at am ET    Julian responded in the other thread \n",
      "   Hi all\n",
      "The results on the final leaderboard are now official   Congratulations to the winners and all involved   This is among the hardest and most ambitious competitions weve hosted   We couldnt be prouder of the results   \n",
      "The competition has received some press coverage with a chance of more to come\n",
      "  \n",
      "  \n",
      "Anthony Love it Interesting that for everyone other than Woodrow Wilson the names popularity monotonically declines over the course of the presidency   \n",
      "Dwight looks like it increases in popularity during WW which makes sense   One suggestion is to add years to the x axis label for each chart to make things like this easier to spot   I Tweeted this script and somebody replied asking \n",
      "Is there a corresponding drop in the name frequency of the losing presidential candidate right after the election   I was thinking another interesting extension would be to answer the question Whats most influential in determining baby name trends out of  \n",
      "\n",
      "Presidents and first ladies   \n",
      "Musician that was  for longest on the billboard charts in a given year  \n",
      "Best actoractress in the Oscars  \n",
      "Basketball football baseball MVPs  \n",
      "Nobel prize winner names  \n",
      "Time person of the year\n",
      "\n",
      "If nobody else tackles this I might try it   \n",
      "This builds off a conversation I had with my coworker Meghan who said itd be interesting to see whether Presidents or royal babies had a bigger impact on baby names   Nicely done and fun writing style   \n",
      "One additional conclusion is that real data is messy    Big Data Borat captures it best \n",
      "In Data Science  of time spent prepare data  of time spent complain about need for prepare data   \n",
      "   Ive played with PCA before but never association plots or MCA   Glad to see an example usage and be able to add these to my toolkit   Thank you\n",
      "For the association plots I assume the width of the box refers to the number of Tweets referring that that airline\n",
      "I assume    is the proportion of comovement explained by the first dimension   Is that correct Is it typical for the first dimension to explain so much of the comovement Any thoughts on how to interpret this dimension \n",
      "Small nit You might want to change res to reason   I initially assumed res stood for residual   And reduce the font size for the x axis label on plot    Thats the most interesting plot to me but its hard to read the labels because they overlap    From this page\n",
      "   This is a nice notebook   \n",
      "Suggestions\n",
      "\n",
      "To make this easier to follow for those who havent yet looked at the data itd be great if you added a section showing a few rows   Or possibly even a few exploratory chartshistograms   Perhaps after the Loading the data section   \n",
      "Itd also be nice to see the before and after you preprocess the data ie before and after the Using textmining to format our data section   \n",
      "Rename the Using textmining to format our data to something like Cleaning the data  \n",
      " Great I always look at the top rated notebooks before looking at the data because the notebooks usually give me a sense for whats in the data and what I could do with it    This is great   \n",
      "Im surprised North America is not higher for sugar   The sweetness of food was one of the first things I noticed when we moved to the US from Australia   Although it could be because a lot of the sweetness comes from high fructose corn syrup which is not captured    Its awesome Really nicely put together   Bluefool I thought you came out really well    Interesting how noisy the very early years are   I suspect the s data is very poor quality    Really nice script   \n",
      "Interesting to see the temperature uncertainty chart   Gives a nice visual of when the data starts becoming more reliable   \n",
      "Also nice idea to put dt into a variable importance plot to see its relative important   Obviously would have been more interesting if wed provided more data   \n",
      "One suggestion is to better label your plots   Theres some good stuff here but it stakes a while to figure out what each chart is showing I actually looked at your code to figure it out   I suspect this script will be more popular with some labels that make it easier to follow    Sven have you been able to figure out an interpretation of this chart Thanks   Itd be helpful if you labeled the charts and possibly added sub label pointing to your interpretation    It may not be useful for the reasons you mention but it looks nice    Would be cool to see the by city version   I assume you didnt use it initially because of the size of the data set BTW I assume red  hot Would be helpful to have a key    Is this a work in progress Or is there an error The charts are showing up blank for me   Cool   As someone who lives in San Francisco Im curious    Juanchaco this is neat but itd be easier to follow if you added a description between charts   At the moment Im scanning the codecomments to try and figure what each chart is showing    Ha   Id not known about this   For others    Akshay this script would be more interesting if you found a neat way to visualize temperature by country    Love this chart And the title is funny   \n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['clean_messages'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The messages are almost cleaned except there are certain words that are fused together like 'mindAnthony' and 'CommunityForum'. I will need to split those words apart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to split string by uppercase\n",
    "def split_uppercase(text):\n",
    "    return re.sub(r'([A-Z])', r' \\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg['clean_messages'] = forum_data_agg['clean_messages'].apply(split_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The public leaderboard is only indicative because competitors can use information on their score to get information on a portion of the test dataset    The final results are a quite different and b better reflect actual performance    Hi  Tanya  Kaggle will maintain a rating system    If you win but youre ineligible for prize money you will still get a strong rating   Anthony  Giovanni Thanks for your feedback    Using the forum to give feedback is a good idea    It allows others to see and comment on suggestions    We might set up a proper feedback forum but for the moment this topic will have to suffice    I also agree that the forum is a bit clunky    However we have a large list of feature requests and only limited resources for the moment  it might take us some time to address this    Apologies    I dont think the prize money in this competition is that relevant the prize is relatively small    Correct me if  Im wrong but  I think contestants are driven by intrinsic factors   A karma system that rewards forum posts is a good idea    Again apologies for any delay in implementing this there are lots of features on our to do list   Anthony  Manish thanks for the feedback    The site is hosted on an  Amazon  E C server on the east coast of  America   Its a fast server but the site has been more popular than we expected   Were currently working on speeding up the site by reducing the number database queries    We may have to implement auto scaling if the site keeps growing so rapidly    Anthony  Just made a change which should speed things up    Let me know if it has made a difference for you    Jonathan thanks for your feedback x    Were currently working on caching database queries    There are a lot of good suggestions here that well try before autoscaling     Colin the choice of scoring system was quite deliberate    Will the competition host considered using  Area  Under the  R O C  Curve where participants submit probabilities but  said that he deals with physicians who just want to know the proportion of predictions that are correct   Rajstennaj and  Colin were really pleased that you believe that theres value to the project    Let me know if there is anyway that we can help to facilitate a community    We did set up the general  Kaggle forum under  Community Forum\r\n",
      "  with such a community in mind  does it provide sufficient infrastructure  You are free to start any new threads on that forum   Regards Anthony  Thanks for participating in this competition    Ive attached the solution file to this post  \n",
      " U P D A T E  The solution is no longer attached but youre welcome to make submissions to this competition    Hi  Matt I believe that  Will the competition host is preparing a blog post that discusses some of the methods that people applied to this competition  based on the feedback we received    Is this the sort of thing you had in mind Anthony  Here are some papers that analyze  Eurovision voting patterns    You might find some of them helpful    Gatherer  Comparison of  Eurovision  Song  Contest  Simulation with  Actual  Results  Reveals  Shifting  Patterns of  Collusive  Voting  Alliances       Eurovision  Song  Contest  Is  Voting  Political or  Cultural  Ginburgh and  Noury     Suleman  Efstathiou and  Johnson     Eurovision  Song  Contest as a ‘ Friendship’  Network\r\n",
      " Dekker   \n",
      "  More research       enjoy Love thy  Neighbor  Love thy  Kin  Voting  Biases in the  Eurovision  Song  Contest   culture and religion  Explaining the bias in  Eurovision song contest voting    Hybrid  System  Approach to  Determine the  Ranking of a  Debutant  Country in  Eurovision    Eurovision    Judgment  Versus  Public  Opinion –  Evidence from the  Eurovision  Song  Contest    Here is the solution file for anybody interested     I accidentally deleted the following post made by another user    Im reposting it on their behalf Are there categorical andor binary variables in the data set  Other than the target variable  For instance  Variable Open in test data seems to have categories           If there are categorical variables do we get to know what the categories mean Thank  You  Just to clarify  the results page will show the leaderboard for all competitors regardless of whether they used future information or not    We will make an honourable mention to the leading competitor who doesnt use future information however their entry will be audited    Kaggle is currently developing a league table that ranks competitors    When it comes to this competition your position on the leaderboard which is indifferent to the use of future information will be what counts towards your  Kaggle ranking     I N F O R M S can offer an awardhonourable mention to those who dont use future data    However the  Kaggle leaderboard will not seperate those who use future information from those who dont    Given the way the competition has been setup theres no way to prevent people from using future data    Even if the winner presents a model that doesnt include future data they may have overfitted to replicate the predictions of a model that does include future data    In theory yes    The problem is that theres no way to be certain that the winner didnt use future information    Even when we check the winning model its possible they have used a model with future information to probe the test dataset    Sali  Mali has pointed out that there is an error in the  A U C\r\n",
      "calculation for entries with tied scores that is when two or more scores have\r\n",
      "precisely the same value    We will look at the problem over the next  hours and will rescore all entries    Apologies Anthony  The  A U C calculation glitch has been fixed and all entries have been rescored    Sali  Mali thanks again for pointing this out    Hi  P G    Not sure that  I fully understand the question    Are you referring to the situation where a classifier returns only  or  rather than a score or probability  Perhaps you can use an example to illustrate the question  Regards  Anthony  Hi  P G    You should give the score for all timestamps  a higher score means the instance is more likely to be a member of the positive     A U C measures your classifiers ability to split the classes  so you dont need to decide which scores predict positive instances  and which predict negative instances     Have  I addressed your concern  Vateesh thanks for sending the files    The files that you sent are actually different    I also had a look at your submissions and you have a few files with the same name but different numbers    Also  I was not able to replicate the problem as you describe it    Perhaps you can try again and let me know if youre still experiencing the error  Hi  Vess    This should not be a problem given the way submissions are stored    Seyhan the leaderboard portion of the test dataset is selected randomly    It is somewhat representative of the overall standings    Cole sorry for the slow response    In this competition all your submissions count    In future we will ask participants to nominate  submissions    Phil that is correct    You must remember that  Kaggle hopes to do more than just host fun competitions we want to help solve real problems    This is why were reluctant to force participants to choose just one model they may make a poor choice and the compettion host may end up with a suboptimal model    Our compromise position is to allow partipants to nominate five entries a feature which well roll out for future competitions     Phil number  is correct    Luck will play a part but  I suspect the test dataset is large enough to limit its impact     I agree in a competition like this one    But as mentioned above we want to host competitions that are useful as well as fun    An upcoming competition will require participants to predict who has prostate cancer based on  variables    In a competition like that it would be a shame to miss out on the best model    Requiring participants to nominate five submissions seems like a good compromise     Hi  Cole Apologies for the ambiguity    The time is as it appears on the competition summary page   adjusts according to the timezone on your computer clock so itll be  Saturday or  Sunday depending on your timezone   You can also see a countdown on the  Kaggle home page   Anthony   Durai apologies for the slow response    All up  countries were represented    Here is the list in order of most participants to fewest  United  States  United  Kingdom  Australia  Canada  Thailand  India  Germany  Spain  China  Netherlands  France  Italy  New  Zealand  South  Africa  Sweden  Argentina  Croatia  Ecuador  Greece  Indonesia  Iran  Ireland  Mexico  Poland  Portugal  Russia  Singapore  Turkey and  Ukraine  Ricardo you are correct   I gave the country list for the wrong competition    countries were represented  United  States  Colombia  India  Australia  United  Kingdom  France  Thailand  Canada  Germany  Argentina  Japan  Afghanistan  Albania  Austria  Belgium  Chile  China  Croatia  Ecuador  Finland  Greece  Hong  Kong  Iran  Poland  Portugal  Slovak  Republic  Venezuela  Sorry for the slow response   Ive been flat out with the new site launch    Below is the list of rows used to calculate the public leaderboard  Phil  I made an error in the ten per cent listed above try scoring with the following rows  Yuchun Apologies for this error    The public leaderboard is portion of the test dataset is actually the first  per cent because we hadnt implemented the code to select a random portion of the leaderboard yet    For info the reason we kept getting different  per cents is because the random seed in the database was set to zero which told our code to choose a random random seed   Anthony  Please use this topic to give us feedback    If youd rather do so in private email me at anthony  goldbloomkaggle  com    Thanks for the feedback   \r\n",
      "\r\n",
      "  What sort of features do you have in mind  Or can you point to a forum that you we should emulate  I just added a quick reply box to make the forum less clunky  \r\n",
      "\r\n",
      "  Great suggestion    I have put this on our extensive features to add list    Hi  Matt Thanks for the nice words and the suggestion    Ive posted the solution file    Good suggestion    Were open to ideas on how we can facilitate this    My thinking is the best thing to do is to implement a more functional forum which were doing    We can then encourage those who are still working on the problem to continue to use the competition forum as a way to collaborate    Use this topic to discuss any competitions you would like us to run    If you would rather contact me privately email anthony  goldbloomkaggle  com      out of   thats pretty impressive  Pity they didnt enter the  Kaggle comp    I think youre right  some competitions exhibit more regularities than others    Soccer may be a difficult sport to model    David this is a great suggestion    The  H I V competition shows that  Kagglers can do great things     My initial concern with any public dataset is that people can look up the answers    We would need researchers to withhold a small portion of the dataset for evaluation    I think the first step is to get in touch with those who set up the  Alzheimers project    It also makes sense to contact the  Michael  J  Fox foundation    If anybody has any connection to either of these projects please let me know   Otherwise  Ill keep you posted on any progress   Anthony  Hi  David I have written to the  Alzheimers  Disease  Neuroimaging  Initiative  A D N I and the  Michael  J  Fox  Foundation    I am scheduling meetings with both for  September    Will keep you posted on any progress    Can you put up a link to the datapaper you found Thanks again for the suggestion    Its great if we can use the power of this platform to tackle meaningful problems    Regards Anthony  Thanks for the nice wishes    Of course  Kaggle wouldnt exist without a brilliant community of data scientists who can solve really challenging problems    Looking forward to seeing what we can do in   This is the photo from the  Kaggle office    This lunch was one of the highlights of my six years of  Kaggle    Not something  I will forget in a hurry     Hi  Dirk The  Elo  Benchmark is based on the training dataset only    Having had many email conversations with  Jeff  I can tell you that the seed ratings matter a lot    Youll notice that  Jeff made two submissions for the  Elo benchmark  thats because hes refining his seeding method    I believe he plans to make a few more refinements   Jeff uses an iterative process to seed the rating system    For example he might start by giving everybody  and then letting  Elo run for  months    He then seeds  Elo with the  month ratings and runs  Elo again    He does several iterations of this   Does this help Anthony   Has anybody tried  Trueskill yet   probably a better starting point than  Elo    This blog post does a nice job of stepping through  Trueskill    Hi  John Have just confirmed with  Jeff methodologies will be shared publicly    Regards Anthony  The competition has been designed to make cheating really difficult    At the end of the competition the winners methodologies will be replicated to help ensure everything is above board    Hi  Matt The reason we prevent participants from submitting an unlimited number of times is because otherwisea our servers may not be able to handle all the traffic anda it would be easier to decode the portion of the test dataset thats used to calculate the public leaderboard    The technique you describe often referred to as cross validation is very sensible and we encourage others to use it    Anthony  Uri you raise an interesting point    However is five months long enough for somebodys rating to move enough for you to notice this  J P L a competition using internet chess data is a good suggestion    For interest the reason we are running the competition using top players is because  Elo ratings matter most for top players since it is used to determine who can play in which tournaments    Jase the score on the full dataset is calculated onthefly  so we actually know who is winning based on the full test dataset   Ron the submission that is performing best on the public leaderboard may be different from the submission that is performing best on the full test dataset    We dont link the best submission on the public leaderboard to the best overall submission so that participants dont become confusedconcerned if their scoreposition on the public leaderboard worsens   Leigh my thinking as well    In a tradeoff between having a veracious public leaderboard and a veracious end result  the end result is most important   Jeff good suggestion     Ive put together an  Excel sheet that might be helpful for cross validation    You paste your predictions for months  into column  G and it aggregates by player by month and then calculates the  R M S E    Hope its helpful   Anthony  Ben The evaluation method was chosen because  Jeff has found that scoring based individual games with  R M S E unduly favours systems that predict a draw    Mark  Glickman raised another issue   R M S E is better suited to normally distributed rather than binary  outcomes    So in order to use  R M S E aggregation is preferable    Of course we could have evaluated on a game by game basis using a different metric   My biggest problem with the current evaluation method is that counting a draw as half a win seems a little arbitrary    However in order to benchmark  Elo such an assumption is necessary    Mark and  Jeff argue that a draw is generally worth half a win  so this assumption isnt too problematic    Anyway hope this gives you some insight into our thinking    Regards Anthony  Jeff please correct me if  Im mistaken but  I believe systems that predict draws are favoured because a high proportion of games are draws at the top level  per cent in the training dataset    Of course you can do better  but a system that predicts    for every game will perform better than it should    Matt am interested in your thinking on this    Why  M A E over  M S E or  R M S E  Is it just that the metric is more intuitive or something subtler  Out of interest has anybody entered this competition using  Glicko  Glicko or  Chessmetrics  Are either of you happy to send me your unmodified  Glicko submission  It would be good to add a  Glicko  Benchmark team to the leaderboard    My email address is anthony  goldbloomkaggle  com   Would like to do the same for  Glicko and  Chessmetrics if anybody has tried those    I have also contacted  Ron about using his  Trueskill submission as a  Trueskill  Benchmark    Jase  I posted a link to your  Glicko code on the hints page    Its very good of you to share it    Im really surprised that  Glicko is performing worse than the  Elo benchmark    Do you think this is because  Jeff put lots of work into optimally seeding the  Elo benchmark  Or is  Glicko just not as good  Was just chatting to  Jeff    Time permitting he is going to benchmark some of these other systems    This way they will all be benchmarked on a consistent basis using the same seeding procedure and the same degree of tuning     Uri the correlation between the public leaderboard score and overall score is significantly higher now    Uri  Im reluctant to release confidence interval information because  I want to minimize the advantage to early submitters    Early submitters already have the small advantage of having seen their submissions on two different public leaderboards    By releasing confidence interval information  Im giving early submitters access to information that isnt available to later entrants    Jase aside from changing the size of the public leaderboard portion of the test dataset we also selected it more sensibly  so it better represents the overall test dataset     Hi  Edward    You will appear on the leaderboard as soon as you make your first submission    Hi  Edward    Try using examplesubmission  csv available at    and replacing the score column with your predicted scores    If youre still having trouble email the file to me anthony  goldbloomkaggle  com and  Ill have a look    Uri thanks for pointing out the problem    Were currently working on a big upgrade to the website the new site should be launched by the end of this month    The upgrade will involve a more functional forum    In the meantime  I will try and fix this problem    Anthony  Uri  Im not able to replicate the error either on the live site or on the development version    Can you let me know if you experience it again  Hi  Hans which post  Still cant replicate the bug       intermittent problems are really annoying  As mentioned were doing a massive site upgrade at the moment  so thats taking up the majority of our development time    How serious is the problem  Can we live with it for the next few weeks until we deploy  Kaggle     I would really like to be more active in the forums  looks like theres some lively discussion happening  Ive been flat out working on the site upgrade which is only a few weeks away from launch   Anyway  Id like to share a few thoughts on this discussion   First off there is quite a strong correlation between the public leaderboard and the overall standings    Secondly the lack of relationship between the  scores and the  scores might indicate overfitting    This may be the case if youre experiencing a larger improvement on the  dataset than the  dataset     On a related point  I notice that youre all performing very well    It could be that youve reached a local maximum i  e   the best possible score given the techniques youre using     Eric thanks for the feedback    Theres not really any reason to insist on a particular file extension    Were currently doing a big site upgrade so  Ill add this to our list of feature requests    Just to reemphasis  Jeffs point you should pay more attention to your cross validation than to the leaderboard    The leaderboard is calculated on a very small amount of data so it is only indicative    Phillipp Sorry for the delay in doing this  I havent had computer access over the last few days    The  Spearman correlation between public scores and overall scores is      I also calculated the correlation for different submission quintiles to make sure the relationship holds at the top it does Top                    Its also worth mentioning that the trouble participants are having  reflects realworld difficulties in formulating a chess rating system    This competition is not just a game but a genuine attempt to explore new approaches to rating chess players   Anthony  Out of interest why arent people rerunning old approaches that had previously been scored on the new cross validation dataset  Wil if you can get historical data from freechess  org possibly by agreeing to share the winning method with them wed be happy to host a comp here    This way you could specify that the winning method must be an instant gratification system    It would also result in a system thats tuned to lower ranked players    Thanks for pointing out the error    It has now been fixed    Apologies for any confusion    Uri makes a very good point    One way we could run a competition without knowing future matchups is to have participants rate every  player    Once we know the matchups we can infer predictions based on players ratings   The only downsides to this approach are    It doesnt allow for probabilistic predictions since there are many ways to map ratings into probabilities      We couldnt show a live leaderboard  which helps to motivate participants    Interested in others thoughts on this particularly the importance of a live leaderboard     Philipp  I dont fully understand your suggestion    Do you mind trying to explain it again  Possibly by reference to an example As a general principle tne problem with attempting to prevent people from using neural networks and the like is that participants use them anyway and then overfit other systems to replicate the neural networks results    I actually think that having neural networks et al in the competition is valuable    Even if they wont be implemented as rating systems they may have some benchmarking value    Assuming they predict most accurately they give a sense for what level of predictive accuracy is possible from any given dataset    As an aside if we require participants to submit ratings and dont \r\n",
      "give them access to the matchups that theyll be scored on this should\r\n",
      " force participants to create a rating system       shouldnt it\n",
      "  B T W  Jeff re    I have been and continue to be amazed by the level of participation so far     I had no idea so many people would participate    Congratulations on organising such a popular competition  P E W what criteria would you use to evaluate such systems B T W  I think youd be surprised at the proportion of the top  who are building rating systems     Ron this is fantastic  Looks like a sizable proportion of the black dots are sitting in a vertical line    Though  Im sure the  Elo  Benchmark would look much worse       Out of interest what software did you use to generate the viz ps    Im guessing the anomalies that this viz highlights e  g   that white is a smaller advantage for lower rated players could inform future versions of your rating system    Philipp thanks for your nice words  Hopefully having a more professional look and feel will help us attract interesting competitions with bigger prize pools     Philipp thanks for pointing out this bug    The error was only aesthetic  had been accidently hardcoded into the new theme    The platform was still only permitting two submissions    Anyway the error has been fixed     Unfortunately the movie isnt out in  Australia yet weve still got another week to wait    Jason theres a bug that prevents users seeing previous scores when they have longish technique descriptions    We are aware of the problem and will fix it as soon as we can   Diogo thanks for pointing out this error    We will setup pagination on the submission page shortly     Diogo thanks for pointing out this bug    Few minor teething problems with the new site  we should have them sorted out before long     Hi all Just to let you know that we have extended the deadline for this competition by just over a week    Both  Jeff and  I will be travellng around mid  November so wouldnt be able to deal with the competitions conclusion   Anhony  Apologies  I hadnt antipicated that this might be an unpopular move    I should have canvassed opinion first    If others also disapprove  I will changed back the deadline  Kaggle is not a dictatorship   The downside of changing back the deadline is that it limits our ability to generate publicity    This bothers me becausea   top performers deserve recognitionb   publicity for the competition is publicity for  Kaggle and more publicity  more members  more competitions andc   it lessens the chances of getting  F I D Es attention   A compromise might be to extend the previous deadline by three days to  Wednesday  November  when  Jeff is offline but  I am available    Thoughts  Hi  Philipp The  Chessbase articles were written by  Jeff he has a relationship with the editor    Jeff being away when the competition finishes means that its unlikely that  Chessbase will report on the end of the competition a real pity if we hope to grab  F I D Es attention    It is unfortunate that were both away when the competition ends  Obviously not foreseen when it launched otherwise we would have set a different deadline    Anthony  Jeff we must have posted simultaneously    You raise a good point    If  Philipp and others are  O K with the th then we should go with the compromise date    This would mean that  Ill be available to report preliminary results and should mean were ready to report the final results by the time you return    Preliminary will be unconfirmed results from the raw leaderboard    Final results after the top ten have all agreed to share their methodology    Ive changed the deadline to the th    As for  Uri breathing down your neck remember that the public leaderboard is only indicative and that the final standings may be different     Apologies  Uri and  L T  seems that any reply is redundant now    Also big thanks to all those who participated in forum discussions    You helped make this a far more interesting competition     This first chart how the leading score has changed on a daybyday basis    The red line shows the  Elo benchmark and the blue line shows the leading score    The  Elo benchmark was outperformed within  hours which is why its always above the best entry    Interesting to see some recent progress after a period of stagnation well done  Philipp    My guess is that any major improvement from this point on will be the result of somebody trying something quite different   This chart shows the number of daily entries    Higher early but seems to have stabilised at around  per day    Happy to put up other charts if people have requests     Philipp theres certainly a largish gap between the top five    Of course this is purely indicative    What really matters is the score difference on the final leaderboard         Philipp great suggesion  Weve got a stack of features we want to implement but  Ill put this in our long term wish list     I tried puting up a general forum for such discussions but found that it was very lightly used    Features in the pipeline include   fixing bugs or incomplete features on the new site   upgrades to  Kaggle infrastructure to allow us to score very large entries    Kaggle ranking system  an  Elo for  Kagglers based on  Microsoft  Trueskill   extended social networking features including live chat recent activity feeds           Philipps  competition analytics suggetion and possibly some other data viz tools Competitions in the pipeline include predicting social network connections predicting the likely success of grant applications for a large  Australian  University forecasting travel times for freeways in  Melbourne  Australia predicting prostate cancer from a high dimensional dataset subject to ethics approval diagnosing breast cancer from mammographics density images also subject to ethics approval Any other suggestions  Any thoughts on what our priorities ought to be  Jason L T are you thinking along the lines of karma points for participating in forum discussions  Or would you like the forums to be more of a  Q A with  Stackoverflow style ratings I like the idea of guest blog posts and community tutorials    After the chess competition ends some might be interested in posting details of their workflowmethodcode   L T the general forum has been taken down for the moment    When  I get a little time  I will attempt to revive it and start encouraging people to use it     Philipp  it may not matter that people only compete in a handful of competitions because each competition contains quite a lot of information    Unlike a single chess game participants are competing against many players    Regardless well do plenty of testing with  Trueskill before implementation    As for the points system points seem a little abitrary    I like the idea of ratings that account for the strength of a competitions participants    I tend to agree with your point on forum participation points    The  Stackoverflow approach seem like a nice way around the problem   There are lots of directions we could take  Kaggle    But for the moment were focused on competiitons     J C  I agree that those who enter early have an advantage    However the main source of advantage comes from the fact that they have had the opportunity to spend longer on the problem and try more things    Philipp the current leader has made  entries    If this competition took ternary scores loss win draw this would amount to  possible combinations  making  Phillips  entries  a drop in the ocean    In fact the test dataset is richer because participants predict the probability of victory   Nonetheless for future competitions we will ask participants to nominate five entries that count towards the final standings     P E W we are not requiring participants to guess but rather encouraging them to rely on their cross validation when determining which models to choose    The problem with allowing people to enter many times and try many parameter tweaks is that they are more likely to accidentally overfit on the test dataset    By this  I mean they are more likely to find a parameter tweak that works well on the test dataset but doesnt work as well for future chess games   On your second point you are correct to say that  I am worried about statistical guessing    The requirement that participants submit code does not obviate this concern because models can be overfitted once the answers are known    In the extreme case somebody could fit a decision tree that classifies every game perfectly if they know the answers    Showing the standings but not the scores makes statistical guessing only slightly more difficult because participants are close enough that the leaderboard ordering gives meaningful feedback on which guesses are better and which are worse   As an aside it seems that  I have failed to convey the message that the public leaderboard is purely indicative and that cross validation is  important    I would even go so far as to say that it may be problematic if the public leaderboard bears too close a resemblance to the overall standings     I like  Uris suggestion    It gets around the problem that  L T mentons while potentially encouraging people to try things beyond parameter tweaks    Couple of potential problems    A participant exhausts the submission limit and another entrant makes and shares a breakthrough eg the use of  Chessmetrics in this competition   Anybody who has exhausted the submission limit wont have the opportunity to build on the breakthrough    This seems less than ideal given that we want to get the best results possible      It might encourage people to make all their entries at the end so that they dont reveal the strength of their hand    What do others think  Philipp  Kaggle has been experiencing a massive lift in site visits and\r\n",
      " signups since the new site launched from  unique visitors to     This accounts for the increase in entries    Thanks everyone for making this an amazing competition Big congratulations to the winner  Outis    Also to the runner up  Jeremy  Howard who only joined the competition late in the piece and to  Martin  Reichert who finished third   Hopefully well get some of the top ten to tell us about their methods on the blog    In the meantime  I encourage you all to tell us a little about what you tried on the forums    Also for interest heres a chart that shows how the best score evolved over time    Rapid improvements initially but after a month progress stalled as participants approached the fronteir of what is possible from this dataset    I think  I can help with this  I dont give names just score combinationsscore publicscore                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Jeff can  I post the test labels on the forum  I only seem to have the aggregate solution on hand attached    Jeff do you have the game by game labels Edit looks like you posted a minute before me  Really nice feedback  very thought provoking    The  A P I suggestion is nice    It does seem that it would prevent people from using the future to predict the present    However the testtraining split is still necessary to prevent overfitting and we could still only give partial leaderboard feedback the  A P I doesnt secure against overfitted parameter tweaks    Also the  A P I approach would add new problems    models will take longer to run because of the delay in receiving data points   as you say it would add a huge load on  Kaggles servers  As for the problems you list here are my responses Predictions can’t use all available prior data since the test data doesn’t provide results This is necessary to ensure against overfitting    If all the data is used to calibrate a model its impossible to know if the model will fit future datasets as well     Limited training and test data creates too much variance between the public score and actual score The mistake made in the first competition was with the size of the public leaderboard portion of the test dataset my fault not  Jeffs    It was too small which lead to the low correlation between public and overall scores    For the  R T A competition we raised the proportion to ensure a stronger correlation    This proportion was calibrated after some testing of the correlation between the two parts of the test dataset    We intend to continue this practice going forward    Model parameters can’t be tuned because actual scores aren’t provided  If we allowed parameter feedback on the whole test dataset this would almost definitely lead to overfilling parameter tweaks that work on the test dataset but wont work for for future datasets    Number of submissions is severely limited because they are so large this will become a bigger problem as larger test datasets are created  I dont think more daily submissions are necessary because the majority of model building should be done with reference to a cross validation dataset    Leaderboard doesn’t reflect actual leaders Again this was my mistake    I made the public leaderboard portion of the test dataset too small    This is not a flaw with the general approach    Future data can be used to predict the past Jeff suggested a really nice solution to this test set includes some spurious games so that people can’t mine the test set for useful data about the future    These spurious games wouldnt be used in final evaluation    The  A P I also provides a really nice answer to this problem    Hi  Dirk Weve updated the data description  thanks for the pointer   \r\n",
      " The competition does require participants to forecast the next four observations    Weve updated the format of tourismdata  csv so that there is always a value in the last row    Regards  Anthony  Hi  Greg Apologies there was a bug that cut off the last  characters    The problem has been fixed but unfortunately the fix will only apply future submissions    Thanks for pointing this out and sorry for the inconvinience    Anthony  Greg thanks for pointing this out    Im currently traveling but will look into this over the weekend    Greg this problem has now been fixed    Thanks again for pointing it out    Dirk  I just changed the file posted on the  Data page to a unix format    Hope this solves the problem    Hi all Wondering why the benchmark is still leading when it is publically available     Have people had trouble replicating the authors methodology  Or is everybody trying their own approaches  Anthony  Something was amiss    There was an error in the data uploaded on  Kaggle  Kaggles fault not the authors   The changes are not particularly big so models that performed well on the previous dataset should continue to perform well    To give you the opportunity to rerun your models and make new entries we have extended the competition deadline by two weeks and lifted the daily submission limit to three per day    And  I believe  George intends to release the code used to create the benchmark    Apologies for the error  Dont hesitate to ask if you have any questions    Hi  Jesse You are correct this is instruction is wrong    The monthly columns  mm should be  lines long including the header and the quarterly columns qq should be  lines long   The examplesubmission  csv file available on the data page gives an example    Im at a conference today but will correct the instruction as soon as  I get the opportunity    Dirk  Ive changed the line break format    Let me know if this doesnt fix the problem     Tim  Kaggle is currently in the process of putting together a  league table which ranks participants based on competition performances   If you perform well in this competition it will count towards your  ranking     Hi  Markus  I can help out on the second part of your query  Ive posted some  P H P  A U C code on another forum post   software packages like  R have easy to use packages that calculate  A U C    Anthony  Steffen you can enter using a model coded in any language    John Drew  I presume those who enter using software other than  R are still eligible for prizes   Hi  Artem For the intuiton behind  A U C have a read of the evaluation page    Kaggle implementation of  A U C works roughly as follows    Sort submissions from highest to lowest    Goes down the sorted list and for each prediction plot a \r\n",
      "point on a graph that represents the cummulative percentage of class  A predictions against the \r\n",
      "cummulative percentage of class  B predictions       Join up all the points to form a \r\n",
      "curve    The  A U C is the area under this curve  \r\n",
      " H T  Phil  Brierley for this explanation   William no thresholding is required which is part of the beauty of  A U C    In fact given that the algorithm works by sorting participants make submissions containing any real number  higher means more confidence that the observation is of the positive class   Hope this response doesnt serve to confuse people   Anthony  Artem  Ive gone through the steps using your example data    Let me know if  Ive made any errors   The  Kaggle algorithm basically works as follows First order the data predicted            real      Then calculate the totals for each class in the totals  totals   Initialise the cumulative percentagespercentslast  percentslast   Iterate for each solutionsubmission pair counts  counts  counts  counts  percents  countstotalspercents   countstotalsrectangle  percentspercentslastpercentslasttriangle  percentspercentslastpercentspercentslast area  area  rectangle  trianglepercentslast  percentspercentslast  percents So in your example First submissionsolution paircounts  counts  percents    percents  triangle  rectangle   Cumulative area  percentslast    percentslast  counts    counts  percents    percents  triangle  rectangle     Cumulative area    percentslast    percentslast  counts    counts  percents    percents  triangle  rectangle   Cumulative area    percentslast    percentslast  counts    counts  percents  percents  triangle  rectangle   Cumulative area     A U C      Also heres  Kaggles  P H P code to calculate  A U Cprivate function  A U Csubmission solution         arraymultisortsubmission  S O R T N U M E R I C  S O R T D E S C solution        total  array A  B        foreach solution as s             if s                  total A            elseif s                  total B                nextissame           thispercent A             thispercent B             area             count A          count B          index           foreach submission as k             index              if nextissame                  lastpercent A  thispercent A                lastpercent B  thispercent B                        ifsolutionindex                   count A                else                 count B                           nextissame              ifindex  countsolution                   ifsubmissionindex   submissionindex                    nextissame                       mycount                                          if nextissame                   thispercent A  count A  total A                 thispercent B  count B  total B                 triangle  thispercent B  lastpercent B  thispercent A  lastpercent A                     rectangle  thispercent B  lastpercent B  lastpercent A                  A  rectangle  triangle                 area   A                              A U C  area         return  A U C  Thanks  B  Yang    The benefit of publishing code is that you get sensible suggestions in return     Hi  Jon Its a fixed  per cent chosen randomly   Anthony  Hi  Tamas As your results suggest the order does matter and the  I Ds dont    Anthony  You can email me the file if you like anthony  goldbloomkaggle  com    Id be happy to take a look at it     William thanks for the question       Teams are allowed to merge      One individual cannot be part of several teams our systems ensure this anyway        as long as somebody doesnt have multiple accounts   Agree that we should make this more explicit in the future    As for finding people who submit from multiple accounts we are actually in the process of implementing rules that alert us when it looks like this is happening    In the future for large prize money competitions we may look at verifying identities     Apologies  Will    I was on a plane and only just got your message    Will make the adjustment this afternoon   Id also like to congratulate the top teams and congratulate  Dirk for running an excellent competition     Thanks to everybody who participated and a big thanks to  Dirk for putting together a really nicely designed competition    The test labels are attached to this post    B  Yang first off congratulations again on a fantastic performance Your frustration is understandable but we cannot enforce rules that dont exist  what is common sense to some is not common sense to others    As  Jeremy points out in the  R T A competition the rules say  The winning entry has to be a general algorithm that can be implemented by the  R T A    An algorithm that involved looking up future answers could not be implemented by the  R T A     Hi  Nick Youre welcome to bring additional data as long as its publicly available   Anthony  This is something that should be dealt with on a case by case basis    If you find a dataset youd like to use ask on the forum and  Ill run it by the  R T A    For information  Im trying to get hold of some incident data    Will keep you posted on this     Vitalie the volumes data is used to calculate travel time  see this post for more info    Our priority at the moment is to get the incident loop error and route length data together    However  I can find out if this data can be made available if you think it might be useful    As  Dennis says itll be highly correlated with travel time and we obviously wouldnt release it for the blanked out times     Jeremy  I wasnt aware that public documents with traffic details were available    To the extent that any information is available for blanked out times this would most definitely be considered cheating   As for question   I am aware of this in fact the issue came up in another post    The rules state that the winning model must be implementable by the  R T A in order to be eligible for the prize    The averaging model passes this test    As an aside  I dont believe the temporal leakage invalidates the algorithms developed in this competition     Alexander to me this means that the algorithm can take a timestamp as an input and can generate forecasts for the next mins mins etc     Lee thanks for pointing this out   This post   post    Jose do you want me to ask if its permissible to use  N O A A data  If so are you asking about the data that  Brad mentions above  Jose and  Joseph just spoke to the  R T A about this    The answer is no because it might allow future weather conditions to be used to predict the present    Attached is some sample code that can be used to constuct an entry that generates a forecast based on the average travel time on a given route on a given day of the week at a given time    Mmm       file didnt attached    Heres the codephprh  fopen R T A Data  csv r  File to read fromwh  fopensample Historical  csv w  Write the entry to this filedatedefaulttimezoneset G M T  Purely to prevent the interpreter from raising a warningtime Stamp  array                               an  Array with the humping off pointsforecast Horizon  array forecast horizon in lots of  minutes e  g      minutes  minutes   hour    This is used for calculating the forecast time stampsforeach time Stamp as ts      foreach forecast Horizon as f          forecast Time Stamp  date N  H istrtotimetsf find day of week hour and minute that corresponds to each of the timestamps     row  while data  fgetcsvrh     F A L S E  loop through the datafile    if row     Write the header         col Count  countdata         for c c  col Count c             fwritewh   datac        fwritewhn        if  inarray date N  H i strtotimedataforecast Time Stamp    if the day of week hour and minute that corresponds to a forecast timestamp is found then save to an array called ts Array         for c c  countdata c             if  emptydatac  datac  x                  ts Arraydate N  H i strtotimedatac  datac            rowforeach time Stamp as ts      foreach forecast Horizon as f          fwritewh date Ymd  Histrtotimetsf        for c c  col Count   c             fwritewh    arraysumts Arraydate N  H istrtotimetsfccountts Arraydate N  H istrtotimetsfc writes the average for a given day of the week hour and minute to the submission file         fwritewhn    fcloserhfclosewh   This code does generate a sample entry    To use it a download the  P H P interpreterb create a file name xxx  php copy the code above and download the data files to the same directoryc run the command  P H P xxx  php  Youre correct  the future is used to predict the present    However  I dont think the temporal leakage invalidates the algorithms developed in this competition     Attached is some sample  Python code that generates forecasts based on the last known travel time    Im new to  Python so happy to hear any feedback on the code    File didnt attached    Heres the codeimport csvimport datetimerhopen R T A Data  csvr read in the data whopensample Naive Python  csvw create a file where the entry will be savedrh C S V  csv  readerrhtime Stamp                                 an  Array with the cutoff pointsforecast Horizon   forecast horizon in lots of  minutes e  g      minutes  minutes   hour    This is used for calculating the forecast time stampsrow   inialise the row variablefor data in rh C S V loop through the data    if row   if the first row then write the header        for j in rangelendata            wh  write  dataj        wh  writen    if data in time Stamp if the row is a cutoff point            for i in forecast Horizon for each forecast horizon write the cutoff travel time as the forecast the definition of  Naive                 date Str  strdatetime  datetimeintdataintdataintdataintdataintdata  datetime  timedeltai calculte the time stamp given the forecast horizin                 wh  writedate Str write the timestamp to the first column of the  C S V                for j in rangelendata                    wh  write  dataj write the cutoff travel time to the subsequent columns                 wh  writen    row  rh  closewh  close  Lee this is great  Dirk did the same thing with some  Python sample code  I wrote for the social networking competition    If you guys keep showing me how things can be done better  I may become a half decent coder    Toppy thanks for the pointer    A higher priority at the moment is to get forum attachments working again    Hi  Peter  Ill follow up in this    At the very least we should be able to provide information on the length of different routes    Anthony  Armin  I agree    Makes more sense for me compile this information once for everybody    Will try and get it done this week    Eleni just uploaded  Route Length Approx  csv which has approximate route length data     Martin  Dane is correct the information in  Route Length Approx  csv is in metres    So route  is approximately   km     Martin when  I open the file it shows  and     What application are you using Anthony  Dirk thanks for pointing this out    Ive written to the  R T A about this and they responded saying Indeed  our control room have confirmed significant increase in traffic volumes following the removal of the tolls    This has had an impact on the overall travel times across the  M   Something to be aware of when using the older data     Hi  Dennis  The  per cent doesnt count towards the final standings and is selected at random across the  timestamps and  routes    As for the  S M T P error its been fixed    The problem was the result of a flood of signups which caused  Google to shut off our mail server    Were now using our own mail server    Anthony  The number directly to the left of the team name is the teams position and the number to the right of the team name is the teams score or  Root  Mean  Squared  Error  R M S E     Apologies for the error its deciseconds not centiseconds  so  is    seconds    Ive fixed the description     Hi  Carlos  Unfortunately not    Clause   c in  Kaggles  Terms and  Conditions saysc            employees or agents of the  Competition  Host are not \r\n",
      "eligible to participate in any  Competition posted by the  Competition \r\n",
      " Host\r\n",
      "\t To answer the second question we would more information about the nature of the business and what your friend does   Anthony  Frank this is great  I particularly like the heatmap  is it possible to zoom Also itd be neat to see some animation on the  M map  showing how travel times evolve over the course of a dayweek dots getting bigger and smaller    Though  I suspect this might be a lot of work   Anthony   C does seem to be an expressive language    Im a  Linux user though so not inclined to pick it up     Daniel  Dennis is correct in saying that averaging the values leads to floating point numbers    The answers are integers but the  R M S E is calculated using floating point arithmetic     Alexander there is no truncation of floats     David  I believe that when loops the measuring device fail travel times are estimated    Im working towards putting together data on when travel time readings are suspect     Andrew good discovery    Ill pass the question onto the  R T A   Edit  Wouldnt it be obvious if they werent making the adjustment since peak traffic times would change  Paresh thanks for the thought provoking question    I agree with  Dennis  I am more interested in the time delay than the percentage delay    On a related matter we think it is more important to predict correctly when travel times are volatile e  g   before and after work    To favour models that predict more accurately during high volatility times we selected more high volatility cutoff points so youll notice more cutoff points during the morning and afternoon    Phil thanks for sharing this    Just got to find a  Windows machine to run it on         Aidan have asked the  R T A about this    This was the response    The cutoff is due to free flow conditions imposed by the system during data unavailability   Ive written again asking for a little more detail    Will post the response when it comes     I have some information on suspect loop readings that  Im working to release    This has information on when loop readings may be unreliable for various reasons    I dont yet know whether or not this will help with the free flow issue    Anyway  I will upload them as soon as  I can get it into a useful format   I suspect the reason the free flow times are different is because route lengths are different    Rob on your point about missing data it might be helpful if  I explain how  I put the files together    I received data in the following formatroute  I Dtimestamptravel time xxx xxx I transposed them into in the hope that theyd be more manageable    When timestamps were missing  I just filled in a blank row    Aaron another good question    Have also passed this on to the  R T A     Daniel and  Dennis are correct    Keep in mind that the  per cent is a random selection of the  that doesnt count towards the final standings which are calculated based on the other  per cent   burak the times in sample Entry  csv are the times you need to generate forecasts for    Theres more info on how the  cutoff points were selected in this forum post    Mmm       my message seems to have disappeared from the board    Anyway heres a repeat   Aaron the units are deciseconds   Nick actually its a hybrid approach    You can nominate five entries that count towards the final standings    You do this from the submissions page  the last five are chosen by default    At the end of the competition the best of your five nominated entries counts towards your final position    And  Nick on your new question the one of the five you nominate that scores best on the  per cent counts    The  per cent is meaningless as far as the final standings are concerned     The cutoff times are all between am and pm    They were selected using a simple formula that favoured high volatility cutoff times over low volatility cutoff times    So youll see more peak hour morning and afternoon cutoff times    The rationale behind this is that its more important to predict accurately during high volatility times so we want to favour models that do best at these times    That explains why the  R M S E is higher than for randomly chosen cutoff points    Thomas  I selected specific cutoff times randomly but chose timeday combinations that are volatile across the dataset    Rasmus apologies  I deleted the wrong post    Anyway you asked how travel times are measured    There are regularly spaced loops along the  M    These loops measure each cars speed and the number of cars that travel across the loop every three minutes  travel times are then calculated using a formula    The formula has been tested and calibrated using test cars that travel along the freeway and record their travel times     Benjamin once we get the incident data  I will put in a request for this data     Hassan the most important file is  R T A Data  csv    You can create a sample entry by   downloading  R T A Data  csv and create Historical  php attached to the same directory   navigating to that directory in the terminalcommand prompt   running php create Historical  php  This will create an entry based on a historical average for that timeday and is a good starting point    B J B very generous of you to upload a  Java code    Ive now enabled   java file uploads so you should be able to upload the file     Aaron you raise a good point    According to the route definitions  I have route  extends from loop  A to loop  A while route  extends from  A to  A so  should encompass all of     Denniss observation that sometimes  has longer throughput times than  is strange    Ill double check the definitions with the  R T A     Konstantin just uploaded  R T A Error  csv the is valid data    Its available on the data page    Mooma  I appreciate your frustration but sensor malfunctions  are part and parcel of dealing with realworld data    If we had the data ready at the outset we might have excluded failed sensors and downweighted the impact of partially failed sensors when evaluating predictions     Konstantin  Dennis is correct it is not safe to assume that there is no errors in the control data     Ahmed just got an answer from the  R T A on this    Heres the response The answer is  maybe    R T A would request that anyone wishing to use the data for further research purposes write to the  R T A and make their case  describing what they wish to do ie the purpose of the research and how they would use the data    The  R T A will consider each application on its merits    Let me know if youd like me to pass on the relevant email address    Im reluctant to do it in the forum but will offer an introduction to anybody who asks    Rob thanks for jumping in     Dielson good pick up    Dennis is correct  the date format doesnt matter    What is important is that you put the correct data in the correct cells    Many thanks to everyone for all your great activity on this fascinating problem  insightful questions and comments on the forum good early results on the leaderboard and interesting discussions  There have been a lot of questions about exactly what constitutes an acceptable model for the  R T A    So far my guidance on this matter has possibly been too fuzzy and  I hear a lot of you looking for more definite rules    Therefore we have come up with the following specific rule regarding the allowed model inputs  Your model can be of any form you like as long as it takes its input only from the following parameters  Time of prediction  Day of week  Is holiday  Month of year  Route number to be predicted  The time taken for route r for datetime t where  r is any route and t is any time less than the datetime being predicted for as  many routes and datetimes as you wish  The sensor accuracy measurements for any routes r and datestimes t defined as above  The estimated route distances as provided by  Kaggle To clarify the following are not permitted  The use of any data other than those provided by  Kaggle for this competition and the list of  N S W holidays    The time taken for any routes in the future compared to the prediction being made  your model can still be trained using all data as long as the resultant model only uses the inputs listed above   Furthermore the algorithm must not be encumbered by patent or other  I P issues and must be fully documented such that the  R T A can completely replicate it without relying on any black box libraries or systems    Hi  Alexander    No    Using full timestamp makes it possible for a model to implicitly incorporate external data and future data      You may also use holiday data extracted from the  P D F file that you linked to in order to get holiday information for previous years    However we will not be providing a file of this information directly      This is correct   Anthony  As  Jeremy  Howard pointed out earlier in this thread the key point that answers most of these questions is that the limitation is only on the functional form of the final model    More specifically  Xiaoshi  Lu  You can build your model  filtering aggregating etc  using all the datetime information you like    The final functional form that you end up with however should only use the predictors listed above    Mooma  The inputs listed include this  The time taken for route r for datetime t where  r is any route and t is any time less than the datetime being predicted for as many routes and datetimes as you wish    So what you ask is specifically allowed    Of course for you to create your input file which includes for example the time taken one hour earlier you will need to use the full datetime    However the resultant model will not directly use this  instead it will only use the time taken on that route as allowed by the rules    Alexander  Groznetsky  Imagine using a very flexible model neural net for instance which trains with all datetime info included in the input parameters    It might implicitly end up using the route times later in the day to predict those earlier  This is an example of how a model could be useless in practice even although it appears highly predictive on the competition data     Matthew    Using  G P L code is fine       The isholiday variable can be a direct input rather than a variable that is derived by reference to a timestamp       You contact me directly at anthony  goldbloomkaggle  com    Dennis you can use isspringbreak rather than isholiday     Nicholas a  Matlab solution is fine as long you dont include libraries that use patented or undocumentedsecret algorithms     Rafael  and  are fine    is also fine as long as the data is derived entirely from the time series as you say      Jose I notice that you are now on the leaderboard    It can take a few minutes before you show up    Anthony  David its really neat   For info it works in  Safari but the page videos are aligned a little strangely    The  In the  Money indicator is based on the public leaderboard only    It doesnt reveal anything about the final standings    Reginald please email your submission to anthony  goldbloomkaggle  com and  Ill have a look    Wu  Wei a route is made up of several loops    A figure of    means that  per cent of the loops in the given route are giving suspect readings     For anybody interest heres the actual solution    Nathaniel is right  the data is correct its just a problem with heading formatting    Will fix this shortly and reupload the data     Finally  fixed the headings    Just to reiterate all the data are correct  its just the capitalization in the headings that caused trouble   As for the inconsistent numbers of delimiters also fixed  my software package stopped printing delimiters when there were no more values or  N As in a row    Jack the country  of  birth issue is now fixed    Please download the latest version of the data     Attached is some  R code to create a  G L M entry for this competition    As always happy to hear feedback from others about how this could have been done more elegantly    Anthony person I Ds refers to all the columns that have investigator  I Ds e  g   column  has investigator  column  has investigator     Ignore the comment numerical values that should be      No    Towards the end of this competition you will be asked to nominate five entries that count towards the final result     P   V   Kiran it means that if your solution is implemented using a software package that is not available to the  University of  Melbourne it must be possible to translate your solution into a different packagelanguage     Just elaborate a little the types of solutions that cant be implemented are those that are encumbered by patents or other intellectual property restrictions    Nathaniel thanks for pointing this out    Definitely worth investigating    The  Number of  Successful  Grants and  Number of  Unsuccessful  Grants  fields dont change in the test dataset for obvious reasons    The journal citations also remain constant in the test dataset to prevent participants using the future to predict the past    Nathaniel  I have looked at the problem in some detail and have spoken to the  University of  Melbourne    They are looking into it and hope to have an answer for us tomorrow before they break for  Christmas     The university has spent the last two days on the problem    They suspect its an internal inconsistency in their database the figures are drawn from different parts of their database    Well have to wait until the end of the  Christmas break to get a final verdict     Deepak thanks for pointing this out    We will ask  the university about this as well    Unfortunately we cant expect an answer until early next year     The university has done an investigation and has found that the issue arises from an inconsistency in their database    Michelangelo truth is that you can submit any real number we suggest a number between  and  because of the convenient interpretation    A U C ranks your scores  the higher the score the more confident you are that the instance is a member of the positive class    I believe it refers to grants made when the researcher was at another university     Edith thanks for the feedback    We agree with your comments and we are working on making the terms more competitor friendly     Michelangelo the  per cent comes from the test dataset    Eu  Jin  Lok the sampling is done randomly     Hi  Greg The answers will be made available on the forum    I can ask whether the data can be used for publishing research if you like Kind  Regards Anthony   Hi  Greg and  Suhendar The university doesnt want the data to be used for any purpose other than for this competition   Anthony  Hi  Greg It would be nice if the dataset could be used for other work    However if we dont allow competition hosts to place restrictions on the use of their data then we wouldnt get access to it in the first place    Will post the solution file now   Regards Anthony  The solution file is attached to this post   Thanks all for participating Anthony   Apologies  I didnt clarify this with  Mahmoud before the launch but we have discussed this offline   This competition requires you to choose five entries that count towards the final result    To choose five entries visit your submissions page and click the star next to the relevant entry to select it    If you do not choose any entries your last five entries will be chosen by default    Hi all Submitting from multiple accounts is most definitely against the rules    We have done some analysis and found that it happens very rarely    However we are working to put the systems in place to identify and block those who attempt to do it   Kind  Regards Anthony  Harri Thanks for the thoughtful post    The  I J C N N people agree with you and have decided not to disqualify  Shen    As mentioned above  Kaggle will soon have the systems in place to detect multiple accounts in real time so that such issues dont arise   Anthony  I have sympathy for peoples frustrations    In this case the competition host decided that the results should stand  so we are facilitating their decision   Chris makes a good point about the rules being scattered throughout the site    We will be sure to address this in future competitions    We will also ensure that they are tightly enforced    For information a lot of effort has gone into framing the  Heritage  Health  Prize rules   Finally thanks for the feedback    Its discussions like this that will help us improve  Kaggle    Kaggle has received legal advice after the controversy surrounding this competition    We have been advised that it sets a dangerous precedent for us to ignore our own terms and conditions notably clause    preventing multiple signups    We have therefore acted in accordance with this clause disqualifying those who clearly submitted from multiple accounts   Thank you all for your patience on this issue and rest assured that we are working to ensure that it is not a feature of future competitions    The solution is attached   Thanks all for participating Anthony  Entries made before we fixed the leaderboard were scored incorrectly    I have now rescored the relevant entries    The error was the fault of  Kaggle and not the competition organizers    Apologies Anthony  Hi  Cerin Apologies for the errors    They all stemmed from the fact that the servers hard drive filled up    Ive cleared some space    For information were currently rewriting the entire site for the  Heritage  Health  Prize    You can expect the next version to be faster and include many more features   Thanks for your patience Anthony  Hi  Cerin Ali is right your entries will count towards the final standings    Anthony  Also covered by  Slate and  Forbes\n",
      "  \n",
      "  \n",
      "and the  Wall  Street  Journal a couple of weeks ago\n",
      "    And  Smarter  Planet\n",
      "    Dorofino\r\n",
      "\r\n",
      " Great idea  Forming a team is a really good way to learn   \r\n",
      "\r\n",
      " Are you affiliated with the  New  York  R  Users  Group  For info  Ive heard rumblings about them setting up a team   \r\n",
      "  \r\n",
      "\r\n",
      " Good luck with this\r\n",
      "\r\n",
      " Anthony  Apologies this was an error    Thanks for drawing our attention to it  \r\n",
      "\r\n",
      " The missing values are for those people who have been in hospital for more than two weeks    They should be replaced with a     You can either do this yourself or download the updated dataset   \r\n",
      "\r\n",
      " For information members who have in hospital for more than two weeks have been grouped for privacy reasons they are rare so may otherwise be identifiable    The implication of this grouping is that if you expect somebody to be in hospital for more than two weeks you should predict  days   \r\n",
      "\r\n",
      " This grouping should not have a big impact because\r\n",
      "a   members who are in hospital for more than two weeks are rare about one per cent of members\r\n",
      "b   the evaluation metric favors algorithms that accurately predict fewer days in hospital on the assumption that these are more preventable    Hi  Rich\r\n",
      "\r\n",
      " Just spoke to  H P N about this    For the moment they dont want to provide general guidance and ask that you make a request through the contact us form    Your request should detail the topic of your proposed research    Definitely worth making it clear that youre just looking to publish the method that you use to enter the competition   \r\n",
      "\r\n",
      " Anthony  Wgn the intention is not to rule out the publication of research    Ive passed on your message to  H P N and a clarification will be forthcoming  \r\n",
      " ashojaee the clarifications havent been made yet     Apologies for the missing values it was an error    You can either replace the missing values with  or download the updated data set   \r\n",
      "\r\n",
      " If youre interested in the reason for the missing data see\r\n",
      "    Y  Y  Y etc refer to different years    We havent revealed which years to help keep the data private     Agree    See the updated evaluation page\r\n",
      "    The years are sequential    We are not revealing what years  Yn refer to nor whether or not they refer to calendar years for data privacy reasons    Just to clarify when  Jeremy says we cleaned it as much as we can we didnt do much to the claims data on purpose    We figure it makes more sense for you to make your own cleaning assumptions rather than have us impose them on you   \r\n",
      "  The criteria was that somebody had to\r\n",
      "   make at least one claim in  Y \r\n",
      "   be eligible to make a claim in  Y\r\n",
      "\r\n",
      " Outliers have been removed from the dataset as well as those suffering from stigmatized diseases   \r\n",
      "  Not only are patients who died in  Y not in the dataset but patients who died in  Y are also not in the dataset because they didnt remain eligible to claim for the whole of  Y    rudychev received an answer from  H P N on this    A patient who visits a clinic outside the network should be captured in this dataset    Of course as  Jeremy keeps reiterating there is always a disconnect between reality and the contents of a database    Hi bacg\r\n",
      "\r\n",
      "    Days In Hospital refers to  Y the second year while the claims refer to  Y the first year  \r\n",
      "\r\n",
      "    Not everything that has a length of stay counts as a hospitalization    In fact you dont have enough detail in the  Claims table to calculate  Days In Hospital    The detail has been suppressed for privacy reasons  \r\n",
      "\r\n",
      " Anthony  Hi mbenjam\r\n",
      "\r\n",
      " We would have loved to release more detailed data but have to be mindful of data privacy   \r\n",
      "\r\n",
      " Anthony mgomari one issue we have to keep in mind are the tradeoffs in releasing data    For data privacy reasons  H P N have a granularity threshold which theyre not willing to breach    The data anonymization team represented by keleman in the forums are trying to release  C P T Codes probably at an aggregated level    Apparently its pretty lineball and releasng  Days In Hospital Y might put this in jeopardy    I describe the data privacy considerations like a waterbed you push down on one part of the bed and it creates a bulge somewhere else  \r\n",
      "\r\n",
      " After  May  youll be able to use  Days In Hospital Y and  Days In Hospital Y to predict  Days In Hospital Y  \r\n",
      "\r\n",
      "ogenex even if we release  Days In Hospital Y you wont be able to do a consistency check    Not all length of stays count as hospitalizations as calculated for this competition and you dont have enough detail in this dataset to work out which count and which dont    S S R C mapping  L O S to  D I H is impossible    Not every  L O S entry corresponds with a  D I H e  g  hospice stay  One reason somebody may have  D I H in y but no claims is if they werent eligible to claim in  Y in which case their  Y claims wouldve been removed    Have received advice from the  H P N lawyers    Im really sad to say that the answer is no on all accounts      The lawyers are taking a conservative stance on this issue    Apologies its really disappointing to have people ruled for this reason    flsdcom  I have a meeting with them in  minutes    I will be sure to raise this point    In response to ashashos original question  I have sought a reexamination of the issue    The  H P N lawyers explained that the reason for the hard line is that they have no way to verify that residency permits comply with  U S legislation    Im really sorry to say that theres not more  I can do   cybaea many thanks for a great discovery  After doing some digging weve discovered that the oddeven observation is an artifact of the cleaning procedure   \r\n",
      "\r\n",
      " We have worked out a remedy and it will be applied to the dataset that will be released on  May     In the meantime it shouldnt make a huge different to models that are currently being developed   boegel yes    On  May  we will be issuing significantly more data    Day In Hospital Y  csv will be changed then    Eu  Jin youve obviously not seen this\r\n",
      "   frankthedefalcos  com or the women who have been treated for erectile dysfunction    Tom  S F  Haines  Jeremy is not the author of the rules    He is merely trying his best to point people to the section that makes the rules as competitor friendly as possible given  H P Ns requirements  \n",
      " Also if you would like to publish your algorithm  I strongly encourage you to put in a research request using the  Contact  Us form    The decision to predict days in hospital was made to make the test dataset richer  so we can better sort out good algorithms from bad    The logarithm in the evaluation metric was chosen to favor models that predict short stays more accurately as these are assumed to be more readily preventable   \r\n",
      "\r\n",
      " As for the question of nefarious intentions  I can tell you what  I know about  Dr  Richard  Merkin the man behind the prize    He is a big philanthropist who devotes time and resources to funding scientific projects schools and the arts  \r\n",
      "\r\n",
      " In my opinion  H P N did not need to put up  million to get an amazing algorithm    Kaggle has found in its own competitions that with prizes as small as  or a chess  D V D participants approach the limit of whats possible on a dataset    In our communications with  H P N we have been told that the  million prize is an attempt to draw mass attention to this prize and the issue in general    Dr  Merkin wants to promote the potential for medical data mining in lowering healthcare costs    The prize also serves to introduce a large number of talented data scientists to medical data  \r\n",
      "\r\n",
      " Finally rest assured that  H P N are working hard behind the scenes to clarify the  I P issue   alexx the  H P N lawyers are working on a clarification    This will be released by the time entries can be made on  May       Hi  Drew\r\n",
      "\r\n",
      " It will be in place by  May  when entries are accepted    Anybody who accepted the existing rules will receive the notification via email   \r\n",
      "\r\n",
      " Anthony  The accuracy threshold will be announced when we release the full claims dataset on  May    \r\n",
      "  This is a sample of the final dataset but the final dataset is not in the  Terabyte range    To the best of my knowledge this dataset is on the larger side for medical datasets which tend to be quite small  \r\n",
      "\r\n",
      " This algorithm will not need to operate in a realtime environment and so there is no restriction on execution time      I want to reassure everyone that  H P N is working hard behind the scenes to clarify the  I P issue    It is not their intention to prevent people from using standard tools nor to discourage anyone from applying their innovative ideas to this problem   \n",
      " For background at  Mondays launch event  Dr  Richard  Merkin the man behind the prize spoke of the long tradition of innovation that has resulted from past prizes    He spoke of\n",
      "\n",
      "the  Longitude  Prize     apparently  Newton and  Galileo had attempted to solve this problem but the winner was a self educated clockmaker from  Yorkshire\n",
      " Napoleons food preservation prize  won by a confectioner and resulted in the invention of canned food\n",
      "the  Orteig  Prize to fly nonstop from  New  York to  Paris     won by the unlikely  Charles  Lindbergh   \n",
      "\n",
      " It is his hope that this prize will spur similar innovation to solve one of  Americas most vexing problems  \n",
      " We appreciate your patience while we await clarification  \n",
      " Kind  Regards\n",
      " Anthony  For those who dont know jphoward was  Kaggles most successful competitor before joining the team    His tutorial gives really clear explanations of the tools and techniques that made him such a successful competitor     Hi  Jim\r\n",
      "\r\n",
      " That is correct    For information the reason for the misnomer is that it was days when we sent it to the anonymization team but they had to group the days to ensure the required level of data privacy  \r\n",
      "\r\n",
      " Anthony  sciolist yes teams are required to publish publicly    mkarbowski as jphoward keeps pointing out theres often a massive disconnect between reality and the contents of a transactional database    See ejloks humorous post for even odder records\r\n",
      "  \r\n",
      "  We intentionally decided against cleaning the data so as not to impose our assumptions on participants     We want the forum to be tightly integrated into the site e  g   to be able to link to forum posts from profiles and vice versa    Y A F is the best    N E T forum software out there and integrating it into  Kaggle is more trouble than its worth   \r\n",
      "\r\n",
      " Also moserware is a brilliant programmer so its the type of thing he could put together in less than a week    D I H includes inpatient admissions and emergency room visits    As mentioned previously you dont have enough detail to calculate it from the claims table    Ralph H  Days In Hospital counts days not nights    So if  Days In Hospital is  then they have not been to the hospital at all    If they were in and out of the  E R then  Days In Hospital would be     Domcastro one of  Kaggles first suggestions was to remove the registration fee   \r\n",
      "\r\n",
      " For info the registration fee wasnt ever to raise money but to try and deter people who werent serious from downloading this sensitive data    Kaggle pointed out that anybody with malevolent intentions would probably still pay the modest registration fee so its effect would be to deter people who didnt think they had a chance of winning    Kaggle went on to argue that these people may also come from interesting backgrounds and may be the ones most likely to apply creative thinking to the problem    Realworld data is messy \r\n",
      "\r\n",
      " Well put up a data dictionary soon    Days In Hospital is calculated based on the  Length Of Stay variable    However you dont have enough detail to calculate  Days In Hospital from  Length Of Stay    quotedaveime\n",
      " Seriously  I understand the need for randomizing and anoymizing the data but unless they have some way to unrandomize it afterwards any algorithms we create will serve no real world application  \n",
      "quote\n",
      "daveime the data is messy not because its been peturbed but because its realworld data    Anonymization focused on generalizing again not peturbing      The the nineyear old pregnant males actually exist in the raw data  \n",
      " For info  Im told that this is one of the cleaner medical claims datasets around   mgomari the difference between  and  is counted as two days  \r\n",
      "\r\n",
      " Overlaps were accounted for so were not double counted    fjn  Pi does not have to be an integer    blonchar youre correct  H P N are limited in what it can release by the need to protect patient privacy    liveflow  I may be misunderstanding the question but the competition requires participants to use data from  Y  Y and  Y to predict  Y    No    Some  Y patients are no longer eligible in  Y    We still provide  Y patients who arent eligible in  Y because theyre useful to train on  \r\n",
      "  Dougie D every member listed in  Days In Hospital Y is eligible to claim in  Y  so if they have   D I H  they are  above    The same will apply for the members listed in  Days In Hospital Y and  Days In Hospital Y when we release those files    jesensky you will be able to use  Days In Hospital Y and  Days In Hospital Y as an input to  Days In Hospital Y  \r\n",
      "\r\n",
      " I like your thinking on the  U S E  O F  O T H E R  D A T A loophole if the answer had been no    Creative thinking    mgomari the answer to both questions is yes     Information  Man that is not the intent of the rule    The  H P N lawyers are working on clarifying this at the moment     No    Again for privacy reasons    irwint good pickup  thanks  Now fixed    gschmidt not sure if this answers your question but the geographic spread is limited to the area in which  H P N operates southern  California  I believe   \r\n",
      "\r\n",
      " As to whether patients change doctors on  May  youll have a few years worth of data so will be able to work this out    You will get some procedure code information in the  May  release    I understand the frustration but data privacy is a priority for  H P N   metaxab the competition was designed this way to replicate how the model might be used in real life    In a real life situation you wouldnt be able to predict hospitalization with contemporaneous claims     Days In Hospital Y is derived from the claims table where a hospital stay includes an inpatient stay or an emergency visit    Note you dont have enough information to calculate  Days In Hospital Y from the claims table     In this dataset missing  Pay Delay either means unknown or greater than     In the  May  release the anonymization team will topcode  Pay Delay so there will be fewer missing values and  will mean     For generating features  I recommend  S Q L Lite  though  My S Q L does the same thing    I know  Jeremy and  Jeff like  Cs  Linq    For building models  I use  R    The rules do not prohibit  Oracle  Data  Miner    rks we will post a sample entry with the rest of the data on  May    trezza and  R H M  Y contains data for a  period   trezza unfortunately not    The anonymization team have identified this as a data privacy risk    Hi  Allan\n",
      " Thats because some members have had claims suppressed    In release  coming soon well make it clear which members this applies to  \n",
      " Anthony   Hi  Domcastro  \n",
      "    Can  I use  R\n",
      " Yes\n",
      "    Can  I use  Weka\n",
      " Yes\n",
      "    Can  I use  Excel\n",
      " Yes\n",
      "    If  I organise the data in a novel way and just use a standard processing algorithm such as  Naive  Bayes is this  O K\n",
      " Yes  You must preserve the order in  Target  csv    Unfortunately not    Apologies for any inconvenience    Darragh its a list of all members in the dataset    Release  zip does supersede  Release  zip      Chris just heard back from the data anonymization team    Members have been renumbered    No   cacross  H P N had a granularity threshold that they wanted to remain below    Some  L O Ss had to be suppressed to achieve this target    If there is a blank  L O S and  Sup L O S is  then this is how it was when it came out of the  H P N dataset    If there is a blank\r\n",
      "  L O S and  Sup L O S is  then the  L O S has been suppressed    Hope that helps   mkwan you fill in the team wizard when you make your first entry    Team mergers will be granted at the organizers discretion    Chris R nice to see you competing in this    Sampling is random    Yes    Bernhard your interpretation sounds about right to me     We cant give you an  H P N benchmark because theyve not tackled this problem before    boegel  Days In Hospital Y contains members who made a claim in  Y and were eligible to make a claim in  Y    Days In Hospital Y contains members who made a claim in  Y and were eligible to make a claim in  Y    Similarly target  csv contains members who made\r\n",
      " a claim in  Y and were eligible to make a claim in  Y    To be eligible means to be an  H P N member regardless of whether or not a claim was made  \n",
      " Therefore the  members in  Days In Hospital Y are not missing from target  csv but rather didnt make a claim in  Y or werent eligible to make a claim in  Y    Therefore all members in target  csv were eligible to make a claim in  Y  so we have an answer\r\n",
      " for each of these members  \n",
      " J E S E N S K Y by my calculation  members appear in  Days In Hospital Y and  Days In Hospital Y but not  Days In Hospital Y perhaps you can confirm this figure    These members are missing from  Days In Hospital Y because they didnt make a claim in  Y despite\r\n",
      " being eligible  \n",
      " Apologies if we didnt communicate this effectively in the description pages    Pro Tester theres nothing in the raw data that distinguishes a death from a patient that leaves  H P N for another provider    Dan B youre right about the selection bias    But because  H P N are releasing almost no information on the members themselves theres nothing to model on for patients without claims    George there are  members in the dataset but you are only tested on  members    Thats because the extra  members arent eligible to claim in  Y or didnt claim in  Y    They have only been provided to help you train your model    Further to  Wills point those who followed the  Netflix  Prize will remember the jump from the  Simon  Funk discovery     is the maximum    Ive said this before but  I think \r\n",
      " Jeremys tutorial is really excellent although it is not focussed on  H H P    He is hoping to get the opportunity to do an  H H P tutorial in the next few months      Darragh  I passed your question onto  H P N    Heres the reply\n",
      " Is there a delay between the scheduling of the surgery and when it takes place   Yes     But that is just a matter of scheduling not something forced by the government     It would also of course depend on how urgent the surgery is    She will be added in the next release     The intent of that provision is to prevent the data being shared with those who have not agreed to the competition rules    Jeff was just referring to the measures he would take to ensure the data isnt accessible to others    Jose thanks for your diligence on this    Its difficult for us to give specific guidelines    Again  H P N is just trying to prevent the data from being accessible to those who havent accepted the rules    Jim its being assessed against  Y hospitalizations    Thanks  Dave    The data description has been fixed    Hi  Bobby\n",
      " Can you clarify what you mean by this  Are you asking if they are obliged to share their model if they finish in first place\n",
      " Anthony  I have checked with  H P N and a milestone prize winner can choose not to disclose their method but will not be eligible for the milestone prizes  \r\n",
      "     Correct  Hi  Willem\n",
      "\n",
      "to what extend the results have to be identical for example small differences in the random number generator may give different results although they should be similar\r\n",
      "\n",
      " They do need to be identical    You can give your random number generator a seed to make sure the resultls are the same each time  \n",
      "\n",
      "in how much time should the results be reproduceable my current best result is a mix of many models each may take minutes to hours to generate\r\n",
      "\n",
      " There is no rule about execution time     \n",
      "\n",
      "the algorithm should produce similar results on a new dataset this doesnt sound very realistic  I dont think there is any way to win this competition without optimizing for this specific dataset    Results on other datasets may be very bad with the\r\n",
      " given optimizations    Probably very good results can be produced by the same algorithm after some tuning but this is a process that requires a lot of knowledge about the used algorithms and a lot of time and patience  \r\n",
      "\n",
      " Not sure  I follow why this is an issue    Remember the  Milestone prize is judged in a portion of the test dataset that participants have not been given any feedback on    Perhaps  Im misunderstanding the concern  \n",
      " H T H\n",
      " Antthony  Regarding the requirement that solutions be identical\n",
      " Willem it would be better to have participants spend time on innovation rather than reproducibility however its important to have strict rules so that the competition remains as fair as possible  \n",
      " B  Yang with regards to the compiler issue we can address it if the issue arises    For example we might start by ensuring that the same compiler is used for verification  \n",
      " Sali  Mali it is exceptable to describe the algorithm and not how it is derived    We are seeking clarification from  H P N on the inconsistency that you describe    Apologies for the delay  \n",
      " Regarding the requirement that the algorithm perform similarly on a separate dataset\n",
      " This is best answered by explaining the rationale behind the rule    It is there to catch any cheating or blatant overfitting    If youre not blatantly overfitting then youre likely to be on safe ground     Hi all\n",
      " Not ignoring this thread    Just seeking clarification from  H P N on one issue   \n",
      " Anthony  Sorry for the delay on this was just clarifying some issues with  H P N  \n",
      "\n",
      " Is it inconsistent as  Sali  Mali pointed out in another thread to require documentation of the winning algorithms be publicly disclosed to all competitors given  Rule   Entrant  Representations   It seems that this disclosure will encourage other competitors\r\n",
      " to use aspects of the winning  Prediction  Algorithm which cause violation directly or otherwise of i  iii and possibly iv of that  Rule  \r\n",
      "\n",
      " Rule  does not apply to the extent that it prevents a competitors other than a milestone prizewinner from using code published by a milestone prizewinner in accordance with competition rules and b a milestone prizewinner from competing subsequently\r\n",
      " in the competition using code for which it was awarded the milestone prize  \n",
      "\n",
      " Can you clarify that code libraries and software specifications are not required to be publicly disclosed to competitors   These materials and intellectual property appear to be referenced separately from  Prediction  Algorithm and documentation  \r\n",
      "\n",
      "\n",
      " Chris correctly points to  Jeremys response in an earlier forum post\n",
      "“ Only the paper describing the algorithm will be posted publicly    The paper must fully describe the algorithm    If other competitors find that its missing key information or doesnt behave as advertised then they can appeal    The idea of course is that\r\n",
      " progress prize winners will fully share the results theyve used to that point so that all competitors can benefit for the remainder of the comp and so that the overall outcome for health care is improved  ”\n",
      "\n",
      "\n",
      "\n",
      " Will  Kaggle or  Heritage have a moderation or appeals process for handling competitor complaints   From the winning entrants pointofview they would not want to be forced through the review process to allow backdoor answers to code and libraries which\r\n",
      " accelerate a competitors integration of the winning solution   \n",
      "\n",
      " Kaggle and the  H H P judging panel will moderate the appeals process  \n",
      "\n",
      "\n",
      " Can you comment on the spirit and fairness of the public disclosure of the  Prediction  Algorithm documentation and its impact on competitiveness   In particular if the documentation truly does meet the requirement of enabling a skilled computer science\r\n",
      " practitioner to reproduce the winning result then this places the winning team at an unfair disadavantage all competitors will have access to their algorithms and research in addition to the winning algorithm  \r\n",
      "\n",
      "\n",
      " This rule is in place to promote collaboration    Those who would prefer not to share can opt out of the prize  \n",
      "\n",
      "\n",
      " Can you provide more detailed clarification on the level of documentation required by conditional milestone winners   The guideline provided by the rules would cover a range of details and description spanning from lecture notes to detailed tutorial\r\n",
      " to whitepaper to conference paper etc   \n",
      "\n",
      " Hopefully this was adequately dealt with in  Jeremys response requoted above    Let me know if further clarification is needed  \n",
      "\n",
      "\n",
      " Can you comment on the reproducibility requirement   For example it is possible to construct algorithms with stochastic elements that may not be precisely reproducible even using the same random seed is it sufficient for these algorithms to reproduce\r\n",
      " the submission approximately   What if they dont reproduce exactly or reproduce at a prediction accuracy that is worse than the submission score possibly worse than other competitor submissions  \r\n",
      "\n",
      "\n",
      " Exactly reproducibility is required     John\n",
      " Only the lowest of the five entries count    Note for the milestone prize only one can be selected  \n",
      " Anthony  If you were  per cent sure that somebody would spend  days in hospital in  Y and  per cent sure they would spend  day in hospital than you might predict that they spend would    days in hospital   pham you do not have enough detail in the claims data to reproduce the  D I H properly    Youve likely reproduced  D I H from claims data as accurately as is possible     Sir Guessalot thanks for the pointer    Its been added to our issue tracker    I must admit we have higher priority issues to tackle but well get there eventually  \r\n",
      "  Just to keep you all in the loop the plan is to announce the milestone prize winners at  O Reillys  Strataconf     Will let you know the exact date as soon as\r\n",
      " were told      Full milestone prize rankings will be released after the announcement is made    Provisional milestone prize winners will receive an email over the weekend    An announcement will be made at  Strataconf on  September \n",
      "    Correct    Congratulations team  Market  Makers and  Willem  Great coverage in the  Wall  Street  Journal here\r\n",
      "    For those interested heres the footage from the award ceremony\r\n",
      "    Jason the anonymization guys have withheld this information intentionally to make the data set more secure    Sorry  Hi all  \n",
      " H P N are currently looking for data scientists\n",
      " Heritage  Provider  Network  the sponsor of the  Heritage  Health  Prize  is looking to hire data scientists to take its data and analytics department to the next level     If you are interested in healthcare join the largest physicians group in  California\r\n",
      " and one of the largest in the  United  States and use your data mining skills to make a difference in the provision of health care to individuals throughout  Southern  California  \n",
      " If interested please send an email indicating your interest to \r\n",
      "datascientistheritagemed  com  \n",
      " Anthony   Does being a member of  H P N mean you usually referred to an innetwork provider of say lab testing unless obviosuly it is some specialty unavailable  Yes   Can you be a member of  H P N and have govt sponsored insurance eg  Medicare  Medi Cal  Yes for\r\n",
      "  Medicare    I can follow up on  Medi Cal if you like  Have passed these questions onto  H P N    Will respond as soon as  I get an answer    \n",
      " We are aware that the rules havent been as clear as we might have liked    Please be reminded that\n",
      "\n",
      "you cannot sign up to  Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and\r\n",
      "privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  \r\n",
      "\n",
      " Weve reached out to several teams about this issue    Please let us know  A S A P if you have multiple accounts and weve not reached out to you  \n",
      "  Entrants are welcome to use other data to develop and test their algorithms and entries until   U T C on  April   if the data are i freely available to all other  Entrants’ and i published or a link provided to the data in the “ External  Data” on this  Forum topic within one  week of an entry submission using the other data     Entrants may not use any data other than the  Data  Sets after   U T C on  April   without prior approval    On  October  the judges in their sole discretion decide whether or not the documentation is sufficient taking account of the comments made on this forum    If they decide the documentation is not sufficient they can impel the winners to address their\r\n",
      " concerns in the seven days following  October     If the winners are asked to resubmit participants have another  days from  November  to raise any additional complaints   \n",
      " The judging panel are experienced academic reviewers\n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   Hi all\n",
      " We are in the process of liaising with the judges    Well report their decision as soon as we have everybodys feedback    Hi guys \n",
      " Glad you like    This dataset reminds me of the  R T A data which was really popular  \n",
      " On the  I P question when no rules are explicitly stated the  Kaggle \r\n",
      "terms and conditions prevail    Specifically clause   \n",
      " By accepting an  Award you agree to grant a license to the  Competition  Host to use any  Model used or consulted by  You in generating  Your  Entry in any way the  Competition  Host thinks fit    This license will be nonexclusive unless otherwise specified  \n",
      " Anthony libraryrandom Forestsetwd C Usersantgoldbloom Dropbox Kaggle Competitions Credit  Scoringtraining  read  csvcstraining  csv R F  random Foresttrainingctraining Serious Dlqinyrs                   sampsizecdo  trace T R U Eimportance T R U Entreeforest T R U Etest  read  csvcstest  csvpred  data  framepredict R Ftestcnamespred   Serious Dlqinyrswrite  csvpredfilesample Entry  csv  Alec setting the random seed is a good idea  \n",
      " Domcastro your hypothesis is correct     Youre correct    Shouldnt include headers     We have made a slight change to the  Terms and  Conditions adding   \n",
      "\n",
      " No individual or entity may share solutions or code for any competition or collaborate in any way with any other individual or entity that is participating as a separate individual or entity for the same competition    The foregoing shall not apply to any\r\n",
      " public communications such as forum participation or blog posts  \n",
      "\r\n",
      " We are also aware that the rules havent been as clear as we might have liked    From now on before you download the data for any new competition you will be reminded that\n",
      "\n",
      "you cannot sign up to  Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and\n",
      "privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  \n",
      "\n",
      " Weve reached out to several teams about this issue    Please let us know  A S A P if you have multiple accounts and weve not reached out to you    It is a mistake  were sorry for it but weve decided not to correct it because it might not be fair to some contestants if we change the data midstream  \n",
      " Shouldnt be too importantonly happened to  chunks  \n",
      " Its the same mistake that caused a few chunks to have some missing data within the chunks\r\n",
      "\r\n",
      "    Sounds like theres a thriving community in  Melb which looks to have been the strongest performing city    Congrats all  Donovan weve looked into this and it turns out that a bug with our process meant that we hadnt received the past few weeks of queries    Weve found your email and you will receive a response shortly as will others who slipped through the cracks    Apologies\r\n",
      " to you and others who have not received a response as a result of this error    Why does lower bound get mentioned so much more than upper bound  Thanks for the thoughtful comments   \n",
      " First off as always we will not make retrospective changes to how we handle past competitions including this one    When issues like this come up we use it as an opportunity to evaluate how we might improve in the future  \n",
      " Internally our debate focused on three issues  \n",
      "\n",
      "recognition for those who completed stage one but not stage two \n",
      "achievements and how the competition appears on profiles th out of  looks more impressive than th out of   \n",
      "how points are handled  \n",
      "\n",
      "   recognition for those who completed stage one but not stage two\n",
      " We need to view the stage one leaderboard as having no weight if it gets a weight we incentivize overfitting or hand labeling for stage one  \n",
      "   achievements and how the competition appears on profiles\n",
      " If we did what  Julian suggests and add stage one participants to the bottom of the stage two leaderboard we undermine our rankings by making it very easy for somebody to get an impressivelooking top  achievement by finishing th out of  with a naive submission   \n",
      "     how points are handled \n",
      " The one change we will make in future is the way points are handled    We will add a multiplier to the number of points for a twostage competition    We have not settled on a formula for doing this yet but commit to communicating it clearly in the rules of the next twostage competition  \n",
      " These are difficult issues but we think this approach strikes the best balance between competing considerations     Just a heads up that were still working through the winners solutions    Will need more time to before announcing the final results as official     Quick update  We will announce the official results on  Wednesday  March  at am  E T     Julian responded in the other thread \n",
      "    Hi all\n",
      " The results on the final leaderboard are now official    Congratulations to the winners and all involved    This is among the hardest and most ambitious competitions weve hosted    We couldnt be prouder of the results   \n",
      " The competition has received some press coverage with a chance of more to come\n",
      "  \n",
      "  \n",
      " Anthony  Love it  Interesting that for everyone other than  Woodrow  Wilson the names popularity monotonically declines over the course of the presidency   \n",
      " Dwight looks like it increases in popularity during  W W which makes sense    One suggestion is to add years to the x axis label for each chart to make things like this easier to spot    I  Tweeted this script and somebody replied asking \n",
      " Is there a corresponding drop in the name frequency of the losing presidential candidate right after the election    I was thinking another interesting extension would be to answer the question  Whats most influential in determining baby name trends out of  \n",
      "\n",
      " Presidents and first ladies   \n",
      " Musician that was  for longest on the billboard charts in a given year  \n",
      " Best actoractress in the  Oscars  \n",
      " Basketball football baseball  M V Ps  \n",
      " Nobel prize winner names  \n",
      " Time person of the year\n",
      "\n",
      " If nobody else tackles this  I might try it   \n",
      " This builds off a conversation  I had with my coworker  Meghan who said itd be interesting to see whether  Presidents or royal babies had a bigger impact on baby names    Nicely done and fun writing style   \n",
      " One additional conclusion is that real data is messy     Big  Data  Borat captures it best \n",
      " In  Data  Science  of time spent prepare data  of time spent complain about need for prepare data   \n",
      "    Ive played with  P C A before but never association plots or  M C A    Glad to see an example usage and be able to add these to my toolkit    Thank you\n",
      " For the association plots  I assume the width of the box refers to the number of  Tweets referring that that airline\n",
      " I assume    is the proportion of comovement explained by the first dimension    Is that correct  Is it typical for the first dimension to explain so much of the comovement  Any thoughts on how to interpret this dimension \n",
      " Small nit  You might want to change res to reason    I initially assumed res stood for residual    And reduce the font size for the x axis label on plot     Thats the most interesting plot to me but its hard to read the labels because they overlap     From this page\n",
      "    This is a nice notebook   \n",
      " Suggestions\n",
      "\n",
      " To make this easier to follow for those who havent yet looked at the data itd be great if you added a section showing a few rows    Or possibly even a few exploratory chartshistograms    Perhaps after the  Loading the data section   \n",
      " Itd also be nice to see the before and after you preprocess the data ie before and after the  Using textmining to format our data section   \n",
      " Rename the  Using textmining to format our data to something like  Cleaning the data  \n",
      "  Great  I always look at the top rated notebooks before looking at the data because the notebooks usually give me a sense for whats in the data and what  I could do with it     This is great   \n",
      " Im surprised  North  America is not higher for sugar    The sweetness of food was one of the first things  I noticed when we moved to the  U S from  Australia    Although it could be because a lot of the sweetness comes from high fructose corn syrup which is not captured     Its awesome  Really nicely put together    Bluefool  I thought you came out really well     Interesting how noisy the very early years are    I suspect the s data is very poor quality     Really nice script   \n",
      " Interesting to see the temperature uncertainty chart    Gives a nice visual of when the data starts becoming more reliable   \n",
      " Also nice idea to put dt into a variable importance plot to see its relative important    Obviously would have been more interesting if wed provided more data   \n",
      " One suggestion is to better label your plots    Theres some good stuff here but it stakes a while to figure out what each chart is showing  I actually looked at your code to figure it out    I suspect this script will be more popular with some labels that make it easier to follow     Sven have you been able to figure out an interpretation of this chart  Thanks    Itd be helpful if you labeled the charts and possibly added sub label pointing to your interpretation     It may not be useful for the reasons you mention but it looks nice     Would be cool to see the by city version    I assume you didnt use it initially because of the size of the data set  B T W  I assume red  hot  Would be helpful to have a key     Is this a work in progress  Or is there an error  The charts are showing up blank for me    Cool    As someone who lives in  San  Francisco  Im curious     Juanchaco this is neat but itd be easier to follow if you added a description between charts    At the moment  Im scanning the codecomments to try and figure what each chart is showing     Ha    Id not known about this    For others     Akshay this script would be more interesting if you found a neat way to visualize temperature by country     Love this chart  And the title is funny   \n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['clean_messages'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much better now. I'll stem the words next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to stem words\n",
    "def stem_text(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words_list = text.split()\n",
    "    new_list = []\n",
    "    for i in words_list:\n",
    "        word = stemmer.stem(i)\n",
    "        new_list.append(word)\n",
    "        \n",
    "    words = new_list\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['clean_posts'] = train_data['clean_posts'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg['clean_messages'] = forum_data_agg['clean_messages'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I cleaned all the training and forum text data. Now, I'll build my pipeline and test a few different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
