{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project, I try to optimize a supervised machine learning algorithm to predict Myers-Briggs personality profiles of Kaggle forum users based on the [(MBTI) Myers-Briggs Personality Type Dataset](https://www.kaggle.com/datasnaek/mbti-type) on Kaggle. \n",
    "\n",
    "This notebook was forked from [this](https://www.kaggle.com/lbronchal/what-s-the-personality-of-kaggle-users) Kaggle kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from time import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../mbti-project/mbti_1.csv')\n",
    "user_data = pd.read_csv('../mbti-project/Users.csv')\n",
    "forum_data = pd.read_csv('../mbti-project/ForumMessages.csv')\n",
    "mbti = {'I':'Introversion', 'E':'Extroversion', 'N':'Intuition', \n",
    "        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling', \n",
    "        'J':'Judging', 'P': 'Perceiving'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of personality profile types in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAENCAYAAABO7NDIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f97f03320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_count = train_data['type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(type_count.index, type_count.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Types', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The personality types seems to be heavily skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there are missing values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forum Missing Values:\n",
      "Id                           0\n",
      "ForumTopicId                 0\n",
      "AuthorUserId                 0\n",
      "PostDate                     0\n",
      "Message                    581\n",
      "ReplyToForumMessageId    70620\n",
      "TopicMessagePosition         0\n",
      "RawMarkdown              60694\n",
      "Score                        0\n",
      "FlaggedCount                 0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "User Missing Values:\n",
      "Id                     0\n",
      "UserName          267200\n",
      "DisplayName           21\n",
      "RegisterDate           0\n",
      "Points            510138\n",
      "Ranking           510138\n",
      "Tier                   0\n",
      "HighestRanking    510132\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Training Missing Values:\n",
      "type     0\n",
      "posts    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Forum Missing Values:')\n",
    "print(forum_data.isnull().sum())\n",
    "print('\\n')\n",
    "print('User Missing Values:')\n",
    "print(user_data.isnull().sum())\n",
    "print('\\n')\n",
    "print('Training Missing Values:')\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values for `forum_data['Message']` with blank space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forum Missing Values:\n",
      "Id                           0\n",
      "ForumTopicId                 0\n",
      "AuthorUserId                 0\n",
      "PostDate                     0\n",
      "Message                      0\n",
      "ReplyToForumMessageId    70620\n",
      "TopicMessagePosition         0\n",
      "RawMarkdown              60694\n",
      "Score                        0\n",
      "FlaggedCount                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "forum_data['Message'] = forum_data['Message'].fillna('')\n",
    "\n",
    "print('Forum Missing Values:')\n",
    "print(forum_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258      1459\n",
      "993       1353\n",
      "2242      1191\n",
      "59561     1011\n",
      "5309       913\n",
      "114978     699\n",
      "1828       679\n",
      "100236     604\n",
      "6696       510\n",
      "24266      499\n",
      "317687     488\n",
      "75837      451\n",
      "2505       436\n",
      "140793     390\n",
      "368        377\n",
      "23831      376\n",
      "3716       375\n",
      "263583     362\n",
      "111776     341\n",
      "147404     323\n",
      "1335       320\n",
      "4398       315\n",
      "37404      310\n",
      "111640     284\n",
      "102203     264\n",
      "381        263\n",
      "2194       253\n",
      "10035      239\n",
      "2036       239\n",
      "131576     237\n",
      "          ... \n",
      "138735       1\n",
      "2839         1\n",
      "201524       1\n",
      "217916       1\n",
      "111072       1\n",
      "405968       1\n",
      "80305        1\n",
      "391593       1\n",
      "231655       1\n",
      "116975       1\n",
      "80113        1\n",
      "170245       1\n",
      "49422        1\n",
      "55030        1\n",
      "10515        1\n",
      "31001        1\n",
      "233764       1\n",
      "366885       1\n",
      "397037       1\n",
      "217404       1\n",
      "145130       1\n",
      "158043       1\n",
      "637281       1\n",
      "51599        1\n",
      "405904       1\n",
      "358082       1\n",
      "155303       1\n",
      "131478       1\n",
      "389544       1\n",
      "14329        1\n",
      "Name: AuthorUserId, Length: 13340, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(forum_data['AuthorUserId'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a given user might have posted more than once on Kaggle forums, I will group all `'Message'` together for each unique user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg = forum_data.groupby('AuthorUserId')['Message'].agg(lambda col: ' '.join(col)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71677     1\n",
      "151016    1\n",
      "494738    1\n",
      "2708      1\n",
      "126473    1\n",
      "121486    1\n",
      "19084     1\n",
      "27272     1\n",
      "605816    1\n",
      "33413     1\n",
      "43648     1\n",
      "643711    1\n",
      "518776    1\n",
      "137846    1\n",
      "45683     1\n",
      "47730     1\n",
      "43632     1\n",
      "348783    1\n",
      "62059     1\n",
      "326250    1\n",
      "21284     1\n",
      "27240     1\n",
      "397927    1\n",
      "203366    1\n",
      "33381     1\n",
      "23198     1\n",
      "144035    1\n",
      "129706    1\n",
      "105158    1\n",
      "552523    1\n",
      "         ..\n",
      "406442    1\n",
      "277709    1\n",
      "13516     1\n",
      "595094    1\n",
      "449793    1\n",
      "617783    1\n",
      "58666     1\n",
      "320822    1\n",
      "294197    1\n",
      "301551    1\n",
      "118067    1\n",
      "77103     1\n",
      "146733    1\n",
      "13612     1\n",
      "38022     1\n",
      "345378    1\n",
      "87328     1\n",
      "7108      1\n",
      "629725    1\n",
      "40435     1\n",
      "202008    1\n",
      "58646     1\n",
      "51550     1\n",
      "96258     1\n",
      "285969    1\n",
      "61922     1\n",
      "9486      1\n",
      "460042    1\n",
      "138505    1\n",
      "327680    1\n",
      "Name: AuthorUserId, Length: 13340, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['AuthorUserId'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll clean the text from the training data posts as well as the Kaggle forum data posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to clean data\n",
    "def clean_text(text):\n",
    "    #get rid of html and seperators\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r'  ', text) \n",
    "    text = re.sub(r'http\\S+', r'  ', text)\n",
    "    #get rid of punctuation\n",
    "    text = text.replace('.', '  ')\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    #get rid of numbers\n",
    "    text = ''.join(i for i in text if not i.isdigit())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['clean_posts'] = train_data['posts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im finding the lack of me in these posts very alarming    Sex can be boring if its in the same position often   For example me and my girlfriend are currently in an environment where we have to creatively use cowgirl and missionary   There isnt enough        Giving new meaning to Game theory    Hello ENTP Grin  Thats all it takes   Than we converse and they do most of the flirting while I acknowledge their presence and return their words with smooth wordplay and more cheeky grins    This  Lack of Balance and Hand Eye Coordination    Real IQ test I score    Internet IQ tests are funny   I score s or higher    Now like the former responses of this thread I will mention that I dont believe in the IQ test   Before you banish        You know youre an ENTP when you vanish from a site for a year and a half return and find people are still commenting on your posts and liking your ideasthoughts   You know youre an ENTP when you                I over think things sometimes   I go by the old Sherlock Holmes quote    Perhaps when a man has special knowledge and special powers like my  own it rather encourages him to seek a complex        cheshirewolf  tumblr  com  So is I D    post  Not really Ive never thought of EI or JP as real functions    I judge myself on what I use   I use Ne and Ti as my dominates   Fe for emotions and rarely Si   I also use Ni due to me strength        You know though   That was ingenious   After saying it I really want to try it and see what happens with me playing a first person shooter in the back while we drive around   I want to see the look on        out of all of them the rock paper one is the best   It makes me lol    You guys are lucky D Im really high up on the tumblr system    So did you hear about that new first person shooter game Ive been rocking the hell out of the soundtrack on my auto sound equipment that will shake the heavens   We managed to put a couple PSs in        No The way he connected things was very Ne   Ne dominates are just as aware of their environments as Se dominates    Example Shawn Spencer or Patrick Jane Both ENTPs    Well charlie I will be the first to admit I do get jealous like you do   I chalk it up to my w heart mixed with my dominate w   s and s both like to be noticed   s like to be known not the same        D Ill upload the same clip with the mic away from my mouth   Than you wont hear anything    Ninja Assassin style but with splatter    Tik Tok is a really great song   As long as you can mental block out the singer   I love the beat it makes me bounce    drop  io vswck  D Mic really close to my mouth and smokin aces assassins ball playing in the background    Sociable  extrovert Im an extrovert and Im not sociable     Sherlock in the movie was an ENTP   Normally hes played as a EXTJ   In the books hes an ESTJ    As I said   The movie looked good except for it being called sherlock holmes        Oh I never had fear of kissing a guy   I will kiss an animal too   So there was nothing to vanish   Just personal taste and me not liking it    The guy I kissed didnt know me   It was one of those        Sounds pretty much like my area and what Im going through right now trying to figure out which way I want to take my life   I want to do so many things   The biggest problem is that I know if I dont        D I was operating under the impression that you were female   I never looked at your boxy   Okay I help out my gay friends all the time and one of them has developed a little crush on me   I get red        TT You just described me  and Im living the worst nightmare   Im trapped in one place with one one around   Only dull woods   If I was a serial killer this would be the perfect place but sadly Im        TBH and biased sounds like a shadowed INFP   I think maybe he was hurt and turned ESTJ   I can tell because he has some of the typical INFP traits left over    Checks list Im sorry   It seems that you have came at a bad time   Weve already reached our quota of INFJs   However being youre female and I like females I will make you a deal   I will kick one        Im ANTP Leaning toward E   Im easy for both ENTPs and INTPs to identify with     I also imagine ENTPs interrogations would go a little bit like Jacks from  except more mechanical   Rigging up shock treatment equipment in an abandoned building out of an old car batty jumper        It was a compliment  Trust me   Im just as psychopathic D except I have emoticons   Theyre just weird ones   Like laughing when I get hurt or at people running themselves over with their lawn mower               No   Its like a theme for where I live and that is why I know it by heart         and I usual dont leave until the thing ends   But in the mean time   In between times   You work your thing   Ill work mine D  D Im the MBP Pleasure to meet you    Damn need to trust my instincts more I would have been closer I was going to say INFP    EXFP Leaning toward S with the way she responded    D My friends even my gay and lesbian ones always come to me for advice    I bow to my entp masters ENTPs are so great   If it wasnt for ENTPs I wouldnt have been able to build what Im building  Duck Duck  Duck  Shotgun  What Me I never do that    \n"
     ]
    }
   ],
   "source": [
    "print(train_data['clean_posts'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg['clean_messages'] = forum_data_agg['Message'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The public leaderboard is only indicative because competitors can use information on their score to get information on a portion of the test dataset   The final results are a quite different and b better reflect actual performance   Hi Tanya Kaggle will maintain a rating system   If you win but youre ineligible for prize money you will still get a strong rating  Anthony GiovanniThanks for your feedback   Using the forum to give feedback is a good idea   It allows others to see and comment on suggestions   We might set up a proper feedback forum but for the moment this topic will have to suffice   I also agree that the forum is a bit clunky   However we have a large list of feature requests and only limited resources for the moment  it might take us some time to address this   Apologies   I dont think the prize money in this competition is that relevant the prize is relatively small   Correct me if Im wrong but I think contestants are driven by intrinsic factors  A karma system that rewards forum posts is a good idea   Again apologies for any delay in implementing this there are lots of features on our to do list  Anthony Manish thanks for the feedback   The site is hosted on an Amazon EC server on the east coast of America  Its a fast server but the site has been more popular than we expected  Were currently working on speeding up the site by reducing the number database queries   We may have to implement auto scaling if the site keeps growing so rapidly   Anthony Just made a change which should speed things up   Let me know if it has made a difference for you   Jonathan thanks for your feedback x   Were currently working on caching database queries   There are a lot of good suggestions here that well try before autoscaling    Colin the choice of scoring system was quite deliberate   Will the competition host considered using Area Under the ROC Curve where participants submit probabilities but  said that he deals with physicians who just want to know the proportion of predictions that are correct  Rajstennaj and Colin were really pleased that you believe that theres value to the project   Let me know if there is anyway that we can help to facilitate a community   We did set up the general Kaggle forum under CommunityForum\r\n",
      "  with such a community in mind  does it provide sufficient infrastructure You are free to start any new threads on that forum  RegardsAnthony Thanks for participating in this competition   Ive attached the solution file to this post  \n",
      "UPDATE The solution is no longer attached but youre welcome to make submissions to this competition   Hi MattI believe that Will the competition host is preparing a blog post that discusses some of the methods that people applied to this competition  based on the feedback we received   Is this the sort of thing you had in mindAnthony Here are some papers that analyze Eurovision voting patterns   You might find some of them helpful   Gatherer Comparison of Eurovision Song Contest Simulation with Actual Results Reveals Shifting Patterns of Collusive Voting Alliances      Eurovision Song Contest Is Voting Political or Cultural Ginburgh and Noury    Suleman Efstathiou and Johnson    Eurovision Song Contest as a ‘Friendship’ Network\r\n",
      "Dekker   \n",
      " More research       enjoyLove thy Neighbor Love thy Kin Voting Biases in the Eurovision Song Contest   culture and religion Explaining the bias in Eurovision song contest voting   Hybrid System Approach to Determine the Ranking of a Debutant Country in Eurovision   Eurovision   Judgment Versus Public Opinion – Evidence from the Eurovision Song Contest   Here is the solution file for anybody interested    I accidentally deleted the following post made by another user   Im reposting it on their behalfAre there categorical andor binary variables in the data set Other than the target variable For instance VariableOpen in test data seems to have categories          If there are categorical variables do we get to know what the categories meanThank You Just to clarify  the results page will show the leaderboard for all competitors regardless of whether they used future information or not   We will make an honourable mention to the leading competitor who doesnt use future information however their entry will be audited   Kaggle is currently developing a league table that ranks competitors   When it comes to this competition your position on the leaderboard which is indifferent to the use of future information will be what counts towards your Kaggle ranking    INFORMS can offer an awardhonourable mention to those who dont use future data   However the Kaggle leaderboard will not seperate those who use future information from those who dont   Given the way the competition has been setup theres no way to prevent people from using future data   Even if the winner presents a model that doesnt include future data they may have overfitted to replicate the predictions of a model that does include future data   In theory yes   The problem is that theres no way to be certain that the winner didnt use future information   Even when we check the winning model its possible they have used a model with future information to probe the test dataset   Sali Mali has pointed out that there is an error in the AUC\r\n",
      "calculation for entries with tied scores that is when two or more scores have\r\n",
      "precisely the same value   We will look at the problem over the next  hours and will rescore all entries   ApologiesAnthony The AUC calculation glitch has been fixed and all entries have been rescored   Sali Mali thanks again for pointing this out   Hi PG   Not sure that I fully understand the question   Are you referring to the situation where a classifier returns only  or  rather than a score or probability Perhaps you can use an example to illustrate the question Regards Anthony Hi PG   You should give the score for all timestamps  a higher score means the instance is more likely to be a member of the positive    AUC measures your classifiers ability to split the classes  so you dont need to decide which scores predict positive instances  and which predict negative instances    Have I addressed your concern Vateesh thanks for sending the files   The files that you sent are actually different   I also had a look at your submissions and you have a few files with the same name but different numbers   Also I was not able to replicate the problem as you describe it   Perhaps you can try again and let me know if youre still experiencing the error Hi Vess   This should not be a problem given the way submissions are stored   Seyhan the leaderboard portion of the test dataset is selected randomly   It is somewhat representative of the overall standings   Cole sorry for the slow response   In this competition all your submissions count   In future we will ask participants to nominate  submissions   Phil that is correct   You must remember that Kaggle hopes to do more than just host fun competitions we want to help solve real problems   This is why were reluctant to force participants to choose just one model they may make a poor choice and the compettion host may end up with a suboptimal model   Our compromise position is to allow partipants to nominate five entries a feature which well roll out for future competitions    Phil number  is correct   Luck will play a part but I suspect the test dataset is large enough to limit its impact    I agree in a competition like this one   But as mentioned above we want to host competitions that are useful as well as fun   An upcoming competition will require participants to predict who has prostate cancer based on  variables   In a competition like that it would be a shame to miss out on the best model   Requiring participants to nominate five submissions seems like a good compromise    Hi ColeApologies for the ambiguity   The time is as it appears on the competition summary page   adjusts according to the timezone on your computer clock so itll be Saturday or Sunday depending on your timezone  You can also see a countdown on the Kaggle home page  Anthony  Durai apologies for the slow response   All up  countries were represented   Here is the list in order of most participants to fewest United States United Kingdom Australia Canada Thailand India Germany Spain China Netherlands France Italy New Zealand South Africa Sweden Argentina Croatia Ecuador Greece Indonesia Iran Ireland Mexico Poland Portugal Russia Singapore Turkey and Ukraine Ricardo you are correct  I gave the country list for the wrong competition    countries were represented United States Colombia India Australia United Kingdom France Thailand Canada Germany Argentina Japan Afghanistan Albania Austria Belgium Chile China Croatia Ecuador Finland Greece Hong Kong Iran Poland Portugal Slovak Republic Venezuela Sorry for the slow response  Ive been flat out with the new site launch   Below is the list of rows used to calculate the public leaderboard Phil I made an error in the ten per cent listed above try scoring with the following rows YuchunApologies for this error   The public leaderboard is portion of the test dataset is actually the first  per cent because we hadnt implemented the code to select a random portion of the leaderboard yet   For info the reason we kept getting different  per cents is because the random seed in the database was set to zero which told our code to choose a random random seed  Anthony Please use this topic to give us feedback   If youd rather do so in private email me at anthony  goldbloomkaggle  com   Thanks for the feedback   \r\n",
      "\r\n",
      " What sort of features do you have in mind Or can you point to a forum that you we should emulate I just added a quick reply box to make the forum less clunky  \r\n",
      "\r\n",
      " Great suggestion   I have put this on our extensive features to add list   Hi MattThanks for the nice words and the suggestion   Ive posted the solution file   Good suggestion   Were open to ideas on how we can facilitate this   My thinking is the best thing to do is to implement a more functional forum which were doing   We can then encourage those who are still working on the problem to continue to use the competition forum as a way to collaborate   Use this topic to discuss any competitions you would like us to run   If you would rather contact me privately email anthony  goldbloomkaggle  com      out of   thats pretty impressive Pity they didnt enter the Kaggle comp   I think youre right  some competitions exhibit more regularities than others   Soccer may be a difficult sport to model   David this is a great suggestion   The HIV competition shows that Kagglers can do great things    My initial concern with any public dataset is that people can look up the answers   We would need researchers to withhold a small portion of the dataset for evaluation   I think the first step is to get in touch with those who set up the Alzheimers project   It also makes sense to contact the Michael J Fox foundation   If anybody has any connection to either of these projects please let me know  Otherwise Ill keep you posted on any progress  Anthony Hi DavidI have written to the Alzheimers Disease Neuroimaging Initiative ADNI and the Michael J Fox Foundation   I am scheduling meetings with both for September   Will keep you posted on any progress   Can you put up a link to the datapaper you foundThanks again for the suggestion   Its great if we can use the power of this platform to tackle meaningful problems   RegardsAnthony Thanks for the nice wishes   Of course Kaggle wouldnt exist without a brilliant community of data scientists who can solve really challenging problems   Looking forward to seeing what we can do in  This is the photo from the Kaggle office   This lunch was one of the highlights of my six years of Kaggle   Not something I will forget in a hurry    Hi DirkThe Elo Benchmark is based on the training dataset only   Having had many email conversations with Jeff I can tell you that the seed ratings matter a lot   Youll notice that Jeff made two submissions for the Elo benchmark  thats because hes refining his seeding method   I believe he plans to make a few more refinements  Jeff uses an iterative process to seed the rating system   For example he might start by giving everybody  and then letting Elo run for  months   He then seeds Elo with the  month ratings and runs Elo again   He does several iterations of this  Does this helpAnthony  Has anybody tried Trueskill yet   probably a better starting point than Elo   This blog post does a nice job of stepping through Trueskill   Hi JohnHave just confirmed with Jeff methodologies will be shared publicly   RegardsAnthony The competition has been designed to make cheating really difficult   At the end of the competition the winners methodologies will be replicated to help ensure everything is above board   Hi MattThe reason we prevent participants from submitting an unlimited number of times is because otherwisea our servers may not be able to handle all the traffic anda it would be easier to decode the portion of the test dataset thats used to calculate the public leaderboard   The technique you describe often referred to as cross validation is very sensible and we encourage others to use it   Anthony Uri you raise an interesting point   However is five months long enough for somebodys rating to move enough for you to notice this JPL a competition using internet chess data is a good suggestion   For interest the reason we are running the competition using top players is because Elo ratings matter most for top players since it is used to determine who can play in which tournaments   Jase the score on the full dataset is calculated onthefly  so we actually know who is winning based on the full test dataset  Ron the submission that is performing best on the public leaderboard may be different from the submission that is performing best on the full test dataset   We dont link the best submission on the public leaderboard to the best overall submission so that participants dont become confusedconcerned if their scoreposition on the public leaderboard worsens  Leigh my thinking as well   In a tradeoff between having a veracious public leaderboard and a veracious end result  the end result is most important  Jeff good suggestion    Ive put together an Excel sheet that might be helpful for cross validation   You paste your predictions for months  into column G and it aggregates by player by month and then calculates the RMSE   Hope its helpful  Anthony BenThe evaluation method was chosen because Jeff has found that scoring based individual games with RMSE unduly favours systems that predict a draw   Mark Glickman raised another issue  RMSE is better suited to normally distributed rather than binary  outcomes   So in order to use RMSE aggregation is preferable   Of course we could have evaluated on a game by game basis using a different metric  My biggest problem with the current evaluation method is that counting a draw as half a win seems a little arbitrary   However in order to benchmark Elo such an assumption is necessary   Mark and Jeff argue that a draw is generally worth half a win  so this assumption isnt too problematic   Anyway hope this gives you some insight into our thinking   RegardsAnthony Jeff please correct me if Im mistaken but I believe systems that predict draws are favoured because a high proportion of games are draws at the top level  per cent in the training dataset   Of course you can do better  but a system that predicts    for every game will perform better than it should   Matt am interested in your thinking on this   Why MAE over MSE or RMSE Is it just that the metric is more intuitive or something subtler Out of interest has anybody entered this competition using Glicko Glicko or Chessmetrics Are either of you happy to send me your unmodified Glicko submission It would be good to add a Glicko Benchmark team to the leaderboard   My email address is anthony  goldbloomkaggle  com  Would like to do the same for Glicko and Chessmetrics if anybody has tried those   I have also contacted Ron about using his Trueskill submission as a Trueskill Benchmark   Jase I posted a link to your Glicko code on the hints page   Its very good of you to share it   Im really surprised that Glicko is performing worse than the Elo benchmark   Do you think this is because Jeff put lots of work into optimally seeding the Elo benchmark Or is Glicko just not as good Was just chatting to Jeff   Time permitting he is going to benchmark some of these other systems   This way they will all be benchmarked on a consistent basis using the same seeding procedure and the same degree of tuning    Uri the correlation between the public leaderboard score and overall score is significantly higher now   Uri Im reluctant to release confidence interval information because I want to minimize the advantage to early submitters   Early submitters already have the small advantage of having seen their submissions on two different public leaderboards   By releasing confidence interval information Im giving early submitters access to information that isnt available to later entrants   Jase aside from changing the size of the public leaderboard portion of the test dataset we also selected it more sensibly  so it better represents the overall test dataset    Hi Edward   You will appear on the leaderboard as soon as you make your first submission   Hi Edward   Try using examplesubmission  csv available at    and replacing the score column with your predicted scores   If youre still having trouble email the file to me anthony  goldbloomkaggle  com and Ill have a look   Uri thanks for pointing out the problem   Were currently working on a big upgrade to the website the new site should be launched by the end of this month   The upgrade will involve a more functional forum   In the meantime I will try and fix this problem   Anthony Uri Im not able to replicate the error either on the live site or on the development version   Can you let me know if you experience it again Hi Hans which post Still cant replicate the bug       intermittent problems are really annoying As mentioned were doing a massive site upgrade at the moment  so thats taking up the majority of our development time   How serious is the problem Can we live with it for the next few weeks until we deploy Kaggle    I would really like to be more active in the forums  looks like theres some lively discussion happening Ive been flat out working on the site upgrade which is only a few weeks away from launch  Anyway Id like to share a few thoughts on this discussion  First off there is quite a strong correlation between the public leaderboard and the overall standings   Secondly the lack of relationship between the  scores and the  scores might indicate overfitting   This may be the case if youre experiencing a larger improvement on the  dataset than the  dataset    On a related point I notice that youre all performing very well   It could be that youve reached a local maximum i  e   the best possible score given the techniques youre using    Eric thanks for the feedback   Theres not really any reason to insist on a particular file extension   Were currently doing a big site upgrade so Ill add this to our list of feature requests   Just to reemphasis Jeffs point you should pay more attention to your cross validation than to the leaderboard   The leaderboard is calculated on a very small amount of data so it is only indicative   PhillippSorry for the delay in doing this I havent had computer access over the last few days   The Spearman correlation between public scores and overall scores is     I also calculated the correlation for different submission quintiles to make sure the relationship holds at the top it doesTop                   Its also worth mentioning that the trouble participants are having  reflects realworld difficulties in formulating a chess rating system   This competition is not just a game but a genuine attempt to explore new approaches to rating chess players  Anthony Out of interest why arent people rerunning old approaches that had previously been scored on the new cross validation dataset Wil if you can get historical data from freechess  org possibly by agreeing to share the winning method with them wed be happy to host a comp here   This way you could specify that the winning method must be an instant gratification system   It would also result in a system thats tuned to lower ranked players   Thanks for pointing out the error   It has now been fixed   Apologies for any confusion   Uri makes a very good point   One way we could run a competition without knowing future matchups is to have participants rate every  player   Once we know the matchups we can infer predictions based on players ratings  The only downsides to this approach are   It doesnt allow for probabilistic predictions since there are many ways to map ratings into probabilities     We couldnt show a live leaderboard  which helps to motivate participants   Interested in others thoughts on this particularly the importance of a live leaderboard    Philipp I dont fully understand your suggestion   Do you mind trying to explain it again Possibly by reference to an exampleAs a general principle tne problem with attempting to prevent people from using neural networks and the like is that participants use them anyway and then overfit other systems to replicate the neural networks results   I actually think that having neural networks et al in the competition is valuable   Even if they wont be implemented as rating systems they may have some benchmarking value   Assuming they predict most accurately they give a sense for what level of predictive accuracy is possible from any given dataset   As an aside if we require participants to submit ratings and dont \r\n",
      "give them access to the matchups that theyll be scored on this should\r\n",
      " force participants to create a rating system       shouldnt it\n",
      " BTW Jeff re   I have been and continue to be amazed by the level of participation so far    I had no idea so many people would participate   Congratulations on organising such a popular competition PEW what criteria would you use to evaluate such systemsBTW I think youd be surprised at the proportion of the top  who are building rating systems    Ron this is fantastic Looks like a sizable proportion of the black dots are sitting in a vertical line   Though Im sure the Elo Benchmark would look much worse      Out of interest what software did you use to generate the viz ps   Im guessing the anomalies that this viz highlights e  g   that white is a smaller advantage for lower rated players could inform future versions of your rating system   Philipp thanks for your nice words Hopefully having a more professional look and feel will help us attract interesting competitions with bigger prize pools    Philipp thanks for pointing out this bug   The error was only aesthetic  had been accidently hardcoded into the new theme   The platform was still only permitting two submissions   Anyway the error has been fixed    Unfortunately the movie isnt out in Australia yet weve still got another week to wait   Jason theres a bug that prevents users seeing previous scores when they have longish technique descriptions   We are aware of the problem and will fix it as soon as we can  Diogo thanks for pointing out this error   We will setup pagination on the submission page shortly    Diogo thanks for pointing out this bug   Few minor teething problems with the new site  we should have them sorted out before long    Hi allJust to let you know that we have extended the deadline for this competition by just over a week   Both Jeff and I will be travellng around mid November so wouldnt be able to deal with the competitions conclusion  Anhony Apologies I hadnt antipicated that this might be an unpopular move   I should have canvassed opinion first   If others also disapprove I will changed back the deadline Kaggle is not a dictatorship  The downside of changing back the deadline is that it limits our ability to generate publicity   This bothers me becausea   top performers deserve recognitionb   publicity for the competition is publicity for Kaggle and more publicity  more members  more competitions andc   it lessens the chances of getting FIDEs attention  A compromise might be to extend the previous deadline by three days to Wednesday November  when Jeff is offline but I am available   Thoughts Hi PhilippThe Chessbase articles were written by Jeff he has a relationship with the editor   Jeff being away when the competition finishes means that its unlikely that Chessbase will report on the end of the competition a real pity if we hope to grab FIDEs attention   It is unfortunate that were both away when the competition ends Obviously not foreseen when it launched otherwise we would have set a different deadline   Anthony Jeff we must have posted simultaneously   You raise a good point   If Philipp and others are OK with the th then we should go with the compromise date   This would mean that Ill be available to report preliminary results and should mean were ready to report the final results by the time you return   Preliminary will be unconfirmed results from the raw leaderboard   Final results after the top ten have all agreed to share their methodology   Ive changed the deadline to the th   As for Uri breathing down your neck remember that the public leaderboard is only indicative and that the final standings may be different    Apologies Uri and LT  seems that any reply is redundant now   Also big thanks to all those who participated in forum discussions   You helped make this a far more interesting competition    This first chart how the leading score has changed on a daybyday basis   The red line shows the Elo benchmark and the blue line shows the leading score   The Elo benchmark was outperformed within  hours which is why its always above the best entry   Interesting to see some recent progress after a period of stagnation well done Philipp   My guess is that any major improvement from this point on will be the result of somebody trying something quite different  This chart shows the number of daily entries   Higher early but seems to have stabilised at around  per day   Happy to put up other charts if people have requests    Philipp theres certainly a largish gap between the top five   Of course this is purely indicative   What really matters is the score difference on the final leaderboard        Philipp great suggesion Weve got a stack of features we want to implement but Ill put this in our long term wish list    I tried puting up a general forum for such discussions but found that it was very lightly used   Features in the pipeline include   fixing bugs or incomplete features on the new site   upgrades to Kaggle infrastructure to allow us to score very large entries   Kaggle ranking system  an Elo for Kagglers based on Microsoft Trueskill   extended social networking features including live chat recent activity feeds          Philipps  competition analytics suggetion and possibly some other data viz toolsCompetitions in the pipeline include predicting social network connections predicting the likely success of grant applications for a large Australian University forecasting travel times for freeways in Melbourne Australia predicting prostate cancer from a high dimensional dataset subject to ethics approval diagnosing breast cancer from mammographics density images also subject to ethics approvalAny other suggestions Any thoughts on what our priorities ought to be JasonLT are you thinking along the lines of karma points for participating in forum discussions Or would you like the forums to be more of a QA with Stackoverflow style ratingsI like the idea of guest blog posts and community tutorials   After the chess competition ends some might be interested in posting details of their workflowmethodcode  LT the general forum has been taken down for the moment   When I get a little time I will attempt to revive it and start encouraging people to use it    Philipp  it may not matter that people only compete in a handful of competitions because each competition contains quite a lot of information   Unlike a single chess game participants are competing against many players   Regardless well do plenty of testing with Trueskill before implementation   As for the points system points seem a little abitrary   I like the idea of ratings that account for the strength of a competitions participants   I tend to agree with your point on forum participation points   The Stackoverflow approach seem like a nice way around the problem  There are lots of directions we could take Kaggle   But for the moment were focused on competiitons    JC I agree that those who enter early have an advantage   However the main source of advantage comes from the fact that they have had the opportunity to spend longer on the problem and try more things   Philipp the current leader has made  entries   If this competition took ternary scores loss win draw this would amount to  possible combinations  making Phillips  entries  a drop in the ocean   In fact the test dataset is richer because participants predict the probability of victory  Nonetheless for future competitions we will ask participants to nominate five entries that count towards the final standings    PEW we are not requiring participants to guess but rather encouraging them to rely on their cross validation when determining which models to choose   The problem with allowing people to enter many times and try many parameter tweaks is that they are more likely to accidentally overfit on the test dataset   By this I mean they are more likely to find a parameter tweak that works well on the test dataset but doesnt work as well for future chess games  On your second point you are correct to say that I am worried about statistical guessing   The requirement that participants submit code does not obviate this concern because models can be overfitted once the answers are known   In the extreme case somebody could fit a decision tree that classifies every game perfectly if they know the answers   Showing the standings but not the scores makes statistical guessing only slightly more difficult because participants are close enough that the leaderboard ordering gives meaningful feedback on which guesses are better and which are worse  As an aside it seems that I have failed to convey the message that the public leaderboard is purely indicative and that cross validation is  important   I would even go so far as to say that it may be problematic if the public leaderboard bears too close a resemblance to the overall standings    I like Uris suggestion   It gets around the problem that LT mentons while potentially encouraging people to try things beyond parameter tweaks   Couple of potential problems   A participant exhausts the submission limit and another entrant makes and shares a breakthrough eg the use of Chessmetrics in this competition  Anybody who has exhausted the submission limit wont have the opportunity to build on the breakthrough   This seems less than ideal given that we want to get the best results possible     It might encourage people to make all their entries at the end so that they dont reveal the strength of their hand   What do others think Philipp Kaggle has been experiencing a massive lift in site visits and\r\n",
      " signups since the new site launched from  unique visitors to    This accounts for the increase in entries   Thanks everyone for making this an amazing competitionBig congratulations to the winner Outis   Also to the runner up Jeremy Howard who only joined the competition late in the piece and to Martin Reichert who finished third  Hopefully well get some of the top ten to tell us about their methods on the blog   In the meantime I encourage you all to tell us a little about what you tried on the forums   Also for interest heres a chart that shows how the best score evolved over time   Rapid improvements initially but after a month progress stalled as participants approached the fronteir of what is possible from this dataset   I think I can help with this I dont give names just score combinationsscore publicscore                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Jeff can I post the test labels on the forum I only seem to have the aggregate solution on hand attached   Jeff do you have the game by game labelsEdit looks like you posted a minute before me Really nice feedback  very thought provoking   The API suggestion is nice   It does seem that it would prevent people from using the future to predict the present   However the testtraining split is still necessary to prevent overfitting and we could still only give partial leaderboard feedback the API doesnt secure against overfitted parameter tweaks   Also the API approach would add new problems    models will take longer to run because of the delay in receiving data points   as you say it would add a huge load on Kaggles servers As for the problems you list here are my responsesPredictions can’t use all available prior data since the test data doesn’t provide resultsThis is necessary to ensure against overfitting   If all the data is used to calibrate a model its impossible to know if the model will fit future datasets as well    Limited training and test data creates too much variance between the public score and actual scoreThe mistake made in the first competition was with the size of the public leaderboard portion of the test dataset my fault not Jeffs   It was too small which lead to the low correlation between public and overall scores   For the RTA competition we raised the proportion to ensure a stronger correlation   This proportion was calibrated after some testing of the correlation between the two parts of the test dataset   We intend to continue this practice going forward   Model parameters can’t be tuned because actual scores aren’t provided If we allowed parameter feedback on the whole test dataset this would almost definitely lead to overfilling parameter tweaks that work on the test dataset but wont work for for future datasets   Number of submissions is severely limited because they are so large this will become a bigger problem as larger test datasets are created I dont think more daily submissions are necessary because the majority of model building should be done with reference to a cross validation dataset   Leaderboard doesn’t reflect actual leadersAgain this was my mistake   I made the public leaderboard portion of the test dataset too small   This is not a flaw with the general approach   Future data can be used to predict the pastJeff suggested a really nice solution to this test set includes some spurious games so that people can’t mine the test set for useful data about the future   These spurious games wouldnt be used in final evaluation   The API also provides a really nice answer to this problem   Hi DirkWeve updated the data description  thanks for the pointer   \r\n",
      "The competition does require participants to forecast the next four observations   Weve updated the format of tourismdata  csv so that there is always a value in the last row   Regards Anthony Hi GregApologies there was a bug that cut off the last  characters   The problem has been fixed but unfortunately the fix will only apply future submissions   Thanks for pointing this out and sorry for the inconvinience   Anthony Greg thanks for pointing this out   Im currently traveling but will look into this over the weekend   Greg this problem has now been fixed   Thanks again for pointing it out   Dirk I just changed the file posted on the Data page to a unix format   Hope this solves the problem   Hi allWondering why the benchmark is still leading when it is publically available    Have people had trouble replicating the authors methodology Or is everybody trying their own approaches Anthony Something was amiss   There was an error in the data uploaded on Kaggle Kaggles fault not the authors  The changes are not particularly big so models that performed well on the previous dataset should continue to perform well   To give you the opportunity to rerun your models and make new entries we have extended the competition deadline by two weeks and lifted the daily submission limit to three per day   And I believe George intends to release the code used to create the benchmark   Apologies for the error Dont hesitate to ask if you have any questions   Hi JesseYou are correct this is instruction is wrong   The monthly columns  mm should be  lines long including the header and the quarterly columns qq should be  lines long  The examplesubmission  csv file available on the data page gives an example   Im at a conference today but will correct the instruction as soon as I get the opportunity   Dirk Ive changed the line break format   Let me know if this doesnt fix the problem    Tim Kaggle is currently in the process of putting together a  league table which ranks participants based on competition performances  If you perform well in this competition it will count towards your  ranking    Hi Markus I can help out on the second part of your query Ive posted some PHP AUC code on another forum post   software packages like R have easy to use packages that calculate AUC   Anthony Steffen you can enter using a model coded in any language   JohnDrew I presume those who enter using software other than R are still eligible for prizes  Hi ArtemFor the intuiton behind AUC have a read of the evaluation page   Kaggle implementation of AUC works roughly as follows   Sort submissions from highest to lowest   Goes down the sorted list and for each prediction plot a \r\n",
      "point on a graph that represents the cummulative percentage of class A predictions against the \r\n",
      "cummulative percentage of class B predictions      Join up all the points to form a \r\n",
      "curve   The AUC is the area under this curve  \r\n",
      "HT Phil Brierley for this explanation  William no thresholding is required which is part of the beauty of AUC   In fact given that the algorithm works by sorting participants make submissions containing any real number  higher means more confidence that the observation is of the positive class  Hope this response doesnt serve to confuse people  Anthony Artem Ive gone through the steps using your example data   Let me know if Ive made any errors  The Kaggle algorithm basically works as followsFirst order the data predicted            real     Then calculate the totals for each class in the totals  totals  Initialise the cumulative percentagespercentslast  percentslast  Iterate for each solutionsubmission pair counts  counts  counts  counts  percents  countstotalspercents   countstotalsrectangle  percentspercentslastpercentslasttriangle  percentspercentslastpercentspercentslast area  area  rectangle  trianglepercentslast  percentspercentslast  percentsSo in your exampleFirst submissionsolution paircounts  counts  percents    percents  triangle  rectangle  Cumulative area  percentslast    percentslast  counts    counts  percents    percents  triangle  rectangle    Cumulative area    percentslast    percentslast  counts    counts  percents    percents  triangle  rectangle  Cumulative area    percentslast    percentslast  counts    counts  percents  percents  triangle  rectangle  Cumulative area    AUC     Also heres Kaggles PHP code to calculate AUCprivate function AUCsubmission solution         arraymultisortsubmission SORTNUMERIC SORTDESC solution        total  arrayA B        foreach solution as s             if s                  totalA            elseif s                  totalB                nextissame           thispercentA             thispercentB             area             countA          countB          index           foreach submission as k             index              if nextissame                  lastpercentA  thispercentA                lastpercentB  thispercentB                        ifsolutionindex                   countA                else                 countB                           nextissame              ifindex  countsolution                   ifsubmissionindex   submissionindex                    nextissame                       mycount                                          if nextissame                   thispercentA  countA  totalA                 thispercentB  countB  totalB                 triangle  thispercentB  lastpercentB  thispercentA  lastpercentA                     rectangle  thispercentB  lastpercentB  lastpercentA                 A  rectangle  triangle                 area  A                             AUC  area         return AUC Thanks B Yang   The benefit of publishing code is that you get sensible suggestions in return    Hi JonIts a fixed  per cent chosen randomly  Anthony Hi TamasAs your results suggest the order does matter and the IDs dont   Anthony You can email me the file if you like anthony  goldbloomkaggle  com   Id be happy to take a look at it    William thanks for the question      Teams are allowed to merge     One individual cannot be part of several teams our systems ensure this anyway        as long as somebody doesnt have multiple accounts  Agree that we should make this more explicit in the future   As for finding people who submit from multiple accounts we are actually in the process of implementing rules that alert us when it looks like this is happening   In the future for large prize money competitions we may look at verifying identities    Apologies Will   I was on a plane and only just got your message   Will make the adjustment this afternoon  Id also like to congratulate the top teams and congratulate Dirk for running an excellent competition    Thanks to everybody who participated and a big thanks to Dirk for putting together a really nicely designed competition   The test labels are attached to this post   B Yang first off congratulations again on a fantastic performanceYour frustration is understandable but we cannot enforce rules that dont exist  what is common sense to some is not common sense to others   As Jeremy points out in the RTA competition the rules say The winning entry has to be a general algorithm that can be implemented by the RTA   An algorithm that involved looking up future answers could not be implemented by the RTA    Hi NickYoure welcome to bring additional data as long as its publicly available  Anthony This is something that should be dealt with on a case by case basis   If you find a dataset youd like to use ask on the forum and Ill run it by the RTA   For information Im trying to get hold of some incident data   Will keep you posted on this    Vitalie the volumes data is used to calculate travel time  see this post for more info   Our priority at the moment is to get the incident loop error and route length data together   However I can find out if this data can be made available if you think it might be useful   As Dennis says itll be highly correlated with travel time and we obviously wouldnt release it for the blanked out times    Jeremy I wasnt aware that public documents with traffic details were available   To the extent that any information is available for blanked out times this would most definitely be considered cheating  As for question  I am aware of this in fact the issue came up in another post   The rules state that the winning model must be implementable by the RTA in order to be eligible for the prize   The averaging model passes this test   As an aside I dont believe the temporal leakage invalidates the algorithms developed in this competition    Alexander to me this means that the algorithm can take a timestamp as an input and can generate forecasts for the next mins mins etc    Lee thanks for pointing this out  This post   post   Jose do you want me to ask if its permissible to use NOAA data If so are you asking about the data that Brad mentions above Jose and Joseph just spoke to the RTA about this   The answer is no because it might allow future weather conditions to be used to predict the present   Attached is some sample code that can be used to constuct an entry that generates a forecast based on the average travel time on a given route on a given day of the week at a given time   Mmm       file didnt attached   Heres the codephprh  fopenRTAData  csv r File to read fromwh  fopensampleHistorical  csv w Write the entry to this filedatedefaulttimezonesetGMT Purely to prevent the interpreter from raising a warningtimeStamp  array                               an Array with the humping off pointsforecastHorizon  array forecast horizon in lots of  minutes e  g      minutes  minutes   hour   This is used for calculating the forecast time stampsforeach timeStamp as ts      foreach forecastHorizon as f          forecastTimeStamp  dateN H istrtotimetsf find day of week hour and minute that corresponds to each of the timestamps     row  while data  fgetcsvrh    FALSE  loop through the datafile    if row    Write the header         colCount  countdata         for c c  colCount c             fwritewh   datac        fwritewhn        if  inarray dateN H i strtotimedataforecastTimeStamp    if the day of week hour and minute that corresponds to a forecast timestamp is found then save to an array called tsArray         for c c  countdata c             if  emptydatac  datac  x                  tsArraydateN H i strtotimedatac  datac            rowforeach timeStamp as ts      foreach forecastHorizon as f          fwritewh dateYmd Histrtotimetsf        for c c  colCount   c             fwritewh    arraysumtsArraydateN H istrtotimetsfccounttsArraydateN H istrtotimetsfc writes the average for a given day of the week hour and minute to the submission file         fwritewhn    fcloserhfclosewh  This code does generate a sample entry   To use it a download the PHP interpreterb create a file name xxx  php copy the code above and download the data files to the same directoryc run the command PHP xxx  php Youre correct  the future is used to predict the present   However I dont think the temporal leakage invalidates the algorithms developed in this competition    Attached is some sample Python code that generates forecasts based on the last known travel time   Im new to Python so happy to hear any feedback on the code   File didnt attached   Heres the codeimport csvimport datetimerhopenRTAData  csvr read in the data whopensampleNaivePython  csvw create a file where the entry will be savedrhCSV  csv  readerrhtimeStamp                                 an Array with the cutoff pointsforecastHorizon   forecast horizon in lots of  minutes e  g      minutes  minutes   hour   This is used for calculating the forecast time stampsrow   inialise the row variablefor data in rhCSV loop through the data    if row   if the first row then write the header        for j in rangelendata            wh  write  dataj        wh  writen    if data in timeStamp if the row is a cutoff point            for i in forecastHorizon for each forecast horizon write the cutoff travel time as the forecast the definition of Naive                 dateStr  strdatetime  datetimeintdataintdataintdataintdataintdata  datetime  timedeltai calculte the time stamp given the forecast horizin                 wh  writedateStr write the timestamp to the first column of the CSV                for j in rangelendata                    wh  write  dataj write the cutoff travel time to the subsequent columns                 wh  writen    row  rh  closewh  close Lee this is great Dirk did the same thing with some Python sample code I wrote for the social networking competition   If you guys keep showing me how things can be done better I may become a half decent coder   Toppy thanks for the pointer   A higher priority at the moment is to get forum attachments working again   Hi Peter Ill follow up in this   At the very least we should be able to provide information on the length of different routes   Anthony Armin I agree   Makes more sense for me compile this information once for everybody   Will try and get it done this week   Eleni just uploaded RouteLengthApprox  csv which has approximate route length data    Martin Dane is correct the information in RouteLengthApprox  csv is in metres   So route  is approximately   km    Martin when I open the file it shows  and    What application are you usingAnthony Dirk thanks for pointing this out   Ive written to the RTA about this and they responded sayingIndeed  our control room have confirmed significant increase in traffic volumes following the removal of the tolls   This has had an impact on the overall travel times across the M  Something to be aware of when using the older data    Hi Dennis The  per cent doesnt count towards the final standings and is selected at random across the  timestamps and  routes   As for the SMTP error its been fixed   The problem was the result of a flood of signups which caused Google to shut off our mail server   Were now using our own mail server   Anthony The number directly to the left of the team name is the teams position and the number to the right of the team name is the teams score or Root Mean Squared Error RMSE    Apologies for the error its deciseconds not centiseconds  so  is    seconds   Ive fixed the description    Hi Carlos Unfortunately not   Clause   c in Kaggles Terms and Conditions saysc            employees or agents of the Competition Host are not \r\n",
      "eligible to participate in any Competition posted by the Competition \r\n",
      "Host\r\n",
      "\tTo answer the second question we would more information about the nature of the business and what your friend does  Anthony Frank this is great I particularly like the heatmap  is it possible to zoomAlso itd be neat to see some animation on the M map  showing how travel times evolve over the course of a dayweek dots getting bigger and smaller   Though I suspect this might be a lot of work  Anthony  C does seem to be an expressive language   Im a Linux user though so not inclined to pick it up    Daniel Dennis is correct in saying that averaging the values leads to floating point numbers   The answers are integers but the RMSE is calculated using floating point arithmetic    Alexander there is no truncation of floats    David I believe that when loops the measuring device fail travel times are estimated   Im working towards putting together data on when travel time readings are suspect    Andrew good discovery   Ill pass the question onto the RTA  Edit Wouldnt it be obvious if they werent making the adjustment since peak traffic times would change Paresh thanks for the thought provoking question   I agree with Dennis I am more interested in the time delay than the percentage delay   On a related matter we think it is more important to predict correctly when travel times are volatile e  g   before and after work   To favour models that predict more accurately during high volatility times we selected more high volatility cutoff points so youll notice more cutoff points during the morning and afternoon   Phil thanks for sharing this   Just got to find a Windows machine to run it on        Aidan have asked the RTA about this   This was the response   The cutoff is due to free flow conditions imposed by the system during data unavailability  Ive written again asking for a little more detail   Will post the response when it comes    I have some information on suspect loop readings that Im working to release   This has information on when loop readings may be unreliable for various reasons   I dont yet know whether or not this will help with the free flow issue   Anyway I will upload them as soon as I can get it into a useful format  I suspect the reason the free flow times are different is because route lengths are different   Rob on your point about missing data it might be helpful if I explain how I put the files together   I received data in the following formatroute IDtimestamptravel time xxx xxxI transposed them into in the hope that theyd be more manageable   When timestamps were missing I just filled in a blank row   Aaron another good question   Have also passed this on to the RTA    Daniel and Dennis are correct   Keep in mind that the  per cent is a random selection of the  that doesnt count towards the final standings which are calculated based on the other  per cent   burak the times in sampleEntry  csv are the times you need to generate forecasts for   Theres more info on how the  cutoff points were selected in this forum post   Mmm       my message seems to have disappeared from the board   Anyway heres a repeat  Aaron the units are deciseconds  Nick actually its a hybrid approach   You can nominate five entries that count towards the final standings   You do this from the submissions page  the last five are chosen by default   At the end of the competition the best of your five nominated entries counts towards your final position   And Nick on your new question the one of the five you nominate that scores best on the  per cent counts   The  per cent is meaningless as far as the final standings are concerned    The cutoff times are all between am and pm   They were selected using a simple formula that favoured high volatility cutoff times over low volatility cutoff times   So youll see more peak hour morning and afternoon cutoff times   The rationale behind this is that its more important to predict accurately during high volatility times so we want to favour models that do best at these times   That explains why the RMSE is higher than for randomly chosen cutoff points   Thomas I selected specific cutoff times randomly but chose timeday combinations that are volatile across the dataset   Rasmus apologies I deleted the wrong post   Anyway you asked how travel times are measured   There are regularly spaced loops along the M   These loops measure each cars speed and the number of cars that travel across the loop every three minutes  travel times are then calculated using a formula   The formula has been tested and calibrated using test cars that travel along the freeway and record their travel times    Benjamin once we get the incident data I will put in a request for this data    Hassan the most important file is RTAData  csv   You can create a sample entry by   downloading RTAData  csv and createHistorical  php attached to the same directory   navigating to that directory in the terminalcommand prompt   running php createHistorical  php This will create an entry based on a historical average for that timeday and is a good starting point   BJB very generous of you to upload a Java code   Ive now enabled   java file uploads so you should be able to upload the file    Aaron you raise a good point   According to the route definitions I have route  extends from loop A to loop A while route  extends from A to A so  should encompass all of    Denniss observation that sometimes  has longer throughput times than  is strange   Ill double check the definitions with the RTA    Konstantin just uploaded RTAError  csv the is valid data   Its available on the data page   Mooma I appreciate your frustration but sensor malfunctions  are part and parcel of dealing with realworld data   If we had the data ready at the outset we might have excluded failed sensors and downweighted the impact of partially failed sensors when evaluating predictions    Konstantin Dennis is correct it is not safe to assume that there is no errors in the control data    Ahmed just got an answer from the RTA on this   Heres the responseThe answer is  maybe   RTA would request that anyone wishing to use the data for further research purposes write to the RTA and make their case  describing what they wish to do ie the purpose of the research and how they would use the data   The RTA will consider each application on its merits   Let me know if youd like me to pass on the relevant email address   Im reluctant to do it in the forum but will offer an introduction to anybody who asks   Rob thanks for jumping in    Dielson good pick up   Dennis is correct  the date format doesnt matter   What is important is that you put the correct data in the correct cells   Many thanks to everyone for all your great activity on this fascinating problem  insightful questions and comments on the forum good early results on the leaderboard and interesting discussions There have been a lot of questions about exactly what constitutes an acceptable model for the RTA   So far my guidance on this matter has possibly been too fuzzy and I hear a lot of you looking for more definite rules   Therefore we have come up with the following specific rule regarding the allowed model inputs Your model can be of any form you like as long as it takes its input only from the following parameters Time of prediction Day of week Is holiday Month of year Route number to be predicted The time taken for route r for datetime t where  r is any route and t is any time less than the datetime being predicted for as  many routes and datetimes as you wish The sensor accuracy measurements for any routes r and datestimes t defined as above The estimated route distances as provided by KaggleTo clarify the following are not permitted The use of any data other than those provided by Kaggle for this competition and the list of NSW holidays   The time taken for any routes in the future compared to the prediction being made  your model can still be trained using all data as long as the resultant model only uses the inputs listed above  Furthermore the algorithm must not be encumbered by patent or other IP issues and must be fully documented such that the RTA can completely replicate it without relying on any black box libraries or systems   Hi Alexander   No   Using full timestamp makes it possible for a model to implicitly incorporate external data and future data     You may also use holiday data extracted from the PDF file that you linked to in order to get holiday information for previous years   However we will not be providing a file of this information directly     This is correct  Anthony As Jeremy Howard pointed out earlier in this thread the key point that answers most of these questions is that the limitation is only on the functional form of the final model   More specifically Xiaoshi Lu You can build your model  filtering aggregating etc  using all the datetime information you like   The final functional form that you end up with however should only use the predictors listed above   Mooma The inputs listed include this The time taken for route r for datetime t where  r is any route and t is any time less than the datetime being predicted for as many routes and datetimes as you wish   So what you ask is specifically allowed   Of course for you to create your input file which includes for example the time taken one hour earlier you will need to use the full datetime   However the resultant model will not directly use this  instead it will only use the time taken on that route as allowed by the rules   Alexander Groznetsky Imagine using a very flexible model neural net for instance which trains with all datetime info included in the input parameters   It might implicitly end up using the route times later in the day to predict those earlier This is an example of how a model could be useless in practice even although it appears highly predictive on the competition data    Matthew   Using GPL code is fine      The isholiday variable can be a direct input rather than a variable that is derived by reference to a timestamp      You contact me directly at anthony  goldbloomkaggle  com   Dennis you can use isspringbreak rather than isholiday    Nicholas a Matlab solution is fine as long you dont include libraries that use patented or undocumentedsecret algorithms    Rafael  and  are fine    is also fine as long as the data is derived entirely from the time series as you say     JoseI notice that you are now on the leaderboard   It can take a few minutes before you show up   Anthony David its really neat  For info it works in Safari but the page videos are aligned a little strangely   The In the Money indicator is based on the public leaderboard only   It doesnt reveal anything about the final standings   Reginald please email your submission to anthony  goldbloomkaggle  com and Ill have a look   Wu Wei a route is made up of several loops   A figure of    means that  per cent of the loops in the given route are giving suspect readings    For anybody interest heres the actual solution   Nathaniel is right  the data is correct its just a problem with heading formatting   Will fix this shortly and reupload the data    Finally  fixed the headings   Just to reiterate all the data are correct  its just the capitalization in the headings that caused trouble  As for the inconsistent numbers of delimiters also fixed  my software package stopped printing delimiters when there were no more values or NAs in a row   Jack the country  of  birth issue is now fixed   Please download the latest version of the data    Attached is some R code to create a GLM entry for this competition   As always happy to hear feedback from others about how this could have been done more elegantly   Anthony personIDs refers to all the columns that have investigator IDs e  g   column  has investigator  column  has investigator    Ignore the comment numerical values that should be     No   Towards the end of this competition you will be asked to nominate five entries that count towards the final result    P  V  Kiran it means that if your solution is implemented using a software package that is not available to the University of Melbourne it must be possible to translate your solution into a different packagelanguage    Just elaborate a little the types of solutions that cant be implemented are those that are encumbered by patents or other intellectual property restrictions   Nathaniel thanks for pointing this out   Definitely worth investigating   The Number of Successful Grants and Number of Unsuccessful Grants  fields dont change in the test dataset for obvious reasons   The journal citations also remain constant in the test dataset to prevent participants using the future to predict the past   Nathaniel I have looked at the problem in some detail and have spoken to the University of Melbourne   They are looking into it and hope to have an answer for us tomorrow before they break for Christmas    The university has spent the last two days on the problem   They suspect its an internal inconsistency in their database the figures are drawn from different parts of their database   Well have to wait until the end of the Christmas break to get a final verdict    Deepak thanks for pointing this out   We will ask  the university about this as well   Unfortunately we cant expect an answer until early next year    The university has done an investigation and has found that the issue arises from an inconsistency in their database   Michelangelo truth is that you can submit any real number we suggest a number between  and  because of the convenient interpretation   AUC ranks your scores  the higher the score the more confident you are that the instance is a member of the positive class   I believe it refers to grants made when the researcher was at another university    Edith thanks for the feedback   We agree with your comments and we are working on making the terms more competitor friendly    Michelangelo the  per cent comes from the test dataset   Eu Jin Lok the sampling is done randomly    Hi GregThe answers will be made available on the forum   I can ask whether the data can be used for publishing research if you likeKind RegardsAnthony  Hi Greg and SuhendarThe university doesnt want the data to be used for any purpose other than for this competition  Anthony Hi GregIt would be nice if the dataset could be used for other work   However if we dont allow competition hosts to place restrictions on the use of their data then we wouldnt get access to it in the first place   Will post the solution file now  RegardsAnthony The solution file is attached to this post  Thanks all for participatingAnthony  Apologies I didnt clarify this with Mahmoud before the launch but we have discussed this offline  This competition requires you to choose five entries that count towards the final result   To choose five entries visit your submissions page and click the star next to the relevant entry to select it   If you do not choose any entries your last five entries will be chosen by default   Hi allSubmitting from multiple accounts is most definitely against the rules   We have done some analysis and found that it happens very rarely   However we are working to put the systems in place to identify and block those who attempt to do it  Kind RegardsAnthony HarriThanks for the thoughtful post   The IJCNN people agree with you and have decided not to disqualify Shen   As mentioned above Kaggle will soon have the systems in place to detect multiple accounts in real time so that such issues dont arise  Anthony I have sympathy for peoples frustrations   In this case the competition host decided that the results should stand  so we are facilitating their decision  Chris makes a good point about the rules being scattered throughout the site   We will be sure to address this in future competitions   We will also ensure that they are tightly enforced   For information a lot of effort has gone into framing the Heritage Health Prize rules  Finally thanks for the feedback   Its discussions like this that will help us improve Kaggle   Kaggle has received legal advice after the controversy surrounding this competition   We have been advised that it sets a dangerous precedent for us to ignore our own terms and conditions notably clause    preventing multiple signups   We have therefore acted in accordance with this clause disqualifying those who clearly submitted from multiple accounts  Thank you all for your patience on this issue and rest assured that we are working to ensure that it is not a feature of future competitions   The solution is attached  Thanks all for participatingAnthony Entries made before we fixed the leaderboard were scored incorrectly   I have now rescored the relevant entries   The error was the fault of Kaggle and not the competition organizers   ApologiesAnthony Hi CerinApologies for the errors   They all stemmed from the fact that the servers hard drive filled up   Ive cleared some space   For information were currently rewriting the entire site for the Heritage Health Prize   You can expect the next version to be faster and include many more features  Thanks for your patienceAnthony Hi CerinAli is right your entries will count towards the final standings   Anthony Also covered by Slate and Forbes\n",
      "  \n",
      "  \n",
      "and the Wall Street Journal a couple of weeks ago\n",
      "   And Smarter Planet\n",
      "   Dorofino\r\n",
      "\r\n",
      "Great idea Forming a team is a really good way to learn   \r\n",
      "\r\n",
      "Are you affiliated with the New York R Users Group For info Ive heard rumblings about them setting up a team   \r\n",
      "  \r\n",
      "\r\n",
      "Good luck with this\r\n",
      "\r\n",
      "Anthony Apologies this was an error   Thanks for drawing our attention to it  \r\n",
      "\r\n",
      "The missing values are for those people who have been in hospital for more than two weeks   They should be replaced with a    You can either do this yourself or download the updated dataset   \r\n",
      "\r\n",
      "For information members who have in hospital for more than two weeks have been grouped for privacy reasons they are rare so may otherwise be identifiable   The implication of this grouping is that if you expect somebody to be in hospital for more than two weeks you should predict  days   \r\n",
      "\r\n",
      "This grouping should not have a big impact because\r\n",
      "a   members who are in hospital for more than two weeks are rare about one per cent of members\r\n",
      "b   the evaluation metric favors algorithms that accurately predict fewer days in hospital on the assumption that these are more preventable   Hi Rich\r\n",
      "\r\n",
      "Just spoke to HPN about this   For the moment they dont want to provide general guidance and ask that you make a request through the contact us form   Your request should detail the topic of your proposed research   Definitely worth making it clear that youre just looking to publish the method that you use to enter the competition   \r\n",
      "\r\n",
      "Anthony Wgn the intention is not to rule out the publication of research   Ive passed on your message to HPN and a clarification will be forthcoming  \r\n",
      " ashojaee the clarifications havent been made yet    Apologies for the missing values it was an error   You can either replace the missing values with  or download the updated data set   \r\n",
      "\r\n",
      "If youre interested in the reason for the missing data see\r\n",
      "   Y Y Y etc refer to different years   We havent revealed which years to help keep the data private    Agree   See the updated evaluation page\r\n",
      "   The years are sequential   We are not revealing what years Yn refer to nor whether or not they refer to calendar years for data privacy reasons   Just to clarify when Jeremy says we cleaned it as much as we can we didnt do much to the claims data on purpose   We figure it makes more sense for you to make your own cleaning assumptions rather than have us impose them on you   \r\n",
      " The criteria was that somebody had to\r\n",
      "   make at least one claim in Y \r\n",
      "   be eligible to make a claim in Y\r\n",
      "\r\n",
      "Outliers have been removed from the dataset as well as those suffering from stigmatized diseases   \r\n",
      " Not only are patients who died in Y not in the dataset but patients who died in Y are also not in the dataset because they didnt remain eligible to claim for the whole of Y    rudychev received an answer from HPN on this   A patient who visits a clinic outside the network should be captured in this dataset   Of course as Jeremy keeps reiterating there is always a disconnect between reality and the contents of a database   Hi bacg\r\n",
      "\r\n",
      "   DaysInHospital refers to Y the second year while the claims refer to Y the first year  \r\n",
      "\r\n",
      "   Not everything that has a length of stay counts as a hospitalization   In fact you dont have enough detail in the Claims table to calculate DaysInHospital   The detail has been suppressed for privacy reasons  \r\n",
      "\r\n",
      "Anthony Hi mbenjam\r\n",
      "\r\n",
      "We would have loved to release more detailed data but have to be mindful of data privacy   \r\n",
      "\r\n",
      "Anthony mgomari one issue we have to keep in mind are the tradeoffs in releasing data   For data privacy reasons HPN have a granularity threshold which theyre not willing to breach   The data anonymization team represented by keleman in the forums are trying to release CPTCodes probably at an aggregated level   Apparently its pretty lineball and releasng DaysInHospitalY might put this in jeopardy   I describe the data privacy considerations like a waterbed you push down on one part of the bed and it creates a bulge somewhere else  \r\n",
      "\r\n",
      "After May  youll be able to use DaysInHospitalY and DaysInHospitalY to predict DaysInHospitalY  \r\n",
      "\r\n",
      "ogenex even if we release DaysInHospitalY you wont be able to do a consistency check   Not all length of stays count as hospitalizations as calculated for this competition and you dont have enough detail in this dataset to work out which count and which dont   SSRC mapping LOS to DIH is impossible   Not every LOS entry corresponds with a DIH e  g  hospice stay One reason somebody may have DIH in y but no claims is if they werent eligible to claim in Y in which case their Y claims wouldve been removed   Have received advice from the HPN lawyers   Im really sad to say that the answer is no on all accounts     The lawyers are taking a conservative stance on this issue   Apologies its really disappointing to have people ruled for this reason    flsdcom I have a meeting with them in  minutes   I will be sure to raise this point   In response to ashashos original question I have sought a reexamination of the issue   The HPN lawyers explained that the reason for the hard line is that they have no way to verify that residency permits comply with US legislation   Im really sorry to say that theres not more I can do   cybaea many thanks for a great discovery After doing some digging weve discovered that the oddeven observation is an artifact of the cleaning procedure   \r\n",
      "\r\n",
      "We have worked out a remedy and it will be applied to the dataset that will be released on May    In the meantime it shouldnt make a huge different to models that are currently being developed   boegel yes   On May  we will be issuing significantly more data   DayInHospitalY  csv will be changed then   Eu Jin youve obviously not seen this\r\n",
      "   frankthedefalcos  com or the women who have been treated for erectile dysfunction   Tom SF Haines Jeremy is not the author of the rules   He is merely trying his best to point people to the section that makes the rules as competitor friendly as possible given HPNs requirements  \n",
      "Also if you would like to publish your algorithm I strongly encourage you to put in a research request using the Contact Us form   The decision to predict days in hospital was made to make the test dataset richer  so we can better sort out good algorithms from bad   The logarithm in the evaluation metric was chosen to favor models that predict short stays more accurately as these are assumed to be more readily preventable   \r\n",
      "\r\n",
      "As for the question of nefarious intentions I can tell you what I know about Dr Richard Merkin the man behind the prize   He is a big philanthropist who devotes time and resources to funding scientific projects schools and the arts  \r\n",
      "\r\n",
      "In my opinion HPN did not need to put up  million to get an amazing algorithm   Kaggle has found in its own competitions that with prizes as small as  or a chess DVD participants approach the limit of whats possible on a dataset   In our communications with HPN we have been told that the  million prize is an attempt to draw mass attention to this prize and the issue in general   Dr Merkin wants to promote the potential for medical data mining in lowering healthcare costs   The prize also serves to introduce a large number of talented data scientists to medical data  \r\n",
      "\r\n",
      "Finally rest assured that HPN are working hard behind the scenes to clarify the IP issue   alexx the HPN lawyers are working on a clarification   This will be released by the time entries can be made on May      Hi Drew\r\n",
      "\r\n",
      "It will be in place by May  when entries are accepted   Anybody who accepted the existing rules will receive the notification via email   \r\n",
      "\r\n",
      "Anthony The accuracy threshold will be announced when we release the full claims dataset on May    \r\n",
      " This is a sample of the final dataset but the final dataset is not in the Terabyte range   To the best of my knowledge this dataset is on the larger side for medical datasets which tend to be quite small  \r\n",
      "\r\n",
      "This algorithm will not need to operate in a realtime environment and so there is no restriction on execution time     I want to reassure everyone that HPN is working hard behind the scenes to clarify the IP issue   It is not their intention to prevent people from using standard tools nor to discourage anyone from applying their innovative ideas to this problem   \n",
      "For background at Mondays launch event Dr Richard Merkin the man behind the prize spoke of the long tradition of innovation that has resulted from past prizes   He spoke of\n",
      "\n",
      "the Longitude Prize     apparently Newton and Galileo had attempted to solve this problem but the winner was a self educated clockmaker from Yorkshire\n",
      "Napoleons food preservation prize  won by a confectioner and resulted in the invention of canned food\n",
      "the Orteig Prize to fly nonstop from New York to Paris     won by the unlikely Charles Lindbergh   \n",
      "\n",
      "It is his hope that this prize will spur similar innovation to solve one of Americas most vexing problems  \n",
      "We appreciate your patience while we await clarification  \n",
      "Kind Regards\n",
      "Anthony For those who dont know jphoward was Kaggles most successful competitor before joining the team   His tutorial gives really clear explanations of the tools and techniques that made him such a successful competitor    Hi Jim\r\n",
      "\r\n",
      "That is correct   For information the reason for the misnomer is that it was days when we sent it to the anonymization team but they had to group the days to ensure the required level of data privacy  \r\n",
      "\r\n",
      "Anthony  sciolist yes teams are required to publish publicly    mkarbowski as jphoward keeps pointing out theres often a massive disconnect between reality and the contents of a transactional database   See ejloks humorous post for even odder records\r\n",
      "  \r\n",
      " We intentionally decided against cleaning the data so as not to impose our assumptions on participants    We want the forum to be tightly integrated into the site e  g   to be able to link to forum posts from profiles and vice versa   YAF is the best   NET forum software out there and integrating it into Kaggle is more trouble than its worth   \r\n",
      "\r\n",
      "Also moserware is a brilliant programmer so its the type of thing he could put together in less than a week   DIH includes inpatient admissions and emergency room visits   As mentioned previously you dont have enough detail to calculate it from the claims table   RalphH DaysInHospital counts days not nights   So if DaysInHospital is  then they have not been to the hospital at all   If they were in and out of the ER then DaysInHospital would be    Domcastro one of Kaggles first suggestions was to remove the registration fee   \r\n",
      "\r\n",
      "For info the registration fee wasnt ever to raise money but to try and deter people who werent serious from downloading this sensitive data   Kaggle pointed out that anybody with malevolent intentions would probably still pay the modest registration fee so its effect would be to deter people who didnt think they had a chance of winning   Kaggle went on to argue that these people may also come from interesting backgrounds and may be the ones most likely to apply creative thinking to the problem   Realworld data is messy \r\n",
      "\r\n",
      "Well put up a data dictionary soon   DaysInHospital is calculated based on the LengthOfStay variable   However you dont have enough detail to calculate DaysInHospital from LengthOfStay    quotedaveime\n",
      "Seriously I understand the need for randomizing and anoymizing the data but unless they have some way to unrandomize it afterwards any algorithms we create will serve no real world application  \n",
      "quote\n",
      "daveime the data is messy not because its been peturbed but because its realworld data   Anonymization focused on generalizing again not peturbing     The the nineyear old pregnant males actually exist in the raw data  \n",
      "For info Im told that this is one of the cleaner medical claims datasets around   mgomari the difference between  and  is counted as two days  \r\n",
      "\r\n",
      "Overlaps were accounted for so were not double counted    fjn Pi does not have to be an integer    blonchar youre correct HPN are limited in what it can release by the need to protect patient privacy    liveflow I may be misunderstanding the question but the competition requires participants to use data from Y Y and Y to predict Y   No   Some Y patients are no longer eligible in Y   We still provide Y patients who arent eligible in Y because theyre useful to train on  \r\n",
      " DougieD every member listed in DaysInHospitalY is eligible to claim in Y  so if they have  DIH  they are  above   The same will apply for the members listed in DaysInHospitalY and DaysInHospitalY when we release those files    jesensky you will be able to use DaysInHospitalY and DaysInHospitalY as an input to DaysInHospitalY  \r\n",
      "\r\n",
      "I like your thinking on the USE OF OTHER DATA loophole if the answer had been no   Creative thinking    mgomari the answer to both questions is yes    Information Man that is not the intent of the rule   The HPN lawyers are working on clarifying this at the moment    No   Again for privacy reasons    irwint good pickup  thanks Now fixed    gschmidt not sure if this answers your question but the geographic spread is limited to the area in which HPN operates southern California I believe   \r\n",
      "\r\n",
      "As to whether patients change doctors on May  youll have a few years worth of data so will be able to work this out   You will get some procedure code information in the May  release   I understand the frustration but data privacy is a priority for HPN   metaxab the competition was designed this way to replicate how the model might be used in real life   In a real life situation you wouldnt be able to predict hospitalization with contemporaneous claims    DaysInHospitalY is derived from the claims table where a hospital stay includes an inpatient stay or an emergency visit   Note you dont have enough information to calculate DaysInHospitalY from the claims table    In this dataset missing PayDelay either means unknown or greater than    In the May  release the anonymization team will topcode PayDelay so there will be fewer missing values and  will mean    For generating features I recommend SQLLite  though MySQL does the same thing   I know Jeremy and Jeff like Cs Linq   For building models I use R   The rules do not prohibit Oracle Data Miner    rks we will post a sample entry with the rest of the data on May    trezza and RHM Y contains data for a  period   trezza unfortunately not   The anonymization team have identified this as a data privacy risk   Hi Allan\n",
      "Thats because some members have had claims suppressed   In release  coming soon well make it clear which members this applies to  \n",
      "Anthony  Hi Domcastro  \n",
      "   Can I use R\n",
      "Yes\n",
      "   Can I use Weka\n",
      "Yes\n",
      "   Can I use Excel\n",
      "Yes\n",
      "   If I organise the data in a novel way and just use a standard processing algorithm such as Naive Bayes is this OK\n",
      "Yes You must preserve the order in Target  csv   Unfortunately not   Apologies for any inconvenience   Darragh its a list of all members in the dataset   Release  zip does supersede Release  zip     Chris just heard back from the data anonymization team   Members have been renumbered   No   cacross HPN had a granularity threshold that they wanted to remain below   Some LOSs had to be suppressed to achieve this target   If there is a blank LOS and SupLOS is  then this is how it was when it came out of the HPN dataset   If there is a blank\r\n",
      " LOS and SupLOS is  then the LOS has been suppressed   Hope that helps   mkwan you fill in the team wizard when you make your first entry   Team mergers will be granted at the organizers discretion   ChrisR nice to see you competing in this   Sampling is random   Yes   Bernhard your interpretation sounds about right to me    We cant give you an HPN benchmark because theyve not tackled this problem before    boegel DaysInHospitalY contains members who made a claim in Y and were eligible to make a claim in Y   DaysInHospitalY contains members who made a claim in Y and were eligible to make a claim in Y   Similarly target  csv contains members who made\r\n",
      " a claim in Y and were eligible to make a claim in Y   To be eligible means to be an HPN member regardless of whether or not a claim was made  \n",
      "Therefore the  members in DaysInHospitalY are not missing from target  csv but rather didnt make a claim in Y or werent eligible to make a claim in Y   Therefore all members in target  csv were eligible to make a claim in Y  so we have an answer\r\n",
      " for each of these members  \n",
      "JESENSKY by my calculation  members appear in DaysInHospitalY and DaysInHospitalY but not DaysInHospitalY perhaps you can confirm this figure   These members are missing from DaysInHospitalY because they didnt make a claim in Y despite\r\n",
      " being eligible  \n",
      "Apologies if we didnt communicate this effectively in the description pages   ProTester theres nothing in the raw data that distinguishes a death from a patient that leaves HPN for another provider   DanB youre right about the selection bias   But because HPN are releasing almost no information on the members themselves theres nothing to model on for patients without claims   George there are  members in the dataset but you are only tested on  members   Thats because the extra  members arent eligible to claim in Y or didnt claim in Y   They have only been provided to help you train your model   Further to Wills point those who followed the Netflix Prize will remember the jump from the Simon Funk discovery     is the maximum   Ive said this before but I think \r\n",
      "Jeremys tutorial is really excellent although it is not focussed on HHP   He is hoping to get the opportunity to do an HHP tutorial in the next few months     Darragh I passed your question onto HPN   Heres the reply\n",
      "Is there a delay between the scheduling of the surgery and when it takes place  Yes    But that is just a matter of scheduling not something forced by the government    It would also of course depend on how urgent the surgery is   She will be added in the next release    The intent of that provision is to prevent the data being shared with those who have not agreed to the competition rules   Jeff was just referring to the measures he would take to ensure the data isnt accessible to others   Jose thanks for your diligence on this   Its difficult for us to give specific guidelines   Again HPN is just trying to prevent the data from being accessible to those who havent accepted the rules   Jim its being assessed against Y hospitalizations   Thanks Dave   The data description has been fixed   Hi Bobby\n",
      "Can you clarify what you mean by this Are you asking if they are obliged to share their model if they finish in first place\n",
      "Anthony I have checked with HPN and a milestone prize winner can choose not to disclose their method but will not be eligible for the milestone prizes  \r\n",
      "    Correct Hi Willem\n",
      "\n",
      "to what extend the results have to be identical for example small differences in the random number generator may give different results although they should be similar\r\n",
      "\n",
      "They do need to be identical   You can give your random number generator a seed to make sure the resultls are the same each time  \n",
      "\n",
      "in how much time should the results be reproduceable my current best result is a mix of many models each may take minutes to hours to generate\r\n",
      "\n",
      "There is no rule about execution time     \n",
      "\n",
      "the algorithm should produce similar results on a new dataset this doesnt sound very realistic I dont think there is any way to win this competition without optimizing for this specific dataset   Results on other datasets may be very bad with the\r\n",
      " given optimizations   Probably very good results can be produced by the same algorithm after some tuning but this is a process that requires a lot of knowledge about the used algorithms and a lot of time and patience  \r\n",
      "\n",
      "Not sure I follow why this is an issue   Remember the Milestone prize is judged in a portion of the test dataset that participants have not been given any feedback on   Perhaps Im misunderstanding the concern  \n",
      "HTH\n",
      "Antthony Regarding the requirement that solutions be identical\n",
      "Willem it would be better to have participants spend time on innovation rather than reproducibility however its important to have strict rules so that the competition remains as fair as possible  \n",
      "B Yang with regards to the compiler issue we can address it if the issue arises   For example we might start by ensuring that the same compiler is used for verification  \n",
      "Sali Mali it is exceptable to describe the algorithm and not how it is derived   We are seeking clarification from HPN on the inconsistency that you describe   Apologies for the delay  \n",
      "Regarding the requirement that the algorithm perform similarly on a separate dataset\n",
      "This is best answered by explaining the rationale behind the rule   It is there to catch any cheating or blatant overfitting   If youre not blatantly overfitting then youre likely to be on safe ground    Hi all\n",
      "Not ignoring this thread   Just seeking clarification from HPN on one issue   \n",
      "Anthony Sorry for the delay on this was just clarifying some issues with HPN  \n",
      "\n",
      "Is it inconsistent as Sali Mali pointed out in another thread to require documentation of the winning algorithms be publicly disclosed to all competitors given Rule  Entrant Representations  It seems that this disclosure will encourage other competitors\r\n",
      " to use aspects of the winning Prediction Algorithm which cause violation directly or otherwise of i  iii and possibly iv of that Rule  \r\n",
      "\n",
      "Rule  does not apply to the extent that it prevents a competitors other than a milestone prizewinner from using code published by a milestone prizewinner in accordance with competition rules and b a milestone prizewinner from competing subsequently\r\n",
      " in the competition using code for which it was awarded the milestone prize  \n",
      "\n",
      "Can you clarify that code libraries and software specifications are not required to be publicly disclosed to competitors  These materials and intellectual property appear to be referenced separately from Prediction Algorithm and documentation  \r\n",
      "\n",
      "\n",
      "Chris correctly points to Jeremys response in an earlier forum post\n",
      "“Only the paper describing the algorithm will be posted publicly   The paper must fully describe the algorithm   If other competitors find that its missing key information or doesnt behave as advertised then they can appeal   The idea of course is that\r\n",
      " progress prize winners will fully share the results theyve used to that point so that all competitors can benefit for the remainder of the comp and so that the overall outcome for health care is improved  ”\n",
      "\n",
      "\n",
      "\n",
      "Will Kaggle or Heritage have a moderation or appeals process for handling competitor complaints  From the winning entrants pointofview they would not want to be forced through the review process to allow backdoor answers to code and libraries which\r\n",
      " accelerate a competitors integration of the winning solution   \n",
      "\n",
      "Kaggle and the HHP judging panel will moderate the appeals process  \n",
      "\n",
      "\n",
      "Can you comment on the spirit and fairness of the public disclosure of the Prediction Algorithm documentation and its impact on competitiveness  In particular if the documentation truly does meet the requirement of enabling a skilled computer science\r\n",
      " practitioner to reproduce the winning result then this places the winning team at an unfair disadavantage all competitors will have access to their algorithms and research in addition to the winning algorithm  \r\n",
      "\n",
      "\n",
      "This rule is in place to promote collaboration   Those who would prefer not to share can opt out of the prize  \n",
      "\n",
      "\n",
      "Can you provide more detailed clarification on the level of documentation required by conditional milestone winners  The guideline provided by the rules would cover a range of details and description spanning from lecture notes to detailed tutorial\r\n",
      " to whitepaper to conference paper etc   \n",
      "\n",
      "Hopefully this was adequately dealt with in Jeremys response requoted above   Let me know if further clarification is needed  \n",
      "\n",
      "\n",
      "Can you comment on the reproducibility requirement  For example it is possible to construct algorithms with stochastic elements that may not be precisely reproducible even using the same random seed is it sufficient for these algorithms to reproduce\r\n",
      " the submission approximately  What if they dont reproduce exactly or reproduce at a prediction accuracy that is worse than the submission score possibly worse than other competitor submissions  \r\n",
      "\n",
      "\n",
      "Exactly reproducibility is required    John\n",
      "Only the lowest of the five entries count   Note for the milestone prize only one can be selected  \n",
      "Anthony If you were  per cent sure that somebody would spend  days in hospital in Y and  per cent sure they would spend  day in hospital than you might predict that they spend would    days in hospital   pham you do not have enough detail in the claims data to reproduce the DIH properly   Youve likely reproduced DIH from claims data as accurately as is possible    SirGuessalot thanks for the pointer   Its been added to our issue tracker   I must admit we have higher priority issues to tackle but well get there eventually  \r\n",
      " Just to keep you all in the loop the plan is to announce the milestone prize winners at OReillys Strataconf    Will let you know the exact date as soon as\r\n",
      " were told     Full milestone prize rankings will be released after the announcement is made   Provisional milestone prize winners will receive an email over the weekend   An announcement will be made at Strataconf on September \n",
      "   Correct   Congratulations team Market Makers and Willem Great coverage in the Wall Street Journal here\r\n",
      "   For those interested heres the footage from the award ceremony\r\n",
      "   Jason the anonymization guys have withheld this information intentionally to make the data set more secure   Sorry Hi all  \n",
      "HPN are currently looking for data scientists\n",
      "Heritage Provider Network  the sponsor of the Heritage Health Prize  is looking to hire data scientists to take its data and analytics department to the next level    If you are interested in healthcare join the largest physicians group in California\r\n",
      " and one of the largest in the United States and use your data mining skills to make a difference in the provision of health care to individuals throughout Southern California  \n",
      "If interested please send an email indicating your interest to \r\n",
      "datascientistheritagemed  com  \n",
      "Anthony  Does being a member of HPN mean you usually referred to an innetwork provider of say lab testing unless obviosuly it is some specialty unavailable Yes  Can you be a member of HPN and have govt sponsored insurance eg Medicare MediCal Yes for\r\n",
      " Medicare   I can follow up on MediCal if you like Have passed these questions onto HPN   Will respond as soon as I get an answer    \n",
      "We are aware that the rules havent been as clear as we might have liked   Please be reminded that\n",
      "\n",
      "you cannot sign up to Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and\r\n",
      "privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  \r\n",
      "\n",
      "Weve reached out to several teams about this issue   Please let us know ASAP if you have multiple accounts and weve not reached out to you  \n",
      " Entrants are welcome to use other data to develop and test their algorithms and entries until  UTC on April   if the data are i freely available to all other Entrants’ and i published or a link provided to the data in the “External Data” on this Forum topic within one  week of an entry submission using the other data    Entrants may not use any data other than the Data Sets after  UTC on April   without prior approval   On October  the judges in their sole discretion decide whether or not the documentation is sufficient taking account of the comments made on this forum   If they decide the documentation is not sufficient they can impel the winners to address their\r\n",
      " concerns in the seven days following October    If the winners are asked to resubmit participants have another  days from November  to raise any additional complaints   \n",
      "The judging panel are experienced academic reviewers\n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  Hi all\n",
      "We are in the process of liaising with the judges   Well report their decision as soon as we have everybodys feedback   Hi guys \n",
      "Glad you like   This dataset reminds me of the RTA data which was really popular  \n",
      "On the IP question when no rules are explicitly stated the Kaggle \r\n",
      "terms and conditions prevail   Specifically clause   \n",
      "By accepting an Award you agree to grant a license to the Competition Host to use any Model used or consulted by You in generating Your Entry in any way the Competition Host thinks fit   This license will be nonexclusive unless otherwise specified  \n",
      "Anthony libraryrandomForestsetwdCUsersantgoldbloomDropboxKaggleCompetitionsCredit Scoringtraining  read  csvcstraining  csvRF  randomForesttrainingctrainingSeriousDlqinyrs                   sampsizecdo  traceTRUEimportanceTRUEntreeforestTRUEtest  read  csvcstest  csvpred  data  framepredictRFtestcnamespred  SeriousDlqinyrswrite  csvpredfilesampleEntry  csv Alec setting the random seed is a good idea  \n",
      "Domcastro your hypothesis is correct    Youre correct   Shouldnt include headers    We have made a slight change to the Terms and Conditions adding   \n",
      "\n",
      "No individual or entity may share solutions or code for any competition or collaborate in any way with any other individual or entity that is participating as a separate individual or entity for the same competition   The foregoing shall not apply to any\r\n",
      " public communications such as forum participation or blog posts  \n",
      "\r\n",
      "We are also aware that the rules havent been as clear as we might have liked   From now on before you download the data for any new competition you will be reminded that\n",
      "\n",
      "you cannot sign up to Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and\n",
      "privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  \n",
      "\n",
      "Weve reached out to several teams about this issue   Please let us know ASAP if you have multiple accounts and weve not reached out to you   It is a mistake  were sorry for it but weve decided not to correct it because it might not be fair to some contestants if we change the data midstream  \n",
      "Shouldnt be too importantonly happened to  chunks  \n",
      "Its the same mistake that caused a few chunks to have some missing data within the chunks\r\n",
      "\r\n",
      "   Sounds like theres a thriving community in Melb which looks to have been the strongest performing city   Congrats all Donovan weve looked into this and it turns out that a bug with our process meant that we hadnt received the past few weeks of queries   Weve found your email and you will receive a response shortly as will others who slipped through the cracks   Apologies\r\n",
      " to you and others who have not received a response as a result of this error   Why does lower bound get mentioned so much more than upper bound Thanks for the thoughtful comments   \n",
      "First off as always we will not make retrospective changes to how we handle past competitions including this one   When issues like this come up we use it as an opportunity to evaluate how we might improve in the future  \n",
      "Internally our debate focused on three issues  \n",
      "\n",
      "recognition for those who completed stage one but not stage two \n",
      "achievements and how the competition appears on profiles th out of  looks more impressive than th out of   \n",
      "how points are handled  \n",
      "\n",
      "   recognition for those who completed stage one but not stage two\n",
      "We need to view the stage one leaderboard as having no weight if it gets a weight we incentivize overfitting or hand labeling for stage one  \n",
      "   achievements and how the competition appears on profiles\n",
      "If we did what Julian suggests and add stage one participants to the bottom of the stage two leaderboard we undermine our rankings by making it very easy for somebody to get an impressivelooking top  achievement by finishing th out of  with a naive submission   \n",
      "     how points are handled \n",
      "The one change we will make in future is the way points are handled   We will add a multiplier to the number of points for a twostage competition   We have not settled on a formula for doing this yet but commit to communicating it clearly in the rules of the next twostage competition  \n",
      "These are difficult issues but we think this approach strikes the best balance between competing considerations    Just a heads up that were still working through the winners solutions   Will need more time to before announcing the final results as official    Quick update We will announce the official results on Wednesday March  at am ET    Julian responded in the other thread \n",
      "   Hi all\n",
      "The results on the final leaderboard are now official   Congratulations to the winners and all involved   This is among the hardest and most ambitious competitions weve hosted   We couldnt be prouder of the results   \n",
      "The competition has received some press coverage with a chance of more to come\n",
      "  \n",
      "  \n",
      "Anthony Love it Interesting that for everyone other than Woodrow Wilson the names popularity monotonically declines over the course of the presidency   \n",
      "Dwight looks like it increases in popularity during WW which makes sense   One suggestion is to add years to the x axis label for each chart to make things like this easier to spot   I Tweeted this script and somebody replied asking \n",
      "Is there a corresponding drop in the name frequency of the losing presidential candidate right after the election   I was thinking another interesting extension would be to answer the question Whats most influential in determining baby name trends out of  \n",
      "\n",
      "Presidents and first ladies   \n",
      "Musician that was  for longest on the billboard charts in a given year  \n",
      "Best actoractress in the Oscars  \n",
      "Basketball football baseball MVPs  \n",
      "Nobel prize winner names  \n",
      "Time person of the year\n",
      "\n",
      "If nobody else tackles this I might try it   \n",
      "This builds off a conversation I had with my coworker Meghan who said itd be interesting to see whether Presidents or royal babies had a bigger impact on baby names   Nicely done and fun writing style   \n",
      "One additional conclusion is that real data is messy    Big Data Borat captures it best \n",
      "In Data Science  of time spent prepare data  of time spent complain about need for prepare data   \n",
      "   Ive played with PCA before but never association plots or MCA   Glad to see an example usage and be able to add these to my toolkit   Thank you\n",
      "For the association plots I assume the width of the box refers to the number of Tweets referring that that airline\n",
      "I assume    is the proportion of comovement explained by the first dimension   Is that correct Is it typical for the first dimension to explain so much of the comovement Any thoughts on how to interpret this dimension \n",
      "Small nit You might want to change res to reason   I initially assumed res stood for residual   And reduce the font size for the x axis label on plot    Thats the most interesting plot to me but its hard to read the labels because they overlap    From this page\n",
      "   This is a nice notebook   \n",
      "Suggestions\n",
      "\n",
      "To make this easier to follow for those who havent yet looked at the data itd be great if you added a section showing a few rows   Or possibly even a few exploratory chartshistograms   Perhaps after the Loading the data section   \n",
      "Itd also be nice to see the before and after you preprocess the data ie before and after the Using textmining to format our data section   \n",
      "Rename the Using textmining to format our data to something like Cleaning the data  \n",
      " Great I always look at the top rated notebooks before looking at the data because the notebooks usually give me a sense for whats in the data and what I could do with it    This is great   \n",
      "Im surprised North America is not higher for sugar   The sweetness of food was one of the first things I noticed when we moved to the US from Australia   Although it could be because a lot of the sweetness comes from high fructose corn syrup which is not captured    Its awesome Really nicely put together   Bluefool I thought you came out really well    Interesting how noisy the very early years are   I suspect the s data is very poor quality    Really nice script   \n",
      "Interesting to see the temperature uncertainty chart   Gives a nice visual of when the data starts becoming more reliable   \n",
      "Also nice idea to put dt into a variable importance plot to see its relative important   Obviously would have been more interesting if wed provided more data   \n",
      "One suggestion is to better label your plots   Theres some good stuff here but it stakes a while to figure out what each chart is showing I actually looked at your code to figure it out   I suspect this script will be more popular with some labels that make it easier to follow    Sven have you been able to figure out an interpretation of this chart Thanks   Itd be helpful if you labeled the charts and possibly added sub label pointing to your interpretation    It may not be useful for the reasons you mention but it looks nice    Would be cool to see the by city version   I assume you didnt use it initially because of the size of the data set BTW I assume red  hot Would be helpful to have a key    Is this a work in progress Or is there an error The charts are showing up blank for me   Cool   As someone who lives in San Francisco Im curious    Juanchaco this is neat but itd be easier to follow if you added a description between charts   At the moment Im scanning the codecomments to try and figure what each chart is showing    Ha   Id not known about this   For others    Akshay this script would be more interesting if you found a neat way to visualize temperature by country    Love this chart And the title is funny   \n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['clean_messages'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data looks good, but the Kaggle forum messages are almost cleaned except there are certain words that are fused together like `'mindAnthony'` and `'CommunityForum'`. I will need to split those words apart before I stem or else it won't work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to split string by uppercase\n",
    "def split_uppercase(text):\n",
    "    text_list = text.split()\n",
    "    new_list = []\n",
    "    for i in text_list:\n",
    "        if i.isupper() == False: #don't split acronyms\n",
    "            word = re.sub(r'([A-Z])', r' \\1', i)\n",
    "            new_list.append(word)\n",
    "        else:\n",
    "            word = i\n",
    "            new_list.append(word)\n",
    "    words = ' '.join(new_list)\n",
    "    return words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg['clean_messages'] = forum_data_agg['clean_messages'].apply(split_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The public leaderboard is only indicative because competitors can use information on their score to get information on a portion of the test dataset  The final results are a quite different and b better reflect actual performance  Hi  Tanya  Kaggle will maintain a rating system  If you win but youre ineligible for prize money you will still get a strong rating  Anthony  Giovanni Thanks for your feedback  Using the forum to give feedback is a good idea  It allows others to see and comment on suggestions  We might set up a proper feedback forum but for the moment this topic will have to suffice I also agree that the forum is a bit clunky  However we have a large list of feature requests and only limited resources for the moment it might take us some time to address this  Apologies I dont think the prize money in this competition is that relevant the prize is relatively small  Correct me if  Im wrong but I think contestants are driven by intrinsic factors A karma system that rewards forum posts is a good idea  Again apologies for any delay in implementing this there are lots of features on our to do list  Anthony  Manish thanks for the feedback  The site is hosted on an  Amazon EC server on the east coast of  America  Its a fast server but the site has been more popular than we expected  Were currently working on speeding up the site by reducing the number database queries  We may have to implement auto scaling if the site keeps growing so rapidly  Anthony  Just made a change which should speed things up  Let me know if it has made a difference for you  Jonathan thanks for your feedback x  Were currently working on caching database queries  There are a lot of good suggestions here that well try before autoscaling  Colin the choice of scoring system was quite deliberate  Will the competition host considered using  Area  Under the ROC  Curve where participants submit probabilities but said that he deals with physicians who just want to know the proportion of predictions that are correct  Rajstennaj and  Colin were really pleased that you believe that theres value to the project  Let me know if there is anyway that we can help to facilitate a community  We did set up the general  Kaggle forum under  Community Forum with such a community in mind does it provide sufficient infrastructure  You are free to start any new threads on that forum  Regards Anthony  Thanks for participating in this competition  Ive attached the solution file to this post UPDATE  The solution is no longer attached but youre welcome to make submissions to this competition  Hi  Matt I believe that  Will the competition host is preparing a blog post that discusses some of the methods that people applied to this competition based on the feedback we received  Is this the sort of thing you had in mind Anthony  Here are some papers that analyze  Eurovision voting patterns  You might find some of them helpful  Gatherer  Comparison of  Eurovision  Song  Contest  Simulation with  Actual  Results  Reveals  Shifting  Patterns of  Collusive  Voting  Alliances  Eurovision  Song  Contest  Is  Voting  Political or  Cultural  Ginburgh and  Noury  Suleman  Efstathiou and  Johnson  Eurovision  Song  Contest as a ‘ Friendship’  Network  Dekker  More research enjoy Love thy  Neighbor  Love thy  Kin  Voting  Biases in the  Eurovision  Song  Contest culture and religion  Explaining the bias in  Eurovision song contest voting  Hybrid  System  Approach to  Determine the  Ranking of a  Debutant  Country in  Eurovision  Eurovision  Judgment  Versus  Public  Opinion –  Evidence from the  Eurovision  Song  Contest  Here is the solution file for anybody interested I accidentally deleted the following post made by another user  Im reposting it on their behalf Are there categorical andor binary variables in the data set  Other than the target variable  For instance  Variable Open in test data seems to have categories  If there are categorical variables do we get to know what the categories mean Thank  You  Just to clarify the results page will show the leaderboard for all competitors regardless of whether they used future information or not  We will make an honourable mention to the leading competitor who doesnt use future information however their entry will be audited  Kaggle is currently developing a league table that ranks competitors  When it comes to this competition your position on the leaderboard which is indifferent to the use of future information will be what counts towards your  Kaggle ranking INFORMS can offer an awardhonourable mention to those who dont use future data  However the  Kaggle leaderboard will not seperate those who use future information from those who dont  Given the way the competition has been setup theres no way to prevent people from using future data  Even if the winner presents a model that doesnt include future data they may have overfitted to replicate the predictions of a model that does include future data  In theory yes  The problem is that theres no way to be certain that the winner didnt use future information  Even when we check the winning model its possible they have used a model with future information to probe the test dataset  Sali  Mali has pointed out that there is an error in the AUC calculation for entries with tied scores that is when two or more scores have precisely the same value  We will look at the problem over the next hours and will rescore all entries  Apologies Anthony  The AUC calculation glitch has been fixed and all entries have been rescored  Sali  Mali thanks again for pointing this out  Hi PG  Not sure that I fully understand the question  Are you referring to the situation where a classifier returns only or rather than a score or probability  Perhaps you can use an example to illustrate the question  Regards  Anthony  Hi PG  You should give the score for all timestamps a higher score means the instance is more likely to be a member of the positive AUC measures your classifiers ability to split the classes so you dont need to decide which scores predict positive instances and which predict negative instances  Have I addressed your concern  Vateesh thanks for sending the files  The files that you sent are actually different I also had a look at your submissions and you have a few files with the same name but different numbers  Also I was not able to replicate the problem as you describe it  Perhaps you can try again and let me know if youre still experiencing the error  Hi  Vess  This should not be a problem given the way submissions are stored  Seyhan the leaderboard portion of the test dataset is selected randomly  It is somewhat representative of the overall standings  Cole sorry for the slow response  In this competition all your submissions count  In future we will ask participants to nominate submissions  Phil that is correct  You must remember that  Kaggle hopes to do more than just host fun competitions we want to help solve real problems  This is why were reluctant to force participants to choose just one model they may make a poor choice and the compettion host may end up with a suboptimal model  Our compromise position is to allow partipants to nominate five entries a feature which well roll out for future competitions  Phil number is correct  Luck will play a part but I suspect the test dataset is large enough to limit its impact I agree in a competition like this one  But as mentioned above we want to host competitions that are useful as well as fun  An upcoming competition will require participants to predict who has prostate cancer based on variables  In a competition like that it would be a shame to miss out on the best model  Requiring participants to nominate five submissions seems like a good compromise  Hi  Cole Apologies for the ambiguity  The time is as it appears on the competition summary page adjusts according to the timezone on your computer clock so itll be  Saturday or  Sunday depending on your timezone  You can also see a countdown on the  Kaggle home page  Anthony  Durai apologies for the slow response  All up countries were represented  Here is the list in order of most participants to fewest  United  States  United  Kingdom  Australia  Canada  Thailand  India  Germany  Spain  China  Netherlands  France  Italy  New  Zealand  South  Africa  Sweden  Argentina  Croatia  Ecuador  Greece  Indonesia  Iran  Ireland  Mexico  Poland  Portugal  Russia  Singapore  Turkey and  Ukraine  Ricardo you are correct I gave the country list for the wrong competition countries were represented  United  States  Colombia  India  Australia  United  Kingdom  France  Thailand  Canada  Germany  Argentina  Japan  Afghanistan  Albania  Austria  Belgium  Chile  China  Croatia  Ecuador  Finland  Greece  Hong  Kong  Iran  Poland  Portugal  Slovak  Republic  Venezuela  Sorry for the slow response  Ive been flat out with the new site launch  Below is the list of rows used to calculate the public leaderboard  Phil I made an error in the ten per cent listed above try scoring with the following rows  Yuchun Apologies for this error  The public leaderboard is portion of the test dataset is actually the first per cent because we hadnt implemented the code to select a random portion of the leaderboard yet  For info the reason we kept getting different per cents is because the random seed in the database was set to zero which told our code to choose a random random seed  Anthony  Please use this topic to give us feedback  If youd rather do so in private email me at anthony goldbloomkaggle com  Thanks for the feedback  What sort of features do you have in mind  Or can you point to a forum that you we should emulate I just added a quick reply box to make the forum less clunky  Great suggestion I have put this on our extensive features to add list  Hi  Matt Thanks for the nice words and the suggestion  Ive posted the solution file  Good suggestion  Were open to ideas on how we can facilitate this  My thinking is the best thing to do is to implement a more functional forum which were doing  We can then encourage those who are still working on the problem to continue to use the competition forum as a way to collaborate  Use this topic to discuss any competitions you would like us to run  If you would rather contact me privately email anthony goldbloomkaggle com out of thats pretty impressive  Pity they didnt enter the  Kaggle comp I think youre right some competitions exhibit more regularities than others  Soccer may be a difficult sport to model  David this is a great suggestion  The HIV competition shows that  Kagglers can do great things  My initial concern with any public dataset is that people can look up the answers  We would need researchers to withhold a small portion of the dataset for evaluation I think the first step is to get in touch with those who set up the  Alzheimers project  It also makes sense to contact the  Michael J  Fox foundation  If anybody has any connection to either of these projects please let me know  Otherwise  Ill keep you posted on any progress  Anthony  Hi  David I have written to the  Alzheimers  Disease  Neuroimaging  Initiative ADNI and the  Michael J  Fox  Foundation I am scheduling meetings with both for  September  Will keep you posted on any progress  Can you put up a link to the datapaper you found Thanks again for the suggestion  Its great if we can use the power of this platform to tackle meaningful problems  Regards Anthony  Thanks for the nice wishes  Of course  Kaggle wouldnt exist without a brilliant community of data scientists who can solve really challenging problems  Looking forward to seeing what we can do in  This is the photo from the  Kaggle office  This lunch was one of the highlights of my six years of  Kaggle  Not something I will forget in a hurry  Hi  Dirk The  Elo  Benchmark is based on the training dataset only  Having had many email conversations with  Jeff I can tell you that the seed ratings matter a lot  Youll notice that  Jeff made two submissions for the  Elo benchmark thats because hes refining his seeding method I believe he plans to make a few more refinements  Jeff uses an iterative process to seed the rating system  For example he might start by giving everybody and then letting  Elo run for months  He then seeds  Elo with the month ratings and runs  Elo again  He does several iterations of this  Does this help Anthony  Has anybody tried  Trueskill yet probably a better starting point than  Elo  This blog post does a nice job of stepping through  Trueskill  Hi  John Have just confirmed with  Jeff methodologies will be shared publicly  Regards Anthony  The competition has been designed to make cheating really difficult  At the end of the competition the winners methodologies will be replicated to help ensure everything is above board  Hi  Matt The reason we prevent participants from submitting an unlimited number of times is because otherwisea our servers may not be able to handle all the traffic anda it would be easier to decode the portion of the test dataset thats used to calculate the public leaderboard  The technique you describe often referred to as cross validation is very sensible and we encourage others to use it  Anthony  Uri you raise an interesting point  However is five months long enough for somebodys rating to move enough for you to notice this JPL a competition using internet chess data is a good suggestion  For interest the reason we are running the competition using top players is because  Elo ratings matter most for top players since it is used to determine who can play in which tournaments  Jase the score on the full dataset is calculated onthefly so we actually know who is winning based on the full test dataset  Ron the submission that is performing best on the public leaderboard may be different from the submission that is performing best on the full test dataset  We dont link the best submission on the public leaderboard to the best overall submission so that participants dont become confusedconcerned if their scoreposition on the public leaderboard worsens  Leigh my thinking as well  In a tradeoff between having a veracious public leaderboard and a veracious end result the end result is most important  Jeff good suggestion  Ive put together an  Excel sheet that might be helpful for cross validation  You paste your predictions for months into column G and it aggregates by player by month and then calculates the RMSE  Hope its helpful  Anthony  Ben The evaluation method was chosen because  Jeff has found that scoring based individual games with RMSE unduly favours systems that predict a draw  Mark  Glickman raised another issue RMSE is better suited to normally distributed rather than binary outcomes  So in order to use RMSE aggregation is preferable  Of course we could have evaluated on a game by game basis using a different metric  My biggest problem with the current evaluation method is that counting a draw as half a win seems a little arbitrary  However in order to benchmark  Elo such an assumption is necessary  Mark and  Jeff argue that a draw is generally worth half a win so this assumption isnt too problematic  Anyway hope this gives you some insight into our thinking  Regards Anthony  Jeff please correct me if  Im mistaken but I believe systems that predict draws are favoured because a high proportion of games are draws at the top level per cent in the training dataset  Of course you can do better but a system that predicts for every game will perform better than it should  Matt am interested in your thinking on this  Why MAE over MSE or RMSE  Is it just that the metric is more intuitive or something subtler  Out of interest has anybody entered this competition using  Glicko  Glicko or  Chessmetrics  Are either of you happy to send me your unmodified  Glicko submission  It would be good to add a  Glicko  Benchmark team to the leaderboard  My email address is anthony goldbloomkaggle com  Would like to do the same for  Glicko and  Chessmetrics if anybody has tried those I have also contacted  Ron about using his  Trueskill submission as a  Trueskill  Benchmark  Jase I posted a link to your  Glicko code on the hints page  Its very good of you to share it  Im really surprised that  Glicko is performing worse than the  Elo benchmark  Do you think this is because  Jeff put lots of work into optimally seeding the  Elo benchmark  Or is  Glicko just not as good  Was just chatting to  Jeff  Time permitting he is going to benchmark some of these other systems  This way they will all be benchmarked on a consistent basis using the same seeding procedure and the same degree of tuning  Uri the correlation between the public leaderboard score and overall score is significantly higher now  Uri  Im reluctant to release confidence interval information because I want to minimize the advantage to early submitters  Early submitters already have the small advantage of having seen their submissions on two different public leaderboards  By releasing confidence interval information  Im giving early submitters access to information that isnt available to later entrants  Jase aside from changing the size of the public leaderboard portion of the test dataset we also selected it more sensibly so it better represents the overall test dataset  Hi  Edward  You will appear on the leaderboard as soon as you make your first submission  Hi  Edward  Try using examplesubmission csv available at and replacing the score column with your predicted scores  If youre still having trouble email the file to me anthony goldbloomkaggle com and  Ill have a look  Uri thanks for pointing out the problem  Were currently working on a big upgrade to the website the new site should be launched by the end of this month  The upgrade will involve a more functional forum  In the meantime I will try and fix this problem  Anthony  Uri  Im not able to replicate the error either on the live site or on the development version  Can you let me know if you experience it again  Hi  Hans which post  Still cant replicate the bug intermittent problems are really annoying  As mentioned were doing a massive site upgrade at the moment so thats taking up the majority of our development time  How serious is the problem  Can we live with it for the next few weeks until we deploy  Kaggle I would really like to be more active in the forums looks like theres some lively discussion happening  Ive been flat out working on the site upgrade which is only a few weeks away from launch  Anyway  Id like to share a few thoughts on this discussion  First off there is quite a strong correlation between the public leaderboard and the overall standings  Secondly the lack of relationship between the scores and the scores might indicate overfitting  This may be the case if youre experiencing a larger improvement on the dataset than the dataset  On a related point I notice that youre all performing very well  It could be that youve reached a local maximum i e the best possible score given the techniques youre using  Eric thanks for the feedback  Theres not really any reason to insist on a particular file extension  Were currently doing a big site upgrade so  Ill add this to our list of feature requests  Just to reemphasis  Jeffs point you should pay more attention to your cross validation than to the leaderboard  The leaderboard is calculated on a very small amount of data so it is only indicative  Phillipp Sorry for the delay in doing this I havent had computer access over the last few days  The  Spearman correlation between public scores and overall scores is I also calculated the correlation for different submission quintiles to make sure the relationship holds at the top it does Top  Its also worth mentioning that the trouble participants are having reflects realworld difficulties in formulating a chess rating system  This competition is not just a game but a genuine attempt to explore new approaches to rating chess players  Anthony  Out of interest why arent people rerunning old approaches that had previously been scored on the new cross validation dataset  Wil if you can get historical data from freechess org possibly by agreeing to share the winning method with them wed be happy to host a comp here  This way you could specify that the winning method must be an instant gratification system  It would also result in a system thats tuned to lower ranked players  Thanks for pointing out the error  It has now been fixed  Apologies for any confusion  Uri makes a very good point  One way we could run a competition without knowing future matchups is to have participants rate every player  Once we know the matchups we can infer predictions based on players ratings  The only downsides to this approach are  It doesnt allow for probabilistic predictions since there are many ways to map ratings into probabilities  We couldnt show a live leaderboard which helps to motivate participants  Interested in others thoughts on this particularly the importance of a live leaderboard  Philipp I dont fully understand your suggestion  Do you mind trying to explain it again  Possibly by reference to an example As a general principle tne problem with attempting to prevent people from using neural networks and the like is that participants use them anyway and then overfit other systems to replicate the neural networks results I actually think that having neural networks et al in the competition is valuable  Even if they wont be implemented as rating systems they may have some benchmarking value  Assuming they predict most accurately they give a sense for what level of predictive accuracy is possible from any given dataset  As an aside if we require participants to submit ratings and dont give them access to the matchups that theyll be scored on this should force participants to create a rating system shouldnt it BTW  Jeff re I have been and continue to be amazed by the level of participation so far I had no idea so many people would participate  Congratulations on organising such a popular competition PEW what criteria would you use to evaluate such systems B T W I think youd be surprised at the proportion of the top who are building rating systems  Ron this is fantastic  Looks like a sizable proportion of the black dots are sitting in a vertical line  Though  Im sure the  Elo  Benchmark would look much worse  Out of interest what software did you use to generate the viz ps  Im guessing the anomalies that this viz highlights e g that white is a smaller advantage for lower rated players could inform future versions of your rating system  Philipp thanks for your nice words  Hopefully having a more professional look and feel will help us attract interesting competitions with bigger prize pools  Philipp thanks for pointing out this bug  The error was only aesthetic had been accidently hardcoded into the new theme  The platform was still only permitting two submissions  Anyway the error has been fixed  Unfortunately the movie isnt out in  Australia yet weve still got another week to wait  Jason theres a bug that prevents users seeing previous scores when they have longish technique descriptions  We are aware of the problem and will fix it as soon as we can  Diogo thanks for pointing out this error  We will setup pagination on the submission page shortly  Diogo thanks for pointing out this bug  Few minor teething problems with the new site we should have them sorted out before long  Hi all Just to let you know that we have extended the deadline for this competition by just over a week  Both  Jeff and I will be travellng around mid  November so wouldnt be able to deal with the competitions conclusion  Anhony  Apologies I hadnt antipicated that this might be an unpopular move I should have canvassed opinion first  If others also disapprove I will changed back the deadline  Kaggle is not a dictatorship  The downside of changing back the deadline is that it limits our ability to generate publicity  This bothers me becausea top performers deserve recognitionb publicity for the competition is publicity for  Kaggle and more publicity more members more competitions andc it lessens the chances of getting  F I D Es attention A compromise might be to extend the previous deadline by three days to  Wednesday  November when  Jeff is offline but I am available  Thoughts  Hi  Philipp The  Chessbase articles were written by  Jeff he has a relationship with the editor  Jeff being away when the competition finishes means that its unlikely that  Chessbase will report on the end of the competition a real pity if we hope to grab  F I D Es attention  It is unfortunate that were both away when the competition ends  Obviously not foreseen when it launched otherwise we would have set a different deadline  Anthony  Jeff we must have posted simultaneously  You raise a good point  If  Philipp and others are OK with the th then we should go with the compromise date  This would mean that  Ill be available to report preliminary results and should mean were ready to report the final results by the time you return  Preliminary will be unconfirmed results from the raw leaderboard  Final results after the top ten have all agreed to share their methodology  Ive changed the deadline to the th  As for  Uri breathing down your neck remember that the public leaderboard is only indicative and that the final standings may be different  Apologies  Uri and LT seems that any reply is redundant now  Also big thanks to all those who participated in forum discussions  You helped make this a far more interesting competition  This first chart how the leading score has changed on a daybyday basis  The red line shows the  Elo benchmark and the blue line shows the leading score  The  Elo benchmark was outperformed within hours which is why its always above the best entry  Interesting to see some recent progress after a period of stagnation well done  Philipp  My guess is that any major improvement from this point on will be the result of somebody trying something quite different  This chart shows the number of daily entries  Higher early but seems to have stabilised at around per day  Happy to put up other charts if people have requests  Philipp theres certainly a largish gap between the top five  Of course this is purely indicative  What really matters is the score difference on the final leaderboard  Philipp great suggesion  Weve got a stack of features we want to implement but  Ill put this in our long term wish list I tried puting up a general forum for such discussions but found that it was very lightly used  Features in the pipeline include fixing bugs or incomplete features on the new site upgrades to  Kaggle infrastructure to allow us to score very large entries  Kaggle ranking system an  Elo for  Kagglers based on  Microsoft  Trueskill extended social networking features including live chat recent activity feeds  Philipps competition analytics suggetion and possibly some other data viz tools Competitions in the pipeline include predicting social network connections predicting the likely success of grant applications for a large  Australian  University forecasting travel times for freeways in  Melbourne  Australia predicting prostate cancer from a high dimensional dataset subject to ethics approval diagnosing breast cancer from mammographics density images also subject to ethics approval Any other suggestions  Any thoughts on what our priorities ought to be  Jason L T are you thinking along the lines of karma points for participating in forum discussions  Or would you like the forums to be more of a QA with  Stackoverflow style ratings I like the idea of guest blog posts and community tutorials  After the chess competition ends some might be interested in posting details of their workflowmethodcode LT the general forum has been taken down for the moment  When I get a little time I will attempt to revive it and start encouraging people to use it  Philipp it may not matter that people only compete in a handful of competitions because each competition contains quite a lot of information  Unlike a single chess game participants are competing against many players  Regardless well do plenty of testing with  Trueskill before implementation  As for the points system points seem a little abitrary I like the idea of ratings that account for the strength of a competitions participants I tend to agree with your point on forum participation points  The  Stackoverflow approach seem like a nice way around the problem  There are lots of directions we could take  Kaggle  But for the moment were focused on competiitons JC I agree that those who enter early have an advantage  However the main source of advantage comes from the fact that they have had the opportunity to spend longer on the problem and try more things  Philipp the current leader has made entries  If this competition took ternary scores loss win draw this would amount to possible combinations making  Phillips entries a drop in the ocean  In fact the test dataset is richer because participants predict the probability of victory  Nonetheless for future competitions we will ask participants to nominate five entries that count towards the final standings PEW we are not requiring participants to guess but rather encouraging them to rely on their cross validation when determining which models to choose  The problem with allowing people to enter many times and try many parameter tweaks is that they are more likely to accidentally overfit on the test dataset  By this I mean they are more likely to find a parameter tweak that works well on the test dataset but doesnt work as well for future chess games  On your second point you are correct to say that I am worried about statistical guessing  The requirement that participants submit code does not obviate this concern because models can be overfitted once the answers are known  In the extreme case somebody could fit a decision tree that classifies every game perfectly if they know the answers  Showing the standings but not the scores makes statistical guessing only slightly more difficult because participants are close enough that the leaderboard ordering gives meaningful feedback on which guesses are better and which are worse  As an aside it seems that I have failed to convey the message that the public leaderboard is purely indicative and that cross validation is important I would even go so far as to say that it may be problematic if the public leaderboard bears too close a resemblance to the overall standings I like  Uris suggestion  It gets around the problem that LT mentons while potentially encouraging people to try things beyond parameter tweaks  Couple of potential problems A participant exhausts the submission limit and another entrant makes and shares a breakthrough eg the use of  Chessmetrics in this competition  Anybody who has exhausted the submission limit wont have the opportunity to build on the breakthrough  This seems less than ideal given that we want to get the best results possible  It might encourage people to make all their entries at the end so that they dont reveal the strength of their hand  What do others think  Philipp  Kaggle has been experiencing a massive lift in site visits and signups since the new site launched from unique visitors to  This accounts for the increase in entries  Thanks everyone for making this an amazing competition Big congratulations to the winner  Outis  Also to the runner up  Jeremy  Howard who only joined the competition late in the piece and to  Martin  Reichert who finished third  Hopefully well get some of the top ten to tell us about their methods on the blog  In the meantime I encourage you all to tell us a little about what you tried on the forums  Also for interest heres a chart that shows how the best score evolved over time  Rapid improvements initially but after a month progress stalled as participants approached the fronteir of what is possible from this dataset I think I can help with this I dont give names just score combinationsscore publicscore  Jeff can I post the test labels on the forum I only seem to have the aggregate solution on hand attached  Jeff do you have the game by game labels Edit looks like you posted a minute before me  Really nice feedback very thought provoking  The API suggestion is nice  It does seem that it would prevent people from using the future to predict the present  However the testtraining split is still necessary to prevent overfitting and we could still only give partial leaderboard feedback the API doesnt secure against overfitted parameter tweaks  Also the API approach would add new problems models will take longer to run because of the delay in receiving data points as you say it would add a huge load on  Kaggles servers  As for the problems you list here are my responses Predictions can’t use all available prior data since the test data doesn’t provide results This is necessary to ensure against overfitting  If all the data is used to calibrate a model its impossible to know if the model will fit future datasets as well  Limited training and test data creates too much variance between the public score and actual score The mistake made in the first competition was with the size of the public leaderboard portion of the test dataset my fault not  Jeffs  It was too small which lead to the low correlation between public and overall scores  For the RTA competition we raised the proportion to ensure a stronger correlation  This proportion was calibrated after some testing of the correlation between the two parts of the test dataset  We intend to continue this practice going forward  Model parameters can’t be tuned because actual scores aren’t provided  If we allowed parameter feedback on the whole test dataset this would almost definitely lead to overfilling parameter tweaks that work on the test dataset but wont work for for future datasets  Number of submissions is severely limited because they are so large this will become a bigger problem as larger test datasets are created I dont think more daily submissions are necessary because the majority of model building should be done with reference to a cross validation dataset  Leaderboard doesn’t reflect actual leaders Again this was my mistake I made the public leaderboard portion of the test dataset too small  This is not a flaw with the general approach  Future data can be used to predict the past Jeff suggested a really nice solution to this test set includes some spurious games so that people can’t mine the test set for useful data about the future  These spurious games wouldnt be used in final evaluation  The API also provides a really nice answer to this problem  Hi  Dirk Weve updated the data description thanks for the pointer  The competition does require participants to forecast the next four observations  Weve updated the format of tourismdata csv so that there is always a value in the last row  Regards  Anthony  Hi  Greg Apologies there was a bug that cut off the last characters  The problem has been fixed but unfortunately the fix will only apply future submissions  Thanks for pointing this out and sorry for the inconvinience  Anthony  Greg thanks for pointing this out  Im currently traveling but will look into this over the weekend  Greg this problem has now been fixed  Thanks again for pointing it out  Dirk I just changed the file posted on the  Data page to a unix format  Hope this solves the problem  Hi all Wondering why the benchmark is still leading when it is publically available  Have people had trouble replicating the authors methodology  Or is everybody trying their own approaches  Anthony  Something was amiss  There was an error in the data uploaded on  Kaggle  Kaggles fault not the authors  The changes are not particularly big so models that performed well on the previous dataset should continue to perform well  To give you the opportunity to rerun your models and make new entries we have extended the competition deadline by two weeks and lifted the daily submission limit to three per day  And I believe  George intends to release the code used to create the benchmark  Apologies for the error  Dont hesitate to ask if you have any questions  Hi  Jesse You are correct this is instruction is wrong  The monthly columns mm should be lines long including the header and the quarterly columns qq should be lines long  The examplesubmission csv file available on the data page gives an example  Im at a conference today but will correct the instruction as soon as I get the opportunity  Dirk  Ive changed the line break format  Let me know if this doesnt fix the problem  Tim  Kaggle is currently in the process of putting together a league table which ranks participants based on competition performances  If you perform well in this competition it will count towards your ranking  Hi  Markus I can help out on the second part of your query  Ive posted some PHP AUC code on another forum post software packages like R have easy to use packages that calculate AUC  Anthony  Steffen you can enter using a model coded in any language  John Drew I presume those who enter using software other than R are still eligible for prizes  Hi  Artem For the intuiton behind AUC have a read of the evaluation page  Kaggle implementation of AUC works roughly as follows  Sort submissions from highest to lowest  Goes down the sorted list and for each prediction plot a point on a graph that represents the cummulative percentage of class A predictions against the cummulative percentage of class B predictions  Join up all the points to form a curve  The AUC is the area under this curve HT  Phil  Brierley for this explanation  William no thresholding is required which is part of the beauty of AUC  In fact given that the algorithm works by sorting participants make submissions containing any real number higher means more confidence that the observation is of the positive class  Hope this response doesnt serve to confuse people  Anthony  Artem  Ive gone through the steps using your example data  Let me know if  Ive made any errors  The  Kaggle algorithm basically works as follows First order the data predicted real  Then calculate the totals for each class in the totals totals  Initialise the cumulative percentagespercentslast percentslast  Iterate for each solutionsubmission pair counts counts counts counts percents countstotalspercents countstotalsrectangle percentspercentslastpercentslasttriangle percentspercentslastpercentspercentslast area area rectangle trianglepercentslast percentspercentslast percents So in your example First submissionsolution paircounts counts percents percents triangle rectangle  Cumulative area percentslast percentslast counts counts percents percents triangle rectangle  Cumulative area percentslast percentslast counts counts percents percents triangle rectangle  Cumulative area percentslast percentslast counts counts percents percents triangle rectangle  Cumulative area AUC  Also heres  Kaggles PHP code to calculate  A U Cprivate function  A U Csubmission solution arraymultisortsubmission SORTNUMERIC SORTDESC solution total array A B foreach solution as s if s total A elseif s total B nextissame thispercent A thispercent B area count A count B index foreach submission as k index if nextissame lastpercent A thispercent A lastpercent B thispercent B ifsolutionindex count A else count B nextissame ifindex countsolution ifsubmissionindex submissionindex nextissame mycount if nextissame thispercent A count A total A thispercent B count B total B triangle thispercent B lastpercent B thispercent A lastpercent A rectangle thispercent B lastpercent B lastpercent A A rectangle triangle area A AUC area return AUC  Thanks B  Yang  The benefit of publishing code is that you get sensible suggestions in return  Hi  Jon Its a fixed per cent chosen randomly  Anthony  Hi  Tamas As your results suggest the order does matter and the  I Ds dont  Anthony  You can email me the file if you like anthony goldbloomkaggle com  Id be happy to take a look at it  William thanks for the question  Teams are allowed to merge  One individual cannot be part of several teams our systems ensure this anyway as long as somebody doesnt have multiple accounts  Agree that we should make this more explicit in the future  As for finding people who submit from multiple accounts we are actually in the process of implementing rules that alert us when it looks like this is happening  In the future for large prize money competitions we may look at verifying identities  Apologies  Will I was on a plane and only just got your message  Will make the adjustment this afternoon  Id also like to congratulate the top teams and congratulate  Dirk for running an excellent competition  Thanks to everybody who participated and a big thanks to  Dirk for putting together a really nicely designed competition  The test labels are attached to this post B  Yang first off congratulations again on a fantastic performance Your frustration is understandable but we cannot enforce rules that dont exist what is common sense to some is not common sense to others  As  Jeremy points out in the RTA competition the rules say  The winning entry has to be a general algorithm that can be implemented by the RTA  An algorithm that involved looking up future answers could not be implemented by the RTA  Hi  Nick Youre welcome to bring additional data as long as its publicly available  Anthony  This is something that should be dealt with on a case by case basis  If you find a dataset youd like to use ask on the forum and  Ill run it by the RTA  For information  Im trying to get hold of some incident data  Will keep you posted on this  Vitalie the volumes data is used to calculate travel time see this post for more info  Our priority at the moment is to get the incident loop error and route length data together  However I can find out if this data can be made available if you think it might be useful  As  Dennis says itll be highly correlated with travel time and we obviously wouldnt release it for the blanked out times  Jeremy I wasnt aware that public documents with traffic details were available  To the extent that any information is available for blanked out times this would most definitely be considered cheating  As for question I am aware of this in fact the issue came up in another post  The rules state that the winning model must be implementable by the RTA in order to be eligible for the prize  The averaging model passes this test  As an aside I dont believe the temporal leakage invalidates the algorithms developed in this competition  Alexander to me this means that the algorithm can take a timestamp as an input and can generate forecasts for the next mins mins etc  Lee thanks for pointing this out  This post post  Jose do you want me to ask if its permissible to use NOAA data  If so are you asking about the data that  Brad mentions above  Jose and  Joseph just spoke to the RTA about this  The answer is no because it might allow future weather conditions to be used to predict the present  Attached is some sample code that can be used to constuct an entry that generates a forecast based on the average travel time on a given route on a given day of the week at a given time  Mmm file didnt attached  Heres the codephprh fopen R T A Data csv r  File to read fromwh fopensample Historical csv w  Write the entry to this filedatedefaulttimezoneset G M T  Purely to prevent the interpreter from raising a warningtime Stamp array an  Array with the humping off pointsforecast Horizon array forecast horizon in lots of minutes e g minutes minutes hour  This is used for calculating the forecast time stampsforeach time Stamp as ts foreach forecast Horizon as f forecast Time Stamp date N H istrtotimetsf find day of week hour and minute that corresponds to each of the timestamps row while data fgetcsvrh FALSE loop through the datafile if row  Write the header col Count countdata for c c col Count c fwritewh datac fwritewhn if inarray date N H i strtotimedataforecast Time Stamp if the day of week hour and minute that corresponds to a forecast timestamp is found then save to an array called ts Array for c c countdata c if emptydatac datac x ts Arraydate N H i strtotimedatac datac rowforeach time Stamp as ts foreach forecast Horizon as f fwritewh date Ymd  Histrtotimetsf for c c col Count c fwritewh arraysumts Arraydate N H istrtotimetsfccountts Arraydate N H istrtotimetsfc writes the average for a given day of the week hour and minute to the submission file fwritewhn fcloserhfclosewh  This code does generate a sample entry  To use it a download the PHP interpreterb create a file name xxx php copy the code above and download the data files to the same directoryc run the command PHP xxx php  Youre correct the future is used to predict the present  However I dont think the temporal leakage invalidates the algorithms developed in this competition  Attached is some sample  Python code that generates forecasts based on the last known travel time  Im new to  Python so happy to hear any feedback on the code  File didnt attached  Heres the codeimport csvimport datetimerhopen R T A Data csvr read in the data whopensample Naive Python csvw create a file where the entry will be savedrh C S V csv readerrhtime Stamp an  Array with the cutoff pointsforecast Horizon forecast horizon in lots of minutes e g minutes minutes hour  This is used for calculating the forecast time stampsrow inialise the row variablefor data in rh C S V loop through the data if row if the first row then write the header for j in rangelendata wh write dataj wh writen if data in time Stamp if the row is a cutoff point for i in forecast Horizon for each forecast horizon write the cutoff travel time as the forecast the definition of  Naive date Str strdatetime datetimeintdataintdataintdataintdataintdata datetime timedeltai calculte the time stamp given the forecast horizin wh writedate Str write the timestamp to the first column of the CSV for j in rangelendata wh write dataj write the cutoff travel time to the subsequent columns wh writen row rh closewh close  Lee this is great  Dirk did the same thing with some  Python sample code I wrote for the social networking competition  If you guys keep showing me how things can be done better I may become a half decent coder  Toppy thanks for the pointer A higher priority at the moment is to get forum attachments working again  Hi  Peter  Ill follow up in this  At the very least we should be able to provide information on the length of different routes  Anthony  Armin I agree  Makes more sense for me compile this information once for everybody  Will try and get it done this week  Eleni just uploaded  Route Length Approx csv which has approximate route length data  Martin  Dane is correct the information in  Route Length Approx csv is in metres  So route is approximately km  Martin when I open the file it shows and  What application are you using Anthony  Dirk thanks for pointing this out  Ive written to the RTA about this and they responded saying Indeed our control room have confirmed significant increase in traffic volumes following the removal of the tolls  This has had an impact on the overall travel times across the M  Something to be aware of when using the older data  Hi  Dennis  The per cent doesnt count towards the final standings and is selected at random across the timestamps and routes  As for the SMTP error its been fixed  The problem was the result of a flood of signups which caused  Google to shut off our mail server  Were now using our own mail server  Anthony  The number directly to the left of the team name is the teams position and the number to the right of the team name is the teams score or  Root  Mean  Squared  Error RMSE  Apologies for the error its deciseconds not centiseconds so is seconds  Ive fixed the description  Hi  Carlos  Unfortunately not  Clause c in  Kaggles  Terms and  Conditions saysc employees or agents of the  Competition  Host are not eligible to participate in any  Competition posted by the  Competition  Host  To answer the second question we would more information about the nature of the business and what your friend does  Anthony  Frank this is great I particularly like the heatmap is it possible to zoom Also itd be neat to see some animation on the M map showing how travel times evolve over the course of a dayweek dots getting bigger and smaller  Though I suspect this might be a lot of work  Anthony C does seem to be an expressive language  Im a  Linux user though so not inclined to pick it up  Daniel  Dennis is correct in saying that averaging the values leads to floating point numbers  The answers are integers but the RMSE is calculated using floating point arithmetic  Alexander there is no truncation of floats  David I believe that when loops the measuring device fail travel times are estimated  Im working towards putting together data on when travel time readings are suspect  Andrew good discovery  Ill pass the question onto the RTA  Edit  Wouldnt it be obvious if they werent making the adjustment since peak traffic times would change  Paresh thanks for the thought provoking question I agree with  Dennis I am more interested in the time delay than the percentage delay  On a related matter we think it is more important to predict correctly when travel times are volatile e g before and after work  To favour models that predict more accurately during high volatility times we selected more high volatility cutoff points so youll notice more cutoff points during the morning and afternoon  Phil thanks for sharing this  Just got to find a  Windows machine to run it on  Aidan have asked the RTA about this  This was the response  The cutoff is due to free flow conditions imposed by the system during data unavailability  Ive written again asking for a little more detail  Will post the response when it comes I have some information on suspect loop readings that  Im working to release  This has information on when loop readings may be unreliable for various reasons I dont yet know whether or not this will help with the free flow issue  Anyway I will upload them as soon as I can get it into a useful format I suspect the reason the free flow times are different is because route lengths are different  Rob on your point about missing data it might be helpful if I explain how I put the files together I received data in the following formatroute  I Dtimestamptravel time xxx xxx I transposed them into in the hope that theyd be more manageable  When timestamps were missing I just filled in a blank row  Aaron another good question  Have also passed this on to the RTA  Daniel and  Dennis are correct  Keep in mind that the per cent is a random selection of the that doesnt count towards the final standings which are calculated based on the other per cent burak the times in sample Entry csv are the times you need to generate forecasts for  Theres more info on how the cutoff points were selected in this forum post  Mmm my message seems to have disappeared from the board  Anyway heres a repeat  Aaron the units are deciseconds  Nick actually its a hybrid approach  You can nominate five entries that count towards the final standings  You do this from the submissions page the last five are chosen by default  At the end of the competition the best of your five nominated entries counts towards your final position  And  Nick on your new question the one of the five you nominate that scores best on the per cent counts  The per cent is meaningless as far as the final standings are concerned  The cutoff times are all between am and pm  They were selected using a simple formula that favoured high volatility cutoff times over low volatility cutoff times  So youll see more peak hour morning and afternoon cutoff times  The rationale behind this is that its more important to predict accurately during high volatility times so we want to favour models that do best at these times  That explains why the RMSE is higher than for randomly chosen cutoff points  Thomas I selected specific cutoff times randomly but chose timeday combinations that are volatile across the dataset  Rasmus apologies I deleted the wrong post  Anyway you asked how travel times are measured  There are regularly spaced loops along the M  These loops measure each cars speed and the number of cars that travel across the loop every three minutes travel times are then calculated using a formula  The formula has been tested and calibrated using test cars that travel along the freeway and record their travel times  Benjamin once we get the incident data I will put in a request for this data  Hassan the most important file is  R T A Data csv  You can create a sample entry by downloading  R T A Data csv and create Historical php attached to the same directory navigating to that directory in the terminalcommand prompt running php create Historical php  This will create an entry based on a historical average for that timeday and is a good starting point BJB very generous of you to upload a  Java code  Ive now enabled java file uploads so you should be able to upload the file  Aaron you raise a good point  According to the route definitions I have route extends from loop A to loop A while route extends from A to A so should encompass all of  Denniss observation that sometimes has longer throughput times than is strange  Ill double check the definitions with the RTA  Konstantin just uploaded  R T A Error csv the is valid data  Its available on the data page  Mooma I appreciate your frustration but sensor malfunctions are part and parcel of dealing with realworld data  If we had the data ready at the outset we might have excluded failed sensors and downweighted the impact of partially failed sensors when evaluating predictions  Konstantin  Dennis is correct it is not safe to assume that there is no errors in the control data  Ahmed just got an answer from the RTA on this  Heres the response The answer is maybe RTA would request that anyone wishing to use the data for further research purposes write to the RTA and make their case describing what they wish to do ie the purpose of the research and how they would use the data  The RTA will consider each application on its merits  Let me know if youd like me to pass on the relevant email address  Im reluctant to do it in the forum but will offer an introduction to anybody who asks  Rob thanks for jumping in  Dielson good pick up  Dennis is correct the date format doesnt matter  What is important is that you put the correct data in the correct cells  Many thanks to everyone for all your great activity on this fascinating problem insightful questions and comments on the forum good early results on the leaderboard and interesting discussions  There have been a lot of questions about exactly what constitutes an acceptable model for the RTA  So far my guidance on this matter has possibly been too fuzzy and I hear a lot of you looking for more definite rules  Therefore we have come up with the following specific rule regarding the allowed model inputs  Your model can be of any form you like as long as it takes its input only from the following parameters  Time of prediction  Day of week  Is holiday  Month of year  Route number to be predicted  The time taken for route r for datetime t where r is any route and t is any time less than the datetime being predicted for as many routes and datetimes as you wish  The sensor accuracy measurements for any routes r and datestimes t defined as above  The estimated route distances as provided by  Kaggle To clarify the following are not permitted  The use of any data other than those provided by  Kaggle for this competition and the list of NSW holidays  The time taken for any routes in the future compared to the prediction being made your model can still be trained using all data as long as the resultant model only uses the inputs listed above  Furthermore the algorithm must not be encumbered by patent or other IP issues and must be fully documented such that the RTA can completely replicate it without relying on any black box libraries or systems  Hi  Alexander  No  Using full timestamp makes it possible for a model to implicitly incorporate external data and future data  You may also use holiday data extracted from the PDF file that you linked to in order to get holiday information for previous years  However we will not be providing a file of this information directly  This is correct  Anthony  As  Jeremy  Howard pointed out earlier in this thread the key point that answers most of these questions is that the limitation is only on the functional form of the final model  More specifically  Xiaoshi  Lu  You can build your model filtering aggregating etc using all the datetime information you like  The final functional form that you end up with however should only use the predictors listed above  Mooma  The inputs listed include this  The time taken for route r for datetime t where r is any route and t is any time less than the datetime being predicted for as many routes and datetimes as you wish  So what you ask is specifically allowed  Of course for you to create your input file which includes for example the time taken one hour earlier you will need to use the full datetime  However the resultant model will not directly use this instead it will only use the time taken on that route as allowed by the rules  Alexander  Groznetsky  Imagine using a very flexible model neural net for instance which trains with all datetime info included in the input parameters  It might implicitly end up using the route times later in the day to predict those earlier  This is an example of how a model could be useless in practice even although it appears highly predictive on the competition data  Matthew  Using GPL code is fine  The isholiday variable can be a direct input rather than a variable that is derived by reference to a timestamp  You contact me directly at anthony goldbloomkaggle com  Dennis you can use isspringbreak rather than isholiday  Nicholas a  Matlab solution is fine as long you dont include libraries that use patented or undocumentedsecret algorithms  Rafael and are fine is also fine as long as the data is derived entirely from the time series as you say  Jose I notice that you are now on the leaderboard  It can take a few minutes before you show up  Anthony  David its really neat  For info it works in  Safari but the page videos are aligned a little strangely  The  In the  Money indicator is based on the public leaderboard only  It doesnt reveal anything about the final standings  Reginald please email your submission to anthony goldbloomkaggle com and  Ill have a look  Wu  Wei a route is made up of several loops A figure of means that per cent of the loops in the given route are giving suspect readings  For anybody interest heres the actual solution  Nathaniel is right the data is correct its just a problem with heading formatting  Will fix this shortly and reupload the data  Finally fixed the headings  Just to reiterate all the data are correct its just the capitalization in the headings that caused trouble  As for the inconsistent numbers of delimiters also fixed my software package stopped printing delimiters when there were no more values or  N As in a row  Jack the country of birth issue is now fixed  Please download the latest version of the data  Attached is some R code to create a GLM entry for this competition  As always happy to hear feedback from others about how this could have been done more elegantly  Anthony person I Ds refers to all the columns that have investigator  I Ds e g column has investigator column has investigator  Ignore the comment numerical values that should be  No  Towards the end of this competition you will be asked to nominate five entries that count towards the final result P V  Kiran it means that if your solution is implemented using a software package that is not available to the  University of  Melbourne it must be possible to translate your solution into a different packagelanguage  Just elaborate a little the types of solutions that cant be implemented are those that are encumbered by patents or other intellectual property restrictions  Nathaniel thanks for pointing this out  Definitely worth investigating  The  Number of  Successful  Grants and  Number of  Unsuccessful  Grants fields dont change in the test dataset for obvious reasons  The journal citations also remain constant in the test dataset to prevent participants using the future to predict the past  Nathaniel I have looked at the problem in some detail and have spoken to the  University of  Melbourne  They are looking into it and hope to have an answer for us tomorrow before they break for  Christmas  The university has spent the last two days on the problem  They suspect its an internal inconsistency in their database the figures are drawn from different parts of their database  Well have to wait until the end of the  Christmas break to get a final verdict  Deepak thanks for pointing this out  We will ask the university about this as well  Unfortunately we cant expect an answer until early next year  The university has done an investigation and has found that the issue arises from an inconsistency in their database  Michelangelo truth is that you can submit any real number we suggest a number between and because of the convenient interpretation AUC ranks your scores the higher the score the more confident you are that the instance is a member of the positive class I believe it refers to grants made when the researcher was at another university  Edith thanks for the feedback  We agree with your comments and we are working on making the terms more competitor friendly  Michelangelo the per cent comes from the test dataset  Eu  Jin  Lok the sampling is done randomly  Hi  Greg The answers will be made available on the forum I can ask whether the data can be used for publishing research if you like Kind  Regards Anthony  Hi  Greg and  Suhendar The university doesnt want the data to be used for any purpose other than for this competition  Anthony  Hi  Greg It would be nice if the dataset could be used for other work  However if we dont allow competition hosts to place restrictions on the use of their data then we wouldnt get access to it in the first place  Will post the solution file now  Regards Anthony  The solution file is attached to this post  Thanks all for participating Anthony  Apologies I didnt clarify this with  Mahmoud before the launch but we have discussed this offline  This competition requires you to choose five entries that count towards the final result  To choose five entries visit your submissions page and click the star next to the relevant entry to select it  If you do not choose any entries your last five entries will be chosen by default  Hi all Submitting from multiple accounts is most definitely against the rules  We have done some analysis and found that it happens very rarely  However we are working to put the systems in place to identify and block those who attempt to do it  Kind  Regards Anthony  Harri Thanks for the thoughtful post  The IJCNN people agree with you and have decided not to disqualify  Shen  As mentioned above  Kaggle will soon have the systems in place to detect multiple accounts in real time so that such issues dont arise  Anthony I have sympathy for peoples frustrations  In this case the competition host decided that the results should stand so we are facilitating their decision  Chris makes a good point about the rules being scattered throughout the site  We will be sure to address this in future competitions  We will also ensure that they are tightly enforced  For information a lot of effort has gone into framing the  Heritage  Health  Prize rules  Finally thanks for the feedback  Its discussions like this that will help us improve  Kaggle  Kaggle has received legal advice after the controversy surrounding this competition  We have been advised that it sets a dangerous precedent for us to ignore our own terms and conditions notably clause preventing multiple signups  We have therefore acted in accordance with this clause disqualifying those who clearly submitted from multiple accounts  Thank you all for your patience on this issue and rest assured that we are working to ensure that it is not a feature of future competitions  The solution is attached  Thanks all for participating Anthony  Entries made before we fixed the leaderboard were scored incorrectly I have now rescored the relevant entries  The error was the fault of  Kaggle and not the competition organizers  Apologies Anthony  Hi  Cerin Apologies for the errors  They all stemmed from the fact that the servers hard drive filled up  Ive cleared some space  For information were currently rewriting the entire site for the  Heritage  Health  Prize  You can expect the next version to be faster and include many more features  Thanks for your patience Anthony  Hi  Cerin Ali is right your entries will count towards the final standings  Anthony  Also covered by  Slate and  Forbes and the  Wall  Street  Journal a couple of weeks ago  And  Smarter  Planet  Dorofino  Great idea  Forming a team is a really good way to learn  Are you affiliated with the  New  York R  Users  Group  For info  Ive heard rumblings about them setting up a team  Good luck with this  Anthony  Apologies this was an error  Thanks for drawing our attention to it  The missing values are for those people who have been in hospital for more than two weeks  They should be replaced with a  You can either do this yourself or download the updated dataset  For information members who have in hospital for more than two weeks have been grouped for privacy reasons they are rare so may otherwise be identifiable  The implication of this grouping is that if you expect somebody to be in hospital for more than two weeks you should predict days  This grouping should not have a big impact because a members who are in hospital for more than two weeks are rare about one per cent of members b the evaluation metric favors algorithms that accurately predict fewer days in hospital on the assumption that these are more preventable  Hi  Rich  Just spoke to HPN about this  For the moment they dont want to provide general guidance and ask that you make a request through the contact us form  Your request should detail the topic of your proposed research  Definitely worth making it clear that youre just looking to publish the method that you use to enter the competition  Anthony  Wgn the intention is not to rule out the publication of research  Ive passed on your message to HPN and a clarification will be forthcoming ashojaee the clarifications havent been made yet  Apologies for the missing values it was an error  You can either replace the missing values with or download the updated data set  If youre interested in the reason for the missing data see Y Y Y etc refer to different years  We havent revealed which years to help keep the data private  Agree  See the updated evaluation page  The years are sequential  We are not revealing what years  Yn refer to nor whether or not they refer to calendar years for data privacy reasons  Just to clarify when  Jeremy says we cleaned it as much as we can we didnt do much to the claims data on purpose  We figure it makes more sense for you to make your own cleaning assumptions rather than have us impose them on you  The criteria was that somebody had to make at least one claim in Y be eligible to make a claim in Y  Outliers have been removed from the dataset as well as those suffering from stigmatized diseases  Not only are patients who died in Y not in the dataset but patients who died in Y are also not in the dataset because they didnt remain eligible to claim for the whole of Y rudychev received an answer from HPN on this A patient who visits a clinic outside the network should be captured in this dataset  Of course as  Jeremy keeps reiterating there is always a disconnect between reality and the contents of a database  Hi bacg  Days In Hospital refers to Y the second year while the claims refer to Y the first year  Not everything that has a length of stay counts as a hospitalization  In fact you dont have enough detail in the  Claims table to calculate  Days In Hospital  The detail has been suppressed for privacy reasons  Anthony  Hi mbenjam  We would have loved to release more detailed data but have to be mindful of data privacy  Anthony mgomari one issue we have to keep in mind are the tradeoffs in releasing data  For data privacy reasons HPN have a granularity threshold which theyre not willing to breach  The data anonymization team represented by keleman in the forums are trying to release  C P T Codes probably at an aggregated level  Apparently its pretty lineball and releasng  Days In Hospital Y might put this in jeopardy I describe the data privacy considerations like a waterbed you push down on one part of the bed and it creates a bulge somewhere else  After  May youll be able to use  Days In Hospital Y and  Days In Hospital Y to predict  Days In Hospital Y ogenex even if we release  Days In Hospital Y you wont be able to do a consistency check  Not all length of stays count as hospitalizations as calculated for this competition and you dont have enough detail in this dataset to work out which count and which dont SSRC mapping LOS to DIH is impossible  Not every LOS entry corresponds with a DIH e g hospice stay  One reason somebody may have DIH in y but no claims is if they werent eligible to claim in Y in which case their Y claims wouldve been removed  Have received advice from the HPN lawyers  Im really sad to say that the answer is no on all accounts  The lawyers are taking a conservative stance on this issue  Apologies its really disappointing to have people ruled for this reason flsdcom I have a meeting with them in minutes I will be sure to raise this point  In response to ashashos original question I have sought a reexamination of the issue  The HPN lawyers explained that the reason for the hard line is that they have no way to verify that residency permits comply with US legislation  Im really sorry to say that theres not more I can do cybaea many thanks for a great discovery  After doing some digging weve discovered that the oddeven observation is an artifact of the cleaning procedure  We have worked out a remedy and it will be applied to the dataset that will be released on  May  In the meantime it shouldnt make a huge different to models that are currently being developed boegel yes  On  May we will be issuing significantly more data  Day In Hospital Y csv will be changed then  Eu  Jin youve obviously not seen this frankthedefalcos com or the women who have been treated for erectile dysfunction  Tom SF  Haines  Jeremy is not the author of the rules  He is merely trying his best to point people to the section that makes the rules as competitor friendly as possible given  H P Ns requirements  Also if you would like to publish your algorithm I strongly encourage you to put in a research request using the  Contact  Us form  The decision to predict days in hospital was made to make the test dataset richer so we can better sort out good algorithms from bad  The logarithm in the evaluation metric was chosen to favor models that predict short stays more accurately as these are assumed to be more readily preventable  As for the question of nefarious intentions I can tell you what I know about  Dr  Richard  Merkin the man behind the prize  He is a big philanthropist who devotes time and resources to funding scientific projects schools and the arts  In my opinion HPN did not need to put up million to get an amazing algorithm  Kaggle has found in its own competitions that with prizes as small as or a chess DVD participants approach the limit of whats possible on a dataset  In our communications with HPN we have been told that the million prize is an attempt to draw mass attention to this prize and the issue in general  Dr  Merkin wants to promote the potential for medical data mining in lowering healthcare costs  The prize also serves to introduce a large number of talented data scientists to medical data  Finally rest assured that HPN are working hard behind the scenes to clarify the IP issue alexx the HPN lawyers are working on a clarification  This will be released by the time entries can be made on  May  Hi  Drew  It will be in place by  May when entries are accepted  Anybody who accepted the existing rules will receive the notification via email  Anthony  The accuracy threshold will be announced when we release the full claims dataset on  May  This is a sample of the final dataset but the final dataset is not in the  Terabyte range  To the best of my knowledge this dataset is on the larger side for medical datasets which tend to be quite small  This algorithm will not need to operate in a realtime environment and so there is no restriction on execution time I want to reassure everyone that HPN is working hard behind the scenes to clarify the IP issue  It is not their intention to prevent people from using standard tools nor to discourage anyone from applying their innovative ideas to this problem  For background at  Mondays launch event  Dr  Richard  Merkin the man behind the prize spoke of the long tradition of innovation that has resulted from past prizes  He spoke of the  Longitude  Prize apparently  Newton and  Galileo had attempted to solve this problem but the winner was a self educated clockmaker from  Yorkshire  Napoleons food preservation prize won by a confectioner and resulted in the invention of canned food the  Orteig  Prize to fly nonstop from  New  York to  Paris won by the unlikely  Charles  Lindbergh  It is his hope that this prize will spur similar innovation to solve one of  Americas most vexing problems  We appreciate your patience while we await clarification  Kind  Regards  Anthony  For those who dont know jphoward was  Kaggles most successful competitor before joining the team  His tutorial gives really clear explanations of the tools and techniques that made him such a successful competitor  Hi  Jim  That is correct  For information the reason for the misnomer is that it was days when we sent it to the anonymization team but they had to group the days to ensure the required level of data privacy  Anthony sciolist yes teams are required to publish publicly mkarbowski as jphoward keeps pointing out theres often a massive disconnect between reality and the contents of a transactional database  See ejloks humorous post for even odder records  We intentionally decided against cleaning the data so as not to impose our assumptions on participants  We want the forum to be tightly integrated into the site e g to be able to link to forum posts from profiles and vice versa YAF is the best NET forum software out there and integrating it into  Kaggle is more trouble than its worth  Also moserware is a brilliant programmer so its the type of thing he could put together in less than a week DIH includes inpatient admissions and emergency room visits  As mentioned previously you dont have enough detail to calculate it from the claims table  Ralph H  Days In Hospital counts days not nights  So if  Days In Hospital is then they have not been to the hospital at all  If they were in and out of the ER then  Days In Hospital would be  Domcastro one of  Kaggles first suggestions was to remove the registration fee  For info the registration fee wasnt ever to raise money but to try and deter people who werent serious from downloading this sensitive data  Kaggle pointed out that anybody with malevolent intentions would probably still pay the modest registration fee so its effect would be to deter people who didnt think they had a chance of winning  Kaggle went on to argue that these people may also come from interesting backgrounds and may be the ones most likely to apply creative thinking to the problem  Realworld data is messy  Well put up a data dictionary soon  Days In Hospital is calculated based on the  Length Of Stay variable  However you dont have enough detail to calculate  Days In Hospital from  Length Of Stay quotedaveime  Seriously I understand the need for randomizing and anoymizing the data but unless they have some way to unrandomize it afterwards any algorithms we create will serve no real world application quote daveime the data is messy not because its been peturbed but because its realworld data  Anonymization focused on generalizing again not peturbing  The the nineyear old pregnant males actually exist in the raw data  For info  Im told that this is one of the cleaner medical claims datasets around mgomari the difference between and is counted as two days  Overlaps were accounted for so were not double counted fjn  Pi does not have to be an integer blonchar youre correct HPN are limited in what it can release by the need to protect patient privacy liveflow I may be misunderstanding the question but the competition requires participants to use data from Y Y and Y to predict Y  No  Some Y patients are no longer eligible in Y  We still provide Y patients who arent eligible in Y because theyre useful to train on  Dougie D every member listed in  Days In Hospital Y is eligible to claim in Y so if they have DIH they are above  The same will apply for the members listed in  Days In Hospital Y and  Days In Hospital Y when we release those files jesensky you will be able to use  Days In Hospital Y and  Days In Hospital Y as an input to  Days In Hospital Y I like your thinking on the USE OF OTHER DATA loophole if the answer had been no  Creative thinking mgomari the answer to both questions is yes  Information  Man that is not the intent of the rule  The HPN lawyers are working on clarifying this at the moment  No  Again for privacy reasons irwint good pickup thanks  Now fixed gschmidt not sure if this answers your question but the geographic spread is limited to the area in which HPN operates southern  California I believe  As to whether patients change doctors on  May youll have a few years worth of data so will be able to work this out  You will get some procedure code information in the  May release I understand the frustration but data privacy is a priority for HPN metaxab the competition was designed this way to replicate how the model might be used in real life  In a real life situation you wouldnt be able to predict hospitalization with contemporaneous claims  Days In Hospital Y is derived from the claims table where a hospital stay includes an inpatient stay or an emergency visit  Note you dont have enough information to calculate  Days In Hospital Y from the claims table  In this dataset missing  Pay Delay either means unknown or greater than  In the  May release the anonymization team will topcode  Pay Delay so there will be fewer missing values and will mean  For generating features I recommend  S Q L Lite though  My S Q L does the same thing I know  Jeremy and  Jeff like  Cs  Linq  For building models I use R  The rules do not prohibit  Oracle  Data  Miner rks we will post a sample entry with the rest of the data on  May trezza and RHM Y contains data for a period trezza unfortunately not  The anonymization team have identified this as a data privacy risk  Hi  Allan  Thats because some members have had claims suppressed  In release coming soon well make it clear which members this applies to  Anthony  Hi  Domcastro  Can I use R  Yes  Can I use  Weka  Yes  Can I use  Excel  Yes  If I organise the data in a novel way and just use a standard processing algorithm such as  Naive  Bayes is this OK  Yes  You must preserve the order in  Target csv  Unfortunately not  Apologies for any inconvenience  Darragh its a list of all members in the dataset  Release zip does supersede  Release zip  Chris just heard back from the data anonymization team  Members have been renumbered  No cacross HPN had a granularity threshold that they wanted to remain below  Some  L O Ss had to be suppressed to achieve this target  If there is a blank LOS and  Sup L O S is then this is how it was when it came out of the HPN dataset  If there is a blank LOS and  Sup L O S is then the LOS has been suppressed  Hope that helps mkwan you fill in the team wizard when you make your first entry  Team mergers will be granted at the organizers discretion  Chris R nice to see you competing in this  Sampling is random  Yes  Bernhard your interpretation sounds about right to me  We cant give you an HPN benchmark because theyve not tackled this problem before boegel  Days In Hospital Y contains members who made a claim in Y and were eligible to make a claim in Y  Days In Hospital Y contains members who made a claim in Y and were eligible to make a claim in Y  Similarly target csv contains members who made a claim in Y and were eligible to make a claim in Y  To be eligible means to be an HPN member regardless of whether or not a claim was made  Therefore the members in  Days In Hospital Y are not missing from target csv but rather didnt make a claim in Y or werent eligible to make a claim in Y  Therefore all members in target csv were eligible to make a claim in Y so we have an answer for each of these members JESENSKY by my calculation members appear in  Days In Hospital Y and  Days In Hospital Y but not  Days In Hospital Y perhaps you can confirm this figure  These members are missing from  Days In Hospital Y because they didnt make a claim in Y despite being eligible  Apologies if we didnt communicate this effectively in the description pages  Pro Tester theres nothing in the raw data that distinguishes a death from a patient that leaves HPN for another provider  Dan B youre right about the selection bias  But because HPN are releasing almost no information on the members themselves theres nothing to model on for patients without claims  George there are members in the dataset but you are only tested on members  Thats because the extra members arent eligible to claim in Y or didnt claim in Y  They have only been provided to help you train your model  Further to  Wills point those who followed the  Netflix  Prize will remember the jump from the  Simon  Funk discovery is the maximum  Ive said this before but I think  Jeremys tutorial is really excellent although it is not focussed on HHP  He is hoping to get the opportunity to do an HHP tutorial in the next few months  Darragh I passed your question onto HPN  Heres the reply  Is there a delay between the scheduling of the surgery and when it takes place  Yes  But that is just a matter of scheduling not something forced by the government  It would also of course depend on how urgent the surgery is  She will be added in the next release  The intent of that provision is to prevent the data being shared with those who have not agreed to the competition rules  Jeff was just referring to the measures he would take to ensure the data isnt accessible to others  Jose thanks for your diligence on this  Its difficult for us to give specific guidelines  Again HPN is just trying to prevent the data from being accessible to those who havent accepted the rules  Jim its being assessed against Y hospitalizations  Thanks  Dave  The data description has been fixed  Hi  Bobby  Can you clarify what you mean by this  Are you asking if they are obliged to share their model if they finish in first place  Anthony I have checked with HPN and a milestone prize winner can choose not to disclose their method but will not be eligible for the milestone prizes  Correct  Hi  Willem to what extend the results have to be identical for example small differences in the random number generator may give different results although they should be similar  They do need to be identical  You can give your random number generator a seed to make sure the resultls are the same each time in how much time should the results be reproduceable my current best result is a mix of many models each may take minutes to hours to generate  There is no rule about execution time the algorithm should produce similar results on a new dataset this doesnt sound very realistic I dont think there is any way to win this competition without optimizing for this specific dataset  Results on other datasets may be very bad with the given optimizations  Probably very good results can be produced by the same algorithm after some tuning but this is a process that requires a lot of knowledge about the used algorithms and a lot of time and patience  Not sure I follow why this is an issue  Remember the  Milestone prize is judged in a portion of the test dataset that participants have not been given any feedback on  Perhaps  Im misunderstanding the concern HTH  Antthony  Regarding the requirement that solutions be identical  Willem it would be better to have participants spend time on innovation rather than reproducibility however its important to have strict rules so that the competition remains as fair as possible B  Yang with regards to the compiler issue we can address it if the issue arises  For example we might start by ensuring that the same compiler is used for verification  Sali  Mali it is exceptable to describe the algorithm and not how it is derived  We are seeking clarification from HPN on the inconsistency that you describe  Apologies for the delay  Regarding the requirement that the algorithm perform similarly on a separate dataset  This is best answered by explaining the rationale behind the rule  It is there to catch any cheating or blatant overfitting  If youre not blatantly overfitting then youre likely to be on safe ground  Hi all  Not ignoring this thread  Just seeking clarification from HPN on one issue  Anthony  Sorry for the delay on this was just clarifying some issues with HPN  Is it inconsistent as  Sali  Mali pointed out in another thread to require documentation of the winning algorithms be publicly disclosed to all competitors given  Rule  Entrant  Representations  It seems that this disclosure will encourage other competitors to use aspects of the winning  Prediction  Algorithm which cause violation directly or otherwise of i iii and possibly iv of that  Rule  Rule does not apply to the extent that it prevents a competitors other than a milestone prizewinner from using code published by a milestone prizewinner in accordance with competition rules and b a milestone prizewinner from competing subsequently in the competition using code for which it was awarded the milestone prize  Can you clarify that code libraries and software specifications are not required to be publicly disclosed to competitors  These materials and intellectual property appear to be referenced separately from  Prediction  Algorithm and documentation  Chris correctly points to  Jeremys response in an earlier forum post “ Only the paper describing the algorithm will be posted publicly  The paper must fully describe the algorithm  If other competitors find that its missing key information or doesnt behave as advertised then they can appeal  The idea of course is that progress prize winners will fully share the results theyve used to that point so that all competitors can benefit for the remainder of the comp and so that the overall outcome for health care is improved ”  Will  Kaggle or  Heritage have a moderation or appeals process for handling competitor complaints  From the winning entrants pointofview they would not want to be forced through the review process to allow backdoor answers to code and libraries which accelerate a competitors integration of the winning solution  Kaggle and the HHP judging panel will moderate the appeals process  Can you comment on the spirit and fairness of the public disclosure of the  Prediction  Algorithm documentation and its impact on competitiveness  In particular if the documentation truly does meet the requirement of enabling a skilled computer science practitioner to reproduce the winning result then this places the winning team at an unfair disadavantage all competitors will have access to their algorithms and research in addition to the winning algorithm  This rule is in place to promote collaboration  Those who would prefer not to share can opt out of the prize  Can you provide more detailed clarification on the level of documentation required by conditional milestone winners  The guideline provided by the rules would cover a range of details and description spanning from lecture notes to detailed tutorial to whitepaper to conference paper etc  Hopefully this was adequately dealt with in  Jeremys response requoted above  Let me know if further clarification is needed  Can you comment on the reproducibility requirement  For example it is possible to construct algorithms with stochastic elements that may not be precisely reproducible even using the same random seed is it sufficient for these algorithms to reproduce the submission approximately  What if they dont reproduce exactly or reproduce at a prediction accuracy that is worse than the submission score possibly worse than other competitor submissions  Exactly reproducibility is required  John  Only the lowest of the five entries count  Note for the milestone prize only one can be selected  Anthony  If you were per cent sure that somebody would spend days in hospital in Y and per cent sure they would spend day in hospital than you might predict that they spend would days in hospital pham you do not have enough detail in the claims data to reproduce the DIH properly  Youve likely reproduced DIH from claims data as accurately as is possible  Sir Guessalot thanks for the pointer  Its been added to our issue tracker I must admit we have higher priority issues to tackle but well get there eventually  Just to keep you all in the loop the plan is to announce the milestone prize winners at  O Reillys  Strataconf  Will let you know the exact date as soon as were told  Full milestone prize rankings will be released after the announcement is made  Provisional milestone prize winners will receive an email over the weekend  An announcement will be made at  Strataconf on  September  Correct  Congratulations team  Market  Makers and  Willem  Great coverage in the  Wall  Street  Journal here  For those interested heres the footage from the award ceremony  Jason the anonymization guys have withheld this information intentionally to make the data set more secure  Sorry  Hi all HPN are currently looking for data scientists  Heritage  Provider  Network the sponsor of the  Heritage  Health  Prize is looking to hire data scientists to take its data and analytics department to the next level  If you are interested in healthcare join the largest physicians group in  California and one of the largest in the  United  States and use your data mining skills to make a difference in the provision of health care to individuals throughout  Southern  California  If interested please send an email indicating your interest to datascientistheritagemed com  Anthony  Does being a member of HPN mean you usually referred to an innetwork provider of say lab testing unless obviosuly it is some specialty unavailable  Yes  Can you be a member of HPN and have govt sponsored insurance eg  Medicare  Medi Cal  Yes for  Medicare I can follow up on  Medi Cal if you like  Have passed these questions onto HPN  Will respond as soon as I get an answer  We are aware that the rules havent been as clear as we might have liked  Please be reminded that you cannot sign up to  Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  Weve reached out to several teams about this issue  Please let us know ASAP if you have multiple accounts and weve not reached out to you  Entrants are welcome to use other data to develop and test their algorithms and entries until UTC on  April if the data are i freely available to all other  Entrants’ and i published or a link provided to the data in the “ External  Data” on this  Forum topic within one week of an entry submission using the other data  Entrants may not use any data other than the  Data  Sets after UTC on  April without prior approval  On  October the judges in their sole discretion decide whether or not the documentation is sufficient taking account of the comments made on this forum  If they decide the documentation is not sufficient they can impel the winners to address their concerns in the seven days following  October  If the winners are asked to resubmit participants have another days from  November to raise any additional complaints  The judging panel are experienced academic reviewers  Hi all  We are in the process of liaising with the judges  Well report their decision as soon as we have everybodys feedback  Hi guys  Glad you like  This dataset reminds me of the RTA data which was really popular  On the IP question when no rules are explicitly stated the  Kaggle terms and conditions prevail  Specifically clause  By accepting an  Award you agree to grant a license to the  Competition  Host to use any  Model used or consulted by  You in generating  Your  Entry in any way the  Competition  Host thinks fit  This license will be nonexclusive unless otherwise specified  Anthony libraryrandom Forestsetwd C Usersantgoldbloom Dropbox Kaggle Competitions Credit  Scoringtraining read csvcstraining csv R F random Foresttrainingctraining Serious Dlqinyrs sampsizecdo trace T R U Eimportance T R U Entreeforest T R U Etest read csvcstest csvpred data framepredict R Ftestcnamespred  Serious Dlqinyrswrite csvpredfilesample Entry csv  Alec setting the random seed is a good idea  Domcastro your hypothesis is correct  Youre correct  Shouldnt include headers  We have made a slight change to the  Terms and  Conditions adding  No individual or entity may share solutions or code for any competition or collaborate in any way with any other individual or entity that is participating as a separate individual or entity for the same competition  The foregoing shall not apply to any public communications such as forum participation or blog posts  We are also aware that the rules havent been as clear as we might have liked  From now on before you download the data for any new competition you will be reminded that you cannot sign up to  Kaggle from multiple accounts and therefore you cannot submit from multiple accounts and privately sharing code or data is not permitted outside of teams sharing data or code is permissible if made available to all players such as on the forums  Weve reached out to several teams about this issue  Please let us know ASAP if you have multiple accounts and weve not reached out to you  It is a mistake were sorry for it but weve decided not to correct it because it might not be fair to some contestants if we change the data midstream  Shouldnt be too importantonly happened to chunks  Its the same mistake that caused a few chunks to have some missing data within the chunks  Sounds like theres a thriving community in  Melb which looks to have been the strongest performing city  Congrats all  Donovan weve looked into this and it turns out that a bug with our process meant that we hadnt received the past few weeks of queries  Weve found your email and you will receive a response shortly as will others who slipped through the cracks  Apologies to you and others who have not received a response as a result of this error  Why does lower bound get mentioned so much more than upper bound  Thanks for the thoughtful comments  First off as always we will not make retrospective changes to how we handle past competitions including this one  When issues like this come up we use it as an opportunity to evaluate how we might improve in the future  Internally our debate focused on three issues recognition for those who completed stage one but not stage two achievements and how the competition appears on profiles th out of looks more impressive than th out of how points are handled recognition for those who completed stage one but not stage two  We need to view the stage one leaderboard as having no weight if it gets a weight we incentivize overfitting or hand labeling for stage one achievements and how the competition appears on profiles  If we did what  Julian suggests and add stage one participants to the bottom of the stage two leaderboard we undermine our rankings by making it very easy for somebody to get an impressivelooking top achievement by finishing th out of with a naive submission how points are handled  The one change we will make in future is the way points are handled  We will add a multiplier to the number of points for a twostage competition  We have not settled on a formula for doing this yet but commit to communicating it clearly in the rules of the next twostage competition  These are difficult issues but we think this approach strikes the best balance between competing considerations  Just a heads up that were still working through the winners solutions  Will need more time to before announcing the final results as official  Quick update  We will announce the official results on  Wednesday  March at am ET  Julian responded in the other thread  Hi all  The results on the final leaderboard are now official  Congratulations to the winners and all involved  This is among the hardest and most ambitious competitions weve hosted  We couldnt be prouder of the results  The competition has received some press coverage with a chance of more to come  Anthony  Love it  Interesting that for everyone other than  Woodrow  Wilson the names popularity monotonically declines over the course of the presidency  Dwight looks like it increases in popularity during WW which makes sense  One suggestion is to add years to the x axis label for each chart to make things like this easier to spot I  Tweeted this script and somebody replied asking  Is there a corresponding drop in the name frequency of the losing presidential candidate right after the election I was thinking another interesting extension would be to answer the question  Whats most influential in determining baby name trends out of  Presidents and first ladies  Musician that was for longest on the billboard charts in a given year  Best actoractress in the  Oscars  Basketball football baseball  M V Ps  Nobel prize winner names  Time person of the year  If nobody else tackles this I might try it  This builds off a conversation I had with my coworker  Meghan who said itd be interesting to see whether  Presidents or royal babies had a bigger impact on baby names  Nicely done and fun writing style  One additional conclusion is that real data is messy  Big  Data  Borat captures it best  In  Data  Science of time spent prepare data of time spent complain about need for prepare data  Ive played with PCA before but never association plots or MCA  Glad to see an example usage and be able to add these to my toolkit  Thank you  For the association plots I assume the width of the box refers to the number of  Tweets referring that that airline I assume is the proportion of comovement explained by the first dimension  Is that correct  Is it typical for the first dimension to explain so much of the comovement  Any thoughts on how to interpret this dimension  Small nit  You might want to change res to reason I initially assumed res stood for residual  And reduce the font size for the x axis label on plot  Thats the most interesting plot to me but its hard to read the labels because they overlap  From this page  This is a nice notebook  Suggestions  To make this easier to follow for those who havent yet looked at the data itd be great if you added a section showing a few rows  Or possibly even a few exploratory chartshistograms  Perhaps after the  Loading the data section  Itd also be nice to see the before and after you preprocess the data ie before and after the  Using textmining to format our data section  Rename the  Using textmining to format our data to something like  Cleaning the data  Great I always look at the top rated notebooks before looking at the data because the notebooks usually give me a sense for whats in the data and what I could do with it  This is great  Im surprised  North  America is not higher for sugar  The sweetness of food was one of the first things I noticed when we moved to the US from  Australia  Although it could be because a lot of the sweetness comes from high fructose corn syrup which is not captured  Its awesome  Really nicely put together  Bluefool I thought you came out really well  Interesting how noisy the very early years are I suspect the s data is very poor quality  Really nice script  Interesting to see the temperature uncertainty chart  Gives a nice visual of when the data starts becoming more reliable  Also nice idea to put dt into a variable importance plot to see its relative important  Obviously would have been more interesting if wed provided more data  One suggestion is to better label your plots  Theres some good stuff here but it stakes a while to figure out what each chart is showing I actually looked at your code to figure it out I suspect this script will be more popular with some labels that make it easier to follow  Sven have you been able to figure out an interpretation of this chart  Thanks  Itd be helpful if you labeled the charts and possibly added sub label pointing to your interpretation  It may not be useful for the reasons you mention but it looks nice  Would be cool to see the by city version I assume you didnt use it initially because of the size of the data set BTW I assume red hot  Would be helpful to have a key  Is this a work in progress  Or is there an error  The charts are showing up blank for me  Cool  As someone who lives in  San  Francisco  Im curious  Juanchaco this is neat but itd be easier to follow if you added a description between charts  At the moment  Im scanning the codecomments to try and figure what each chart is showing  Ha  Id not known about this  For others  Akshay this script would be more interesting if you found a neat way to visualize temperature by country  Love this chart  And the title is funny\n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['clean_messages'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much better. Now that the train posts and forum posts are cleaned, I'll stem them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to stem words\n",
    "def stem_text(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words_list = text.split()\n",
    "    new_list = []\n",
    "    for i in words_list:\n",
    "        word = stemmer.stem(i)\n",
    "        new_list.append(word)\n",
    "        \n",
    "    words = new_list\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['clean_posts'] = train_data['clean_posts'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im find the lack of me in these post veri alarm sex can be bore if it in the same posit often for exampl me and my girlfriend are current in an environ where we have to creativ use cowgirl and missionari there isnt enough give new mean to game theori hello entp grin that all it take than we convers and they do most of the flirt while i acknowledg their presenc and return their word with smooth wordplay and more cheeki grin this lack of balanc and hand eye coordin real iq test i score internet iq test are funni i score s or higher now like the former respons of this thread i will mention that i dont believ in the iq test befor you banish you know your an entp when you vanish from a site for a year and a half return and find peopl are still comment on your post and like your ideasthought you know your an entp when you i over think thing sometim i go by the old sherlock holm quot perhap when a man has special knowledg and special power like my own it rather encourag him to seek a complex cheshirewolf tumblr com so is i d post not realli ive never thought of ei or jp as real function i judg myself on what i use i use ne and ti as my domin fe for emot and rare si i also use ni due to me strength you know though that was ingeni after say it i realli want to tri it and see what happen with me play a first person shooter in the back while we drive around i want to see the look on out of all of them the rock paper one is the best it make me lol you guy are lucki d im realli high up on the tumblr system so did you hear about that new first person shooter game ive been rock the hell out of the soundtrack on my auto sound equip that will shake the heaven we manag to put a coupl pss in no the way he connect thing was veri ne ne domin are just as awar of their environ as se domin exampl shawn spencer or patrick jane both entp well charli i will be the first to admit i do get jealous like you do i chalk it up to my w heart mix with my domin w s and s both like to be notic s like to be known not the same d ill upload the same clip with the mic away from my mouth than you wont hear anyth ninja assassin style but with splatter tik tok is a realli great song as long as you can mental block out the singer i love the beat it make me bounc drop io vswck d mic realli close to my mouth and smokin ace assassin ball play in the background sociabl extrovert im an extrovert and im not sociabl sherlock in the movi was an entp normal hes play as a extj in the book hes an estj as i said the movi look good except for it be call sherlock holm oh i never had fear of kiss a guy i will kiss an anim too so there was noth to vanish just person tast and me not like it the guy i kiss didnt know me it was one of those sound pretti much like my area and what im go through right now tri to figur out which way i want to take my life i want to do so mani thing the biggest problem is that i know if i dont d i was oper under the impress that you were femal i never look at your boxi okay i help out my gay friend all the time and one of them has develop a littl crush on me i get red tt you just describ me and im live the worst nightmar im trap in one place with one one around onli dull wood if i was a serial killer this would be the perfect place but sad im tbh and bias sound like a shadow infp i think mayb he was hurt and turn estj i can tell becaus he has some of the typic infp trait left over check list im sorri it seem that you have came at a bad time weve alreadi reach our quota of infj howev be your femal and i like femal i will make you a deal i will kick one im antp lean toward e im easi for both entp and intp to identifi with i also imagin entp interrog would go a littl bit like jack from except more mechan rig up shock treatment equip in an abandon build out of an old car batti jumper it was a compliment trust me im just as psychopath d except i have emoticon theyr just weird one like laugh when i get hurt or at peopl run themselv over with their lawn mower no it like a theme for where i live and that is whi i know it by heart and i usual dont leav until the thing end but in the mean time in between time you work your thing ill work mine d d im the mbp pleasur to meet you damn need to trust my instinct more i would have been closer i was go to say infp exfp lean toward s with the way she respond d my friend even my gay and lesbian one alway come to me for advic i bow to my entp master entp are so great if it wasnt for entp i wouldnt have been abl to build what im build duck duck duck shotgun what me i never do that\n"
     ]
    }
   ],
   "source": [
    "print(train_data['clean_posts'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forum_data_agg['clean_messages'] = forum_data_agg['clean_messages'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the public leaderboard is onli indic becaus competitor can use inform on their score to get inform on a portion of the test dataset the final result are a quit differ and b better reflect actual perform hi tanya kaggl will maintain a rate system if you win but your inelig for prize money you will still get a strong rate anthoni giovanni thank for your feedback use the forum to give feedback is a good idea it allow other to see and comment on suggest we might set up a proper feedback forum but for the moment this topic will have to suffic i also agre that the forum is a bit clunki howev we have a larg list of featur request and onli limit resourc for the moment it might take us some time to address this apolog i dont think the prize money in this competit is that relev the prize is relat small correct me if im wrong but i think contest are driven by intrins factor a karma system that reward forum post is a good idea again apolog for ani delay in implement this there are lot of featur on our to do list anthoni manish thank for the feedback the site is host on an amazon ec server on the east coast of america it a fast server but the site has been more popular than we expect were current work on speed up the site by reduc the number databas queri we may have to implement auto scale if the site keep grow so rapid anthoni just made a chang which should speed thing up let me know if it has made a differ for you jonathan thank for your feedback x were current work on cach databas queri there are a lot of good suggest here that well tri befor autosc colin the choic of score system was quit deliber will the competit host consid use area under the roc curv where particip submit probabl but said that he deal with physician who just want to know the proport of predict that are correct rajstennaj and colin were realli pleas that you believ that there valu to the project let me know if there is anyway that we can help to facilit a communiti we did set up the general kaggl forum under communiti forum with such a communiti in mind doe it provid suffici infrastructur you are free to start ani new thread on that forum regard anthoni thank for particip in this competit ive attach the solut file to this post updat the solut is no longer attach but your welcom to make submiss to this competit hi matt i believ that will the competit host is prepar a blog post that discuss some of the method that peopl appli to this competit base on the feedback we receiv is this the sort of thing you had in mind anthoni here are some paper that analyz eurovis vote pattern you might find some of them help gather comparison of eurovis song contest simul with actual result reveal shift pattern of collus vote allianc eurovis song contest is vote polit or cultur ginburgh and nouri suleman efstathiou and johnson eurovis song contest as a ‘ friendship network dekker more research enjoy love thi neighbor love thi kin vote bias in the eurovis song contest cultur and religion explain the bias in eurovis song contest vote hybrid system approach to determin the rank of a debut countri in eurovis eurovis judgment versus public opinion – evid from the eurovis song contest here is the solut file for anybodi interest i accident delet the follow post made by anoth user im repost it on their behalf are there categor andor binari variabl in the data set other than the target variabl for instanc variabl open in test data seem to have categori if there are categor variabl do we get to know what the categori mean thank you just to clarifi the result page will show the leaderboard for all competitor regardless of whether they use futur inform or not we will make an honour mention to the lead competitor who doesnt use futur inform howev their entri will be audit kaggl is current develop a leagu tabl that rank competitor when it come to this competit your posit on the leaderboard which is indiffer to the use of futur inform will be what count toward your kaggl rank inform can offer an awardhonour mention to those who dont use futur data howev the kaggl leaderboard will not seper those who use futur inform from those who dont given the way the competit has been setup there no way to prevent peopl from use futur data even if the winner present a model that doesnt includ futur data they may have overfit to replic the predict of a model that doe includ futur data in theori yes the problem is that there no way to be certain that the winner didnt use futur inform even when we check the win model it possibl they have use a model with futur inform to probe the test dataset sali mali has point out that there is an error in the auc calcul for entri with tie score that is when two or more score have precis the same valu we will look at the problem over the next hour and will rescor all entri apolog anthoni the auc calcul glitch has been fix and all entri have been rescor sali mali thank again for point this out hi pg not sure that i fulli understand the question are you refer to the situat where a classifi return onli or rather than a score or probabl perhap you can use an exampl to illustr the question regard anthoni hi pg you should give the score for all timestamp a higher score mean the instanc is more like to be a member of the posit auc measur your classifi abil to split the class so you dont need to decid which score predict posit instanc and which predict negat instanc have i address your concern vateesh thank for send the file the file that you sent are actual differ i also had a look at your submiss and you have a few file with the same name but differ number also i was not abl to replic the problem as you describ it perhap you can tri again and let me know if your still experienc the error hi vess this should not be a problem given the way submiss are store seyhan the leaderboard portion of the test dataset is select random it is somewhat repres of the overal stand cole sorri for the slow respons in this competit all your submiss count in futur we will ask particip to nomin submiss phil that is correct you must rememb that kaggl hope to do more than just host fun competit we want to help solv real problem this is whi were reluct to forc particip to choos just one model they may make a poor choic and the compett host may end up with a suboptim model our compromis posit is to allow partip to nomin five entri a featur which well roll out for futur competit phil number is correct luck will play a part but i suspect the test dataset is larg enough to limit it impact i agre in a competit like this one but as mention abov we want to host competit that are use as well as fun an upcom competit will requir particip to predict who has prostat cancer base on variabl in a competit like that it would be a shame to miss out on the best model requir particip to nomin five submiss seem like a good compromis hi cole apolog for the ambigu the time is as it appear on the competit summari page adjust accord to the timezon on your comput clock so itll be saturday or sunday depend on your timezon you can also see a countdown on the kaggl home page anthoni durai apolog for the slow respons all up countri were repres here is the list in order of most particip to fewest unit state unit kingdom australia canada thailand india germani spain china netherland franc itali new zealand south africa sweden argentina croatia ecuador greec indonesia iran ireland mexico poland portug russia singapor turkey and ukrain ricardo you are correct i gave the countri list for the wrong competit countri were repres unit state colombia india australia unit kingdom franc thailand canada germani argentina japan afghanistan albania austria belgium chile china croatia ecuador finland greec hong kong iran poland portug slovak republ venezuela sorri for the slow respons ive been flat out with the new site launch below is the list of row use to calcul the public leaderboard phil i made an error in the ten per cent list abov tri score with the follow row yuchun apolog for this error the public leaderboard is portion of the test dataset is actual the first per cent becaus we hadnt implement the code to select a random portion of the leaderboard yet for info the reason we kept get differ per cent is becaus the random seed in the databas was set to zero which told our code to choos a random random seed anthoni pleas use this topic to give us feedback if youd rather do so in privat email me at anthoni goldbloomkaggl com thank for the feedback what sort of featur do you have in mind or can you point to a forum that you we should emul i just ad a quick repli box to make the forum less clunki great suggest i have put this on our extens featur to add list hi matt thank for the nice word and the suggest ive post the solut file good suggest were open to idea on how we can facilit this my think is the best thing to do is to implement a more function forum which were do we can then encourag those who are still work on the problem to continu to use the competit forum as a way to collabor use this topic to discuss ani competit you would like us to run if you would rather contact me privat email anthoni goldbloomkaggl com out of that pretti impress piti they didnt enter the kaggl comp i think your right some competit exhibit more regular than other soccer may be a difficult sport to model david this is a great suggest the hiv competit show that kaggler can do great thing my initi concern with ani public dataset is that peopl can look up the answer we would need research to withhold a small portion of the dataset for evalu i think the first step is to get in touch with those who set up the alzheim project it also make sens to contact the michael j fox foundat if anybodi has ani connect to either of these project pleas let me know otherwis ill keep you post on ani progress anthoni hi david i have written to the alzheim diseas neuroimag initi adni and the michael j fox foundat i am schedul meet with both for septemb will keep you post on ani progress can you put up a link to the datapap you found thank again for the suggest it great if we can use the power of this platform to tackl meaning problem regard anthoni thank for the nice wish of cours kaggl wouldnt exist without a brilliant communiti of data scientist who can solv realli challeng problem look forward to see what we can do in this is the photo from the kaggl offic this lunch was one of the highlight of my six year of kaggl not someth i will forget in a hurri hi dirk the elo benchmark is base on the train dataset onli have had mani email convers with jeff i can tell you that the seed rate matter a lot youll notic that jeff made two submiss for the elo benchmark that becaus hes refin his seed method i believ he plan to make a few more refin jeff use an iter process to seed the rate system for exampl he might start by give everybodi and then let elo run for month he then seed elo with the month rate and run elo again he doe sever iter of this doe this help anthoni has anybodi tri trueskil yet probabl a better start point than elo this blog post doe a nice job of step through trueskil hi john have just confirm with jeff methodolog will be share public regard anthoni the competit has been design to make cheat realli difficult at the end of the competit the winner methodolog will be replic to help ensur everyth is abov board hi matt the reason we prevent particip from submit an unlimit number of time is becaus otherwisea our server may not be abl to handl all the traffic anda it would be easier to decod the portion of the test dataset that use to calcul the public leaderboard the techniqu you describ often refer to as cross valid is veri sensibl and we encourag other to use it anthoni uri you rais an interest point howev is five month long enough for somebodi rate to move enough for you to notic this jpl a competit use internet chess data is a good suggest for interest the reason we are run the competit use top player is becaus elo rate matter most for top player sinc it is use to determin who can play in which tournament jase the score on the full dataset is calcul onthefli so we actual know who is win base on the full test dataset ron the submiss that is perform best on the public leaderboard may be differ from the submiss that is perform best on the full test dataset we dont link the best submiss on the public leaderboard to the best overal submiss so that particip dont becom confusedconcern if their scoreposit on the public leaderboard worsen leigh my think as well in a tradeoff between have a veraci public leaderboard and a veraci end result the end result is most import jeff good suggest ive put togeth an excel sheet that might be help for cross valid you past your predict for month into column g and it aggreg by player by month and then calcul the rmse hope it help anthoni ben the evalu method was chosen becaus jeff has found that score base individu game with rmse unduli favour system that predict a draw mark glickman rais anoth issu rmse is better suit to normal distribut rather than binari outcom so in order to use rmse aggreg is prefer of cours we could have evalu on a game by game basi use a differ metric my biggest problem with the current evalu method is that count a draw as half a win seem a littl arbitrari howev in order to benchmark elo such an assumpt is necessari mark and jeff argu that a draw is general worth half a win so this assumpt isnt too problemat anyway hope this give you some insight into our think regard anthoni jeff pleas correct me if im mistaken but i believ system that predict draw are favour becaus a high proport of game are draw at the top level per cent in the train dataset of cours you can do better but a system that predict for everi game will perform better than it should matt am interest in your think on this whi mae over mse or rmse is it just that the metric is more intuit or someth subtler out of interest has anybodi enter this competit use glicko glicko or chessmetr are either of you happi to send me your unmodifi glicko submiss it would be good to add a glicko benchmark team to the leaderboard my email address is anthoni goldbloomkaggl com would like to do the same for glicko and chessmetr if anybodi has tri those i have also contact ron about use his trueskil submiss as a trueskil benchmark jase i post a link to your glicko code on the hint page it veri good of you to share it im realli surpris that glicko is perform wors than the elo benchmark do you think this is becaus jeff put lot of work into optim seed the elo benchmark or is glicko just not as good was just chat to jeff time permit he is go to benchmark some of these other system this way they will all be benchmark on a consist basi use the same seed procedur and the same degre of tune uri the correl between the public leaderboard score and overal score is signific higher now uri im reluct to releas confid interv inform becaus i want to minim the advantag to earli submitt earli submitt alreadi have the small advantag of have seen their submiss on two differ public leaderboard by releas confid interv inform im give earli submitt access to inform that isnt avail to later entrant jase asid from chang the size of the public leaderboard portion of the test dataset we also select it more sensibl so it better repres the overal test dataset hi edward you will appear on the leaderboard as soon as you make your first submiss hi edward tri use examplesubmiss csv avail at and replac the score column with your predict score if your still have troubl email the file to me anthoni goldbloomkaggl com and ill have a look uri thank for point out the problem were current work on a big upgrad to the websit the new site should be launch by the end of this month the upgrad will involv a more function forum in the meantim i will tri and fix this problem anthoni uri im not abl to replic the error either on the live site or on the develop version can you let me know if you experi it again hi han which post still cant replic the bug intermitt problem are realli annoy as mention were do a massiv site upgrad at the moment so that take up the major of our develop time how serious is the problem can we live with it for the next few week until we deploy kaggl i would realli like to be more activ in the forum look like there some live discuss happen ive been flat out work on the site upgrad which is onli a few week away from launch anyway id like to share a few thought on this discuss first off there is quit a strong correl between the public leaderboard and the overal stand second the lack of relationship between the score and the score might indic overfit this may be the case if your experienc a larger improv on the dataset than the dataset on a relat point i notic that your all perform veri well it could be that youv reach a local maximum i e the best possibl score given the techniqu your use eric thank for the feedback there not realli ani reason to insist on a particular file extens were current do a big site upgrad so ill add this to our list of featur request just to reemphasi jeff point you should pay more attent to your cross valid than to the leaderboard the leaderboard is calcul on a veri small amount of data so it is onli indic phillipp sorri for the delay in do this i havent had comput access over the last few day the spearman correl between public score and overal score is i also calcul the correl for differ submiss quintil to make sure the relationship hold at the top it doe top it also worth mention that the troubl particip are have reflect realworld difficulti in formul a chess rate system this competit is not just a game but a genuin attempt to explor new approach to rate chess player anthoni out of interest whi arent peopl rerun old approach that had previous been score on the new cross valid dataset wil if you can get histor data from freechess org possibl by agre to share the win method with them wed be happi to host a comp here this way you could specifi that the win method must be an instant gratif system it would also result in a system that tune to lower rank player thank for point out the error it has now been fix apolog for ani confus uri make a veri good point one way we could run a competit without know futur matchup is to have particip rate everi player onc we know the matchup we can infer predict base on player rate the onli downsid to this approach are it doesnt allow for probabilist predict sinc there are mani way to map rate into probabl we couldnt show a live leaderboard which help to motiv particip interest in other thought on this particular the import of a live leaderboard philipp i dont fulli understand your suggest do you mind tri to explain it again possibl by refer to an exampl as a general principl tne problem with attempt to prevent peopl from use neural network and the like is that particip use them anyway and then overfit other system to replic the neural network result i actual think that have neural network et al in the competit is valuabl even if they wont be implement as rate system they may have some benchmark valu assum they predict most accur they give a sens for what level of predict accuraci is possibl from ani given dataset as an asid if we requir particip to submit rate and dont give them access to the matchup that theyll be score on this should forc particip to creat a rate system shouldnt it btw jeff re i have been and continu to be amaz by the level of particip so far i had no idea so mani peopl would particip congratul on organis such a popular competit pew what criteria would you use to evalu such system b t w i think youd be surpris at the proport of the top who are build rate system ron this is fantast look like a sizabl proport of the black dot are sit in a vertic line though im sure the elo benchmark would look much wors out of interest what softwar did you use to generat the viz ps im guess the anomali that this viz highlight e g that white is a smaller advantag for lower rate player could inform futur version of your rate system philipp thank for your nice word hope have a more profession look and feel will help us attract interest competit with bigger prize pool philipp thank for point out this bug the error was onli aesthet had been accid hardcod into the new theme the platform was still onli permit two submiss anyway the error has been fix unfortun the movi isnt out in australia yet weve still got anoth week to wait jason there a bug that prevent user see previous score when they have longish techniqu descript we are awar of the problem and will fix it as soon as we can diogo thank for point out this error we will setup pagin on the submiss page short diogo thank for point out this bug few minor teeth problem with the new site we should have them sort out befor long hi all just to let you know that we have extend the deadlin for this competit by just over a week both jeff and i will be travellng around mid novemb so wouldnt be abl to deal with the competit conclus anhoni apolog i hadnt antip that this might be an unpopular move i should have canvass opinion first if other also disapprov i will chang back the deadlin kaggl is not a dictatorship the downsid of chang back the deadlin is that it limit our abil to generat public this bother me becausea top perform deserv recognitionb public for the competit is public for kaggl and more public more member more competit andc it lessen the chanc of get f i d es attent a compromis might be to extend the previous deadlin by three day to wednesday novemb when jeff is offlin but i am avail thought hi philipp the chessbas articl were written by jeff he has a relationship with the editor jeff be away when the competit finish mean that it unlik that chessbas will report on the end of the competit a real piti if we hope to grab f i d es attent it is unfortun that were both away when the competit end obvious not foreseen when it launch otherwis we would have set a differ deadlin anthoni jeff we must have post simultan you rais a good point if philipp and other are ok with the th then we should go with the compromis date this would mean that ill be avail to report preliminari result and should mean were readi to report the final result by the time you return preliminari will be unconfirm result from the raw leaderboard final result after the top ten have all agre to share their methodolog ive chang the deadlin to the th as for uri breath down your neck rememb that the public leaderboard is onli indic and that the final stand may be differ apolog uri and lt seem that ani repli is redund now also big thank to all those who particip in forum discuss you help make this a far more interest competit this first chart how the lead score has chang on a daybyday basi the red line show the elo benchmark and the blue line show the lead score the elo benchmark was outperform within hour which is whi it alway abov the best entri interest to see some recent progress after a period of stagnat well done philipp my guess is that ani major improv from this point on will be the result of somebodi tri someth quit differ this chart show the number of daili entri higher earli but seem to have stabilis at around per day happi to put up other chart if peopl have request philipp there certain a largish gap between the top five of cours this is pure indic what realli matter is the score differ on the final leaderboard philipp great sugges weve got a stack of featur we want to implement but ill put this in our long term wish list i tri pute up a general forum for such discuss but found that it was veri light use featur in the pipelin includ fix bug or incomplet featur on the new site upgrad to kaggl infrastructur to allow us to score veri larg entri kaggl rank system an elo for kaggler base on microsoft trueskil extend social network featur includ live chat recent activ feed philipp competit analyt sugget and possibl some other data viz tool competit in the pipelin includ predict social network connect predict the like success of grant applic for a larg australian univers forecast travel time for freeway in melbourn australia predict prostat cancer from a high dimension dataset subject to ethic approv diagnos breast cancer from mammograph densiti imag also subject to ethic approv ani other suggest ani thought on what our prioriti ought to be jason l t are you think along the line of karma point for particip in forum discuss or would you like the forum to be more of a qa with stackoverflow style rate i like the idea of guest blog post and communiti tutori after the chess competit end some might be interest in post detail of their workflowmethodcod lt the general forum has been taken down for the moment when i get a littl time i will attempt to reviv it and start encourag peopl to use it philipp it may not matter that peopl onli compet in a hand of competit becaus each competit contain quit a lot of inform unlik a singl chess game particip are compet against mani player regardless well do plenti of test with trueskil befor implement as for the point system point seem a littl abitrari i like the idea of rate that account for the strength of a competit particip i tend to agre with your point on forum particip point the stackoverflow approach seem like a nice way around the problem there are lot of direct we could take kaggl but for the moment were focus on competiiton jc i agre that those who enter earli have an advantag howev the main sourc of advantag come from the fact that they have had the opportun to spend longer on the problem and tri more thing philipp the current leader has made entri if this competit took ternari score loss win draw this would amount to possibl combin make phillip entri a drop in the ocean in fact the test dataset is richer becaus particip predict the probabl of victori nonetheless for futur competit we will ask particip to nomin five entri that count toward the final stand pew we are not requir particip to guess but rather encourag them to reli on their cross valid when determin which model to choos the problem with allow peopl to enter mani time and tri mani paramet tweak is that they are more like to accident overfit on the test dataset by this i mean they are more like to find a paramet tweak that work well on the test dataset but doesnt work as well for futur chess game on your second point you are correct to say that i am worri about statist guess the requir that particip submit code doe not obviat this concern becaus model can be overfit onc the answer are known in the extrem case somebodi could fit a decis tree that classifi everi game perfect if they know the answer show the stand but not the score make statist guess onli slight more difficult becaus particip are close enough that the leaderboard order give meaning feedback on which guess are better and which are wors as an asid it seem that i have fail to convey the messag that the public leaderboard is pure indic and that cross valid is import i would even go so far as to say that it may be problemat if the public leaderboard bear too close a resembl to the overal stand i like uri suggest it get around the problem that lt menton while potenti encourag peopl to tri thing beyond paramet tweak coupl of potenti problem a particip exhaust the submiss limit and anoth entrant make and share a breakthrough eg the use of chessmetr in this competit anybodi who has exhaust the submiss limit wont have the opportun to build on the breakthrough this seem less than ideal given that we want to get the best result possibl it might encourag peopl to make all their entri at the end so that they dont reveal the strength of their hand what do other think philipp kaggl has been experienc a massiv lift in site visit and signup sinc the new site launch from uniqu visitor to this account for the increas in entri thank everyon for make this an amaz competit big congratul to the winner outi also to the runner up jeremi howard who onli join the competit late in the piec and to martin reichert who finish third hope well get some of the top ten to tell us about their method on the blog in the meantim i encourag you all to tell us a littl about what you tri on the forum also for interest here a chart that show how the best score evolv over time rapid improv initi but after a month progress stall as particip approach the fronteir of what is possibl from this dataset i think i can help with this i dont give name just score combinationsscor publicscor jeff can i post the test label on the forum i onli seem to have the aggreg solut on hand attach jeff do you have the game by game label edit look like you post a minut befor me realli nice feedback veri thought provok the api suggest is nice it doe seem that it would prevent peopl from use the futur to predict the present howev the testtrain split is still necessari to prevent overfit and we could still onli give partial leaderboard feedback the api doesnt secur against overfit paramet tweak also the api approach would add new problem model will take longer to run becaus of the delay in receiv data point as you say it would add a huge load on kaggl server as for the problem you list here are my respons predict can't use all avail prior data sinc the test data doesn't provid result this is necessari to ensur against overfit if all the data is use to calibr a model it imposs to know if the model will fit futur dataset as well limit train and test data creat too much varianc between the public score and actual score the mistak made in the first competit was with the size of the public leaderboard portion of the test dataset my fault not jeff it was too small which lead to the low correl between public and overal score for the rta competit we rais the proport to ensur a stronger correl this proport was calibr after some test of the correl between the two part of the test dataset we intend to continu this practic go forward model paramet can't be tune becaus actual score aren't provid if we allow paramet feedback on the whole test dataset this would almost definit lead to overfil paramet tweak that work on the test dataset but wont work for for futur dataset number of submiss is sever limit becaus they are so larg this will becom a bigger problem as larger test dataset are creat i dont think more daili submiss are necessari becaus the major of model build should be done with refer to a cross valid dataset leaderboard doesn't reflect actual leader again this was my mistak i made the public leaderboard portion of the test dataset too small this is not a flaw with the general approach futur data can be use to predict the past jeff suggest a realli nice solut to this test set includ some spurious game so that peopl can't mine the test set for use data about the futur these spurious game wouldnt be use in final evalu the api also provid a realli nice answer to this problem hi dirk weve updat the data descript thank for the pointer the competit doe requir particip to forecast the next four observ weve updat the format of tourismdata csv so that there is alway a valu in the last row regard anthoni hi greg apolog there was a bug that cut off the last charact the problem has been fix but unfortun the fix will onli appli futur submiss thank for point this out and sorri for the inconvini anthoni greg thank for point this out im current travel but will look into this over the weekend greg this problem has now been fix thank again for point it out dirk i just chang the file post on the data page to a unix format hope this solv the problem hi all wonder whi the benchmark is still lead when it is public avail have peopl had troubl replic the author methodolog or is everybodi tri their own approach anthoni someth was amiss there was an error in the data upload on kaggl kaggl fault not the author the chang are not particular big so model that perform well on the previous dataset should continu to perform well to give you the opportun to rerun your model and make new entri we have extend the competit deadlin by two week and lift the daili submiss limit to three per day and i believ georg intend to releas the code use to creat the benchmark apolog for the error dont hesit to ask if you have ani question hi jess you are correct this is instruct is wrong the month column mm should be line long includ the header and the quarter column qq should be line long the examplesubmiss csv file avail on the data page give an exampl im at a confer today but will correct the instruct as soon as i get the opportun dirk ive chang the line break format let me know if this doesnt fix the problem tim kaggl is current in the process of put togeth a leagu tabl which rank particip base on competit perform if you perform well in this competit it will count toward your rank hi markus i can help out on the second part of your queri ive post some php auc code on anoth forum post softwar packag like r have easi to use packag that calcul auc anthoni steffen you can enter use a model code in ani languag john drew i presum those who enter use softwar other than r are still elig for prize hi artem for the intuiton behind auc have a read of the evalu page kaggl implement of auc work rough as follow sort submiss from highest to lowest goe down the sort list and for each predict plot a point on a graph that repres the cummul percentag of class a predict against the cummul percentag of class b predict join up all the point to form a curv the auc is the area under this curv ht phil brierley for this explan william no threshold is requir which is part of the beauti of auc in fact given that the algorithm work by sort particip make submiss contain ani real number higher mean more confid that the observ is of the posit class hope this respons doesnt serv to confus peopl anthoni artem ive gone through the step use your exampl data let me know if ive made ani error the kaggl algorithm basic work as follow first order the data predict real then calcul the total for each class in the total total initialis the cumul percentagespercentslast percentslast iter for each solutionsubmiss pair count count count count percent countstotalsperc countstotalsrectangl percentspercentslastpercentslasttriangl percentspercentslastpercentspercentslast area area rectangl trianglepercentslast percentspercentslast percent so in your exampl first submissionsolut paircount count percent percent triangl rectangl cumul area percentslast percentslast count count percent percent triangl rectangl cumul area percentslast percentslast count count percent percent triangl rectangl cumul area percentslast percentslast count count percent percent triangl rectangl cumul area auc also here kaggl php code to calcul a u cprivat function a u csubmiss solut arraymultisortsubmiss sortnumer sortdesc solut total array a b foreach solut as s if s total a elseif s total b nextissam thisperc a thisperc b area count a count b index foreach submiss as k index if nextissam lastperc a thisperc a lastperc b thisperc b ifsolutionindex count a els count b nextissam ifindex countsolut ifsubmissionindex submissionindex nextissam mycount if nextissam thisperc a count a total a thisperc b count b total b triangl thisperc b lastperc b thisperc a lastperc a rectangl thisperc b lastperc b lastperc a a rectangl triangl area a auc area return auc thank b yang the benefit of publish code is that you get sensibl suggest in return hi jon it a fix per cent chosen random anthoni hi tama as your result suggest the order doe matter and the i ds dont anthoni you can email me the file if you like anthoni goldbloomkaggl com id be happi to take a look at it william thank for the question team are allow to merg one individu cannot be part of sever team our system ensur this anyway as long as somebodi doesnt have multipl account agre that we should make this more explicit in the futur as for find peopl who submit from multipl account we are actual in the process of implement rule that alert us when it look like this is happen in the futur for larg prize money competit we may look at verifi ident apolog will i was on a plane and onli just got your messag will make the adjust this afternoon id also like to congratul the top team and congratul dirk for run an excel competit thank to everybodi who particip and a big thank to dirk for put togeth a realli nice design competit the test label are attach to this post b yang first off congratul again on a fantast perform your frustrat is understand but we cannot enforc rule that dont exist what is common sens to some is not common sens to other as jeremi point out in the rta competit the rule say the win entri has to be a general algorithm that can be implement by the rta an algorithm that involv look up futur answer could not be implement by the rta hi nick your welcom to bring addit data as long as it public avail anthoni this is someth that should be dealt with on a case by case basi if you find a dataset youd like to use ask on the forum and ill run it by the rta for inform im tri to get hold of some incid data will keep you post on this vitali the volum data is use to calcul travel time see this post for more info our prioriti at the moment is to get the incid loop error and rout length data togeth howev i can find out if this data can be made avail if you think it might be use as denni say itll be high correl with travel time and we obvious wouldnt releas it for the blank out time jeremi i wasnt awar that public document with traffic detail were avail to the extent that ani inform is avail for blank out time this would most definit be consid cheat as for question i am awar of this in fact the issu came up in anoth post the rule state that the win model must be implement by the rta in order to be elig for the prize the averag model pass this test as an asid i dont believ the tempor leakag invalid the algorithm develop in this competit alexand to me this mean that the algorithm can take a timestamp as an input and can generat forecast for the next min min etc lee thank for point this out this post post jose do you want me to ask if it permiss to use noaa data if so are you ask about the data that brad mention abov jose and joseph just spoke to the rta about this the answer is no becaus it might allow futur weather condit to be use to predict the present attach is some sampl code that can be use to constuct an entri that generat a forecast base on the averag travel time on a given rout on a given day of the week at a given time mmm file didnt attach here the codephprh fopen r t a data csv r file to read fromwh fopensampl histor csv w write the entri to this filedatedefaulttimezoneset g m t pure to prevent the interpret from rais a warningtim stamp array an array with the hump off pointsforecast horizon array forecast horizon in lot of minut e g minut minut hour this is use for calcul the forecast time stampsforeach time stamp as ts foreach forecast horizon as f forecast time stamp date n h istrtotimetsf find day of week hour and minut that correspond to each of the timestamp row while data fgetcsvrh fals loop through the datafil if row write the header col count countdata for c c col count c fwritewh datac fwritewhn if inarray date n h i strtotimedataforecast time stamp if the day of week hour and minut that correspond to a forecast timestamp is found then save to an array call ts array for c c countdata c if emptydatac datac x ts arrayd n h i strtotimedatac datac rowforeach time stamp as ts foreach forecast horizon as f fwritewh date ymd histrtotimetsf for c c col count c fwritewh arraysumt arrayd n h istrtotimetsfccountt arrayd n h istrtotimetsfc write the averag for a given day of the week hour and minut to the submiss file fwritewhn fcloserhfclosewh this code doe generat a sampl entri to use it a download the php interpreterb creat a file name xxx php copi the code abov and download the data file to the same directoryc run the command php xxx php your correct the futur is use to predict the present howev i dont think the tempor leakag invalid the algorithm develop in this competit attach is some sampl python code that generat forecast base on the last known travel time im new to python so happi to hear ani feedback on the code file didnt attach here the codeimport csvimport datetimerhopen r t a data csvr read in the data whopensampl naiv python csvw creat a file where the entri will be savedrh c s v csv readerrhtim stamp an array with the cutoff pointsforecast horizon forecast horizon in lot of minut e g minut minut hour this is use for calcul the forecast time stampsrow inialis the row variablefor data in rh c s v loop through the data if row if the first row then write the header for j in rangelendata wh write dataj wh writen if data in time stamp if the row is a cutoff point for i in forecast horizon for each forecast horizon write the cutoff travel time as the forecast the definit of naiv date str strdatetim datetimeintdataintdataintdataintdataintdata datetim timedeltai calcult the time stamp given the forecast horizin wh writed str write the timestamp to the first column of the csv for j in rangelendata wh write dataj write the cutoff travel time to the subsequ column wh writen row rh closewh close lee this is great dirk did the same thing with some python sampl code i wrote for the social network competit if you guy keep show me how thing can be done better i may becom a half decent coder toppi thank for the pointer a higher prioriti at the moment is to get forum attach work again hi peter ill follow up in this at the veri least we should be abl to provid inform on the length of differ rout anthoni armin i agre make more sens for me compil this inform onc for everybodi will tri and get it done this week eleni just upload rout length approx csv which has approxim rout length data martin dane is correct the inform in rout length approx csv is in metr so rout is approxim km martin when i open the file it show and what applic are you use anthoni dirk thank for point this out ive written to the rta about this and they respond say inde our control room have confirm signific increas in traffic volum follow the remov of the toll this has had an impact on the overal travel time across the m someth to be awar of when use the older data hi denni the per cent doesnt count toward the final stand and is select at random across the timestamp and rout as for the smtp error it been fix the problem was the result of a flood of signup which caus googl to shut off our mail server were now use our own mail server anthoni the number direct to the left of the team name is the team posit and the number to the right of the team name is the team score or root mean squar error rmse apolog for the error it decisecond not centisecond so is second ive fix the descript hi carlo unfortun not claus c in kaggl term and condit saysc employe or agent of the competit host are not elig to particip in ani competit post by the competit host to answer the second question we would more inform about the natur of the busi and what your friend doe anthoni frank this is great i particular like the heatmap is it possibl to zoom also itd be neat to see some anim on the m map show how travel time evolv over the cours of a dayweek dot get bigger and smaller though i suspect this might be a lot of work anthoni c doe seem to be an express languag im a linux user though so not inclin to pick it up daniel denni is correct in say that averag the valu lead to float point number the answer are integ but the rmse is calcul use float point arithmet alexand there is no truncat of float david i believ that when loop the measur devic fail travel time are estim im work toward put togeth data on when travel time read are suspect andrew good discoveri ill pass the question onto the rta edit wouldnt it be obvious if they werent make the adjust sinc peak traffic time would chang paresh thank for the thought provok question i agre with denni i am more interest in the time delay than the percentag delay on a relat matter we think it is more import to predict correct when travel time are volatil e g befor and after work to favour model that predict more accur dure high volatil time we select more high volatil cutoff point so youll notic more cutoff point dure the morn and afternoon phil thank for share this just got to find a window machin to run it on aidan have ask the rta about this this was the respons the cutoff is due to free flow condit impos by the system dure data unavail ive written again ask for a littl more detail will post the respons when it come i have some inform on suspect loop read that im work to releas this has inform on when loop read may be unreli for various reason i dont yet know whether or not this will help with the free flow issu anyway i will upload them as soon as i can get it into a use format i suspect the reason the free flow time are differ is becaus rout length are differ rob on your point about miss data it might be help if i explain how i put the file togeth i receiv data in the follow formatrout i dtimestamptravel time xxx xxx i transpos them into in the hope that theyd be more manag when timestamp were miss i just fill in a blank row aaron anoth good question have also pass this on to the rta daniel and denni are correct keep in mind that the per cent is a random select of the that doesnt count toward the final stand which are calcul base on the other per cent burak the time in sampl entri csv are the time you need to generat forecast for there more info on how the cutoff point were select in this forum post mmm my messag seem to have disappear from the board anyway here a repeat aaron the unit are decisecond nick actual it a hybrid approach you can nomin five entri that count toward the final stand you do this from the submiss page the last five are chosen by default at the end of the competit the best of your five nomin entri count toward your final posit and nick on your new question the one of the five you nomin that score best on the per cent count the per cent is meaningless as far as the final stand are concern the cutoff time are all between am and pm they were select use a simpl formula that favour high volatil cutoff time over low volatil cutoff time so youll see more peak hour morn and afternoon cutoff time the rational behind this is that it more import to predict accur dure high volatil time so we want to favour model that do best at these time that explain whi the rmse is higher than for random chosen cutoff point thoma i select specif cutoff time random but chose timeday combin that are volatil across the dataset rasmus apolog i delet the wrong post anyway you ask how travel time are measur there are regular space loop along the m these loop measur each car speed and the number of car that travel across the loop everi three minut travel time are then calcul use a formula the formula has been test and calibr use test car that travel along the freeway and record their travel time benjamin onc we get the incid data i will put in a request for this data hassan the most import file is r t a data csv you can creat a sampl entri by download r t a data csv and creat histor php attach to the same directori navig to that directori in the terminalcommand prompt run php creat histor php this will creat an entri base on a histor averag for that timeday and is a good start point bjb veri generous of you to upload a java code ive now enabl java file upload so you should be abl to upload the file aaron you rais a good point accord to the rout definit i have rout extend from loop a to loop a while rout extend from a to a so should encompass all of denniss observ that sometim has longer throughput time than is strang ill doubl check the definit with the rta konstantin just upload r t a error csv the is valid data it avail on the data page mooma i appreci your frustrat but sensor malfunct are part and parcel of deal with realworld data if we had the data readi at the outset we might have exclud fail sensor and downweight the impact of partial fail sensor when evalu predict konstantin denni is correct it is not safe to assum that there is no error in the control data ahm just got an answer from the rta on this here the respons the answer is mayb rta would request that anyon wish to use the data for further research purpos write to the rta and make their case describ what they wish to do ie the purpos of the research and how they would use the data the rta will consid each applic on it merit let me know if youd like me to pass on the relev email address im reluct to do it in the forum but will offer an introduct to anybodi who ask rob thank for jump in dielson good pick up denni is correct the date format doesnt matter what is import is that you put the correct data in the correct cell mani thank to everyon for all your great activ on this fascin problem insight question and comment on the forum good earli result on the leaderboard and interest discuss there have been a lot of question about exact what constitut an accept model for the rta so far my guidanc on this matter has possibl been too fuzzi and i hear a lot of you look for more definit rule therefor we have come up with the follow specif rule regard the allow model input your model can be of ani form you like as long as it take it input onli from the follow paramet time of predict day of week is holiday month of year rout number to be predict the time taken for rout r for datetim t where r is ani rout and t is ani time less than the datetim be predict for as mani rout and datetim as you wish the sensor accuraci measur for ani rout r and datestim t defin as abov the estim rout distanc as provid by kaggl to clarifi the follow are not permit the use of ani data other than those provid by kaggl for this competit and the list of nsw holiday the time taken for ani rout in the futur compar to the predict be made your model can still be train use all data as long as the result model onli use the input list abov furthermor the algorithm must not be encumb by patent or other ip issu and must be fulli document such that the rta can complet replic it without reli on ani black box librari or system hi alexand no use full timestamp make it possibl for a model to implicit incorpor extern data and futur data you may also use holiday data extract from the pdf file that you link to in order to get holiday inform for previous year howev we will not be provid a file of this inform direct this is correct anthoni as jeremi howard point out earlier in this thread the key point that answer most of these question is that the limit is onli on the function form of the final model more specif xiaoshi lu you can build your model filter aggreg etc use all the datetim inform you like the final function form that you end up with howev should onli use the predictor list abov mooma the input list includ this the time taken for rout r for datetim t where r is ani rout and t is ani time less than the datetim be predict for as mani rout and datetim as you wish so what you ask is specif allow of cours for you to creat your input file which includ for exampl the time taken one hour earlier you will need to use the full datetim howev the result model will not direct use this instead it will onli use the time taken on that rout as allow by the rule alexand groznetski imagin use a veri flexibl model neural net for instanc which train with all datetim info includ in the input paramet it might implicit end up use the rout time later in the day to predict those earlier this is an exampl of how a model could be useless in practic even although it appear high predict on the competit data matthew use gpl code is fine the isholiday variabl can be a direct input rather than a variabl that is deriv by refer to a timestamp you contact me direct at anthoni goldbloomkaggl com denni you can use isspringbreak rather than isholiday nichola a matlab solut is fine as long you dont includ librari that use patent or undocumentedsecret algorithm rafael and are fine is also fine as long as the data is deriv entir from the time seri as you say jose i notic that you are now on the leaderboard it can take a few minut befor you show up anthoni david it realli neat for info it work in safari but the page video are align a littl strang the in the money indic is base on the public leaderboard onli it doesnt reveal anyth about the final stand reginald pleas email your submiss to anthoni goldbloomkaggl com and ill have a look wu wei a rout is made up of sever loop a figur of mean that per cent of the loop in the given rout are give suspect read for anybodi interest here the actual solut nathaniel is right the data is correct it just a problem with head format will fix this short and reupload the data final fix the head just to reiter all the data are correct it just the capit in the head that caus troubl as for the inconsist number of delimit also fix my softwar packag stop print delimit when there were no more valu or n as in a row jack the countri of birth issu is now fix pleas download the latest version of the data attach is some r code to creat a glm entri for this competit as alway happi to hear feedback from other about how this could have been done more eleg anthoni person i ds refer to all the column that have investig i ds e g column has investig column has investig ignor the comment numer valu that should be no toward the end of this competit you will be ask to nomin five entri that count toward the final result p v kiran it mean that if your solut is implement use a softwar packag that is not avail to the univers of melbourn it must be possibl to translat your solut into a differ packagelanguag just elabor a littl the type of solut that cant be implement are those that are encumb by patent or other intellectu properti restrict nathaniel thank for point this out definit worth investig the number of success grant and number of unsuccess grant field dont chang in the test dataset for obvious reason the journal citat also remain constant in the test dataset to prevent particip use the futur to predict the past nathaniel i have look at the problem in some detail and have spoken to the univers of melbourn they are look into it and hope to have an answer for us tomorrow befor they break for christma the univers has spent the last two day on the problem they suspect it an intern inconsist in their databas the figur are drawn from differ part of their databas well have to wait until the end of the christma break to get a final verdict deepak thank for point this out we will ask the univers about this as well unfortun we cant expect an answer until earli next year the univers has done an investig and has found that the issu aris from an inconsist in their databas michelangelo truth is that you can submit ani real number we suggest a number between and becaus of the conveni interpret auc rank your score the higher the score the more confid you are that the instanc is a member of the posit class i believ it refer to grant made when the research was at anoth univers edith thank for the feedback we agre with your comment and we are work on make the term more competitor friend michelangelo the per cent come from the test dataset eu jin lok the sampl is done random hi greg the answer will be made avail on the forum i can ask whether the data can be use for publish research if you like kind regard anthoni hi greg and suhendar the univers doesnt want the data to be use for ani purpos other than for this competit anthoni hi greg it would be nice if the dataset could be use for other work howev if we dont allow competit host to place restrict on the use of their data then we wouldnt get access to it in the first place will post the solut file now regard anthoni the solut file is attach to this post thank all for particip anthoni apolog i didnt clarifi this with mahmoud befor the launch but we have discuss this offlin this competit requir you to choos five entri that count toward the final result to choos five entri visit your submiss page and click the star next to the relev entri to select it if you do not choos ani entri your last five entri will be chosen by default hi all submit from multipl account is most definit against the rule we have done some analysi and found that it happen veri rare howev we are work to put the system in place to identifi and block those who attempt to do it kind regard anthoni harri thank for the thought post the ijcnn peopl agre with you and have decid not to disqualifi shen as mention abov kaggl will soon have the system in place to detect multipl account in real time so that such issu dont aris anthoni i have sympathi for peopl frustrat in this case the competit host decid that the result should stand so we are facilit their decis chris make a good point about the rule be scatter throughout the site we will be sure to address this in futur competit we will also ensur that they are tight enforc for inform a lot of effort has gone into frame the heritag health prize rule final thank for the feedback it discuss like this that will help us improv kaggl kaggl has receiv legal advic after the controversi surround this competit we have been advis that it set a danger preced for us to ignor our own term and condit notabl claus prevent multipl signup we have therefor act in accord with this claus disqualifi those who clear submit from multipl account thank you all for your patienc on this issu and rest assur that we are work to ensur that it is not a featur of futur competit the solut is attach thank all for particip anthoni entri made befor we fix the leaderboard were score incorrect i have now rescor the relev entri the error was the fault of kaggl and not the competit organ apolog anthoni hi cerin apolog for the error they all stem from the fact that the server hard drive fill up ive clear some space for inform were current rewrit the entir site for the heritag health prize you can expect the next version to be faster and includ mani more featur thank for your patienc anthoni hi cerin ali is right your entri will count toward the final stand anthoni also cover by slate and forb and the wall street journal a coupl of week ago and smarter planet dorofino great idea form a team is a realli good way to learn are you affili with the new york r user group for info ive heard rumbl about them set up a team good luck with this anthoni apolog this was an error thank for draw our attent to it the miss valu are for those peopl who have been in hospit for more than two week they should be replac with a you can either do this yourself or download the updat dataset for inform member who have in hospit for more than two week have been group for privaci reason they are rare so may otherwis be identifi the implic of this group is that if you expect somebodi to be in hospit for more than two week you should predict day this group should not have a big impact becaus a member who are in hospit for more than two week are rare about one per cent of member b the evalu metric favor algorithm that accur predict fewer day in hospit on the assumpt that these are more prevent hi rich just spoke to hpn about this for the moment they dont want to provid general guidanc and ask that you make a request through the contact us form your request should detail the topic of your propos research definit worth make it clear that your just look to publish the method that you use to enter the competit anthoni wgn the intent is not to rule out the public of research ive pass on your messag to hpn and a clarif will be forthcom ashojae the clarif havent been made yet apolog for the miss valu it was an error you can either replac the miss valu with or download the updat data set if your interest in the reason for the miss data see y y y etc refer to differ year we havent reveal which year to help keep the data privat agre see the updat evalu page the year are sequenti we are not reveal what year yn refer to nor whether or not they refer to calendar year for data privaci reason just to clarifi when jeremi say we clean it as much as we can we didnt do much to the claim data on purpos we figur it make more sens for you to make your own clean assumpt rather than have us impos them on you the criteria was that somebodi had to make at least one claim in y be elig to make a claim in y outlier have been remov from the dataset as well as those suffer from stigmat diseas not onli are patient who die in y not in the dataset but patient who die in y are also not in the dataset becaus they didnt remain elig to claim for the whole of y rudychev receiv an answer from hpn on this a patient who visit a clinic outsid the network should be captur in this dataset of cours as jeremi keep reiter there is alway a disconnect between realiti and the content of a databas hi bacg day in hospit refer to y the second year while the claim refer to y the first year not everyth that has a length of stay count as a hospit in fact you dont have enough detail in the claim tabl to calcul day in hospit the detail has been suppress for privaci reason anthoni hi mbenjam we would have love to releas more detail data but have to be mind of data privaci anthoni mgomari one issu we have to keep in mind are the tradeoff in releas data for data privaci reason hpn have a granular threshold which theyr not will to breach the data anonym team repres by keleman in the forum are tri to releas c p t code probabl at an aggreg level appar it pretti linebal and releasng day in hospit y might put this in jeopardi i describ the data privaci consider like a waterb you push down on one part of the bed and it creat a bulg somewher els after may youll be abl to use day in hospit y and day in hospit y to predict day in hospit y ogenex even if we releas day in hospit y you wont be abl to do a consist check not all length of stay count as hospit as calcul for this competit and you dont have enough detail in this dataset to work out which count and which dont ssrc map los to dih is imposs not everi los entri correspond with a dih e g hospic stay one reason somebodi may have dih in y but no claim is if they werent elig to claim in y in which case their y claim wouldv been remov have receiv advic from the hpn lawyer im realli sad to say that the answer is no on all account the lawyer are take a conserv stanc on this issu apolog it realli disappoint to have peopl rule for this reason flsdcom i have a meet with them in minut i will be sure to rais this point in respons to ashasho origin question i have sought a reexamin of the issu the hpn lawyer explain that the reason for the hard line is that they have no way to verifi that resid permit compli with us legisl im realli sorri to say that there not more i can do cybaea mani thank for a great discoveri after do some dig weve discov that the oddeven observ is an artifact of the clean procedur we have work out a remedi and it will be appli to the dataset that will be releas on may in the meantim it shouldnt make a huge differ to model that are current be develop boegel yes on may we will be issu signific more data day in hospit y csv will be chang then eu jin youv obvious not seen this frankthedefalco com or the women who have been treat for erectil dysfunct tom sf hain jeremi is not the author of the rule he is mere tri his best to point peopl to the section that make the rule as competitor friend as possibl given h p ns requir also if you would like to publish your algorithm i strong encourag you to put in a research request use the contact us form the decis to predict day in hospit was made to make the test dataset richer so we can better sort out good algorithm from bad the logarithm in the evalu metric was chosen to favor model that predict short stay more accur as these are assum to be more readili prevent as for the question of nefari intent i can tell you what i know about dr richard merkin the man behind the prize he is a big philanthropist who devot time and resourc to fund scientif project school and the art in my opinion hpn did not need to put up million to get an amaz algorithm kaggl has found in it own competit that with prize as small as or a chess dvd particip approach the limit of what possibl on a dataset in our communic with hpn we have been told that the million prize is an attempt to draw mass attent to this prize and the issu in general dr merkin want to promot the potenti for medic data mine in lower healthcar cost the prize also serv to introduc a larg number of talent data scientist to medic data final rest assur that hpn are work hard behind the scene to clarifi the ip issu alexx the hpn lawyer are work on a clarif this will be releas by the time entri can be made on may hi drew it will be in place by may when entri are accept anybodi who accept the exist rule will receiv the notif via email anthoni the accuraci threshold will be announc when we releas the full claim dataset on may this is a sampl of the final dataset but the final dataset is not in the terabyt rang to the best of my knowledg this dataset is on the larger side for medic dataset which tend to be quit small this algorithm will not need to oper in a realtim environ and so there is no restrict on execut time i want to reassur everyon that hpn is work hard behind the scene to clarifi the ip issu it is not their intent to prevent peopl from use standard tool nor to discourag anyon from appli their innov idea to this problem for background at monday launch event dr richard merkin the man behind the prize spoke of the long tradit of innov that has result from past prize he spoke of the longitud prize appar newton and galileo had attempt to solv this problem but the winner was a self educ clockmak from yorkshir napoleon food preserv prize won by a confection and result in the invent of can food the orteig prize to fli nonstop from new york to pari won by the unlik charl lindbergh it is his hope that this prize will spur similar innov to solv one of america most vex problem we appreci your patienc while we await clarif kind regard anthoni for those who dont know jphoward was kaggl most success competitor befor join the team his tutori give realli clear explan of the tool and techniqu that made him such a success competitor hi jim that is correct for inform the reason for the misnom is that it was day when we sent it to the anonym team but they had to group the day to ensur the requir level of data privaci anthoni sciolist yes team are requir to publish public mkarbowski as jphoward keep point out there often a massiv disconnect between realiti and the content of a transact databas see ejlok humor post for even odder record we intent decid against clean the data so as not to impos our assumpt on particip we want the forum to be tight integr into the site e g to be abl to link to forum post from profil and vice versa yaf is the best net forum softwar out there and integr it into kaggl is more troubl than it worth also moserwar is a brilliant programm so it the type of thing he could put togeth in less than a week dih includ inpati admiss and emerg room visit as mention previous you dont have enough detail to calcul it from the claim tabl ralph h day in hospit count day not night so if day in hospit is then they have not been to the hospit at all if they were in and out of the er then day in hospit would be domcastro one of kaggl first suggest was to remov the registr fee for info the registr fee wasnt ever to rais money but to tri and deter peopl who werent serious from download this sensit data kaggl point out that anybodi with malevol intent would probabl still pay the modest registr fee so it effect would be to deter peopl who didnt think they had a chanc of win kaggl went on to argu that these peopl may also come from interest background and may be the one most like to appli creativ think to the problem realworld data is messi well put up a data dictionari soon day in hospit is calcul base on the length of stay variabl howev you dont have enough detail to calcul day in hospit from length of stay quotedaveim serious i understand the need for random and anoym the data but unless they have some way to unrandom it afterward ani algorithm we creat will serv no real world applic quot daveim the data is messi not becaus it been peturb but becaus it realworld data anonym focus on general again not peturb the the nineyear old pregnant male actual exist in the raw data for info im told that this is one of the cleaner medic claim dataset around mgomari the differ between and is count as two day overlap were account for so were not doubl count fjn pi doe not have to be an integ blonchar your correct hpn are limit in what it can releas by the need to protect patient privaci liveflow i may be misunderstand the question but the competit requir particip to use data from y y and y to predict y no some y patient are no longer elig in y we still provid y patient who arent elig in y becaus theyr use to train on dougi d everi member list in day in hospit y is elig to claim in y so if they have dih they are abov the same will appli for the member list in day in hospit y and day in hospit y when we releas those file jesenski you will be abl to use day in hospit y and day in hospit y as an input to day in hospit y i like your think on the use of other data loophol if the answer had been no creativ think mgomari the answer to both question is yes inform man that is not the intent of the rule the hpn lawyer are work on clarifi this at the moment no again for privaci reason irwint good pickup thank now fix gschmidt not sure if this answer your question but the geograph spread is limit to the area in which hpn oper southern california i believ as to whether patient chang doctor on may youll have a few year worth of data so will be abl to work this out you will get some procedur code inform in the may releas i understand the frustrat but data privaci is a prioriti for hpn metaxab the competit was design this way to replic how the model might be use in real life in a real life situat you wouldnt be abl to predict hospit with contemporan claim day in hospit y is deriv from the claim tabl where a hospit stay includ an inpati stay or an emerg visit note you dont have enough inform to calcul day in hospit y from the claim tabl in this dataset miss pay delay either mean unknown or greater than in the may releas the anonym team will topcod pay delay so there will be fewer miss valu and will mean for generat featur i recommend s q l lite though my s q l doe the same thing i know jeremi and jeff like cs linq for build model i use r the rule do not prohibit oracl data miner rks we will post a sampl entri with the rest of the data on may trezza and rhm y contain data for a period trezza unfortun not the anonym team have identifi this as a data privaci risk hi allan that becaus some member have had claim suppress in releas come soon well make it clear which member this appli to anthoni hi domcastro can i use r yes can i use weka yes can i use excel yes if i organis the data in a novel way and just use a standard process algorithm such as naiv bay is this ok yes you must preserv the order in target csv unfortun not apolog for ani inconveni darragh it a list of all member in the dataset releas zip doe supersed releas zip chris just heard back from the data anonym team member have been renumb no cacross hpn had a granular threshold that they want to remain below some l o ss had to be suppress to achiev this target if there is a blank los and sup l o s is then this is how it was when it came out of the hpn dataset if there is a blank los and sup l o s is then the los has been suppress hope that help mkwan you fill in the team wizard when you make your first entri team merger will be grant at the organ discret chris r nice to see you compet in this sampl is random yes bernhard your interpret sound about right to me we cant give you an hpn benchmark becaus theyv not tackl this problem befor boegel day in hospit y contain member who made a claim in y and were elig to make a claim in y day in hospit y contain member who made a claim in y and were elig to make a claim in y similar target csv contain member who made a claim in y and were elig to make a claim in y to be elig mean to be an hpn member regardless of whether or not a claim was made therefor the member in day in hospit y are not miss from target csv but rather didnt make a claim in y or werent elig to make a claim in y therefor all member in target csv were elig to make a claim in y so we have an answer for each of these member jesenski by my calcul member appear in day in hospit y and day in hospit y but not day in hospit y perhap you can confirm this figur these member are miss from day in hospit y becaus they didnt make a claim in y despit be elig apolog if we didnt communic this effect in the descript page pro tester there noth in the raw data that distinguish a death from a patient that leav hpn for anoth provid dan b your right about the select bias but becaus hpn are releas almost no inform on the member themselv there noth to model on for patient without claim georg there are member in the dataset but you are onli test on member that becaus the extra member arent elig to claim in y or didnt claim in y they have onli been provid to help you train your model further to will point those who follow the netflix prize will rememb the jump from the simon funk discoveri is the maximum ive said this befor but i think jeremi tutori is realli excel although it is not focuss on hhp he is hope to get the opportun to do an hhp tutori in the next few month darragh i pass your question onto hpn here the repli is there a delay between the schedul of the surgeri and when it take place yes but that is just a matter of schedul not someth forc by the govern it would also of cours depend on how urgent the surgeri is she will be ad in the next releas the intent of that provis is to prevent the data be share with those who have not agre to the competit rule jeff was just refer to the measur he would take to ensur the data isnt access to other jose thank for your dilig on this it difficult for us to give specif guidelin again hpn is just tri to prevent the data from be access to those who havent accept the rule jim it be assess against y hospit thank dave the data descript has been fix hi bobbi can you clarifi what you mean by this are you ask if they are oblig to share their model if they finish in first place anthoni i have check with hpn and a mileston prize winner can choos not to disclos their method but will not be elig for the mileston prize correct hi willem to what extend the result have to be ident for exampl small differ in the random number generat may give differ result although they should be similar they do need to be ident you can give your random number generat a seed to make sure the resultl are the same each time in how much time should the result be reproduc my current best result is a mix of mani model each may take minut to hour to generat there is no rule about execut time the algorithm should produc similar result on a new dataset this doesnt sound veri realist i dont think there is ani way to win this competit without optim for this specif dataset result on other dataset may be veri bad with the given optim probabl veri good result can be produc by the same algorithm after some tune but this is a process that requir a lot of knowledg about the use algorithm and a lot of time and patienc not sure i follow whi this is an issu rememb the mileston prize is judg in a portion of the test dataset that particip have not been given ani feedback on perhap im misunderstand the concern hth antthoni regard the requir that solut be ident willem it would be better to have particip spend time on innov rather than reproduc howev it import to have strict rule so that the competit remain as fair as possibl b yang with regard to the compil issu we can address it if the issu aris for exampl we might start by ensur that the same compil is use for verif sali mali it is except to describ the algorithm and not how it is deriv we are seek clarif from hpn on the inconsist that you describ apolog for the delay regard the requir that the algorithm perform similar on a separ dataset this is best answer by explain the rational behind the rule it is there to catch ani cheat or blatant overfit if your not blatant overfit then your like to be on safe ground hi all not ignor this thread just seek clarif from hpn on one issu anthoni sorri for the delay on this was just clarifi some issu with hpn is it inconsist as sali mali point out in anoth thread to requir document of the win algorithm be public disclos to all competitor given rule entrant represent it seem that this disclosur will encourag other competitor to use aspect of the win predict algorithm which caus violat direct or otherwis of i iii and possibl iv of that rule rule doe not appli to the extent that it prevent a competitor other than a mileston prizewinn from use code publish by a mileston prizewinn in accord with competit rule and b a mileston prizewinn from compet subsequ in the competit use code for which it was award the mileston prize can you clarifi that code librari and softwar specif are not requir to be public disclos to competitor these materi and intellectu properti appear to be referenc separ from predict algorithm and document chris correct point to jeremi respons in an earlier forum post “ onli the paper describ the algorithm will be post public the paper must fulli describ the algorithm if other competitor find that it miss key inform or doesnt behav as advertis then they can appeal the idea of cours is that progress prize winner will fulli share the result theyv use to that point so that all competitor can benefit for the remaind of the comp and so that the overal outcom for health care is improv ” will kaggl or heritag have a moder or appeal process for handl competitor complaint from the win entrant pointofview they would not want to be forc through the review process to allow backdoor answer to code and librari which acceler a competitor integr of the win solut kaggl and the hhp judg panel will moder the appeal process can you comment on the spirit and fair of the public disclosur of the predict algorithm document and it impact on competit in particular if the document truli doe meet the requir of enabl a skill comput scienc practition to reproduc the win result then this place the win team at an unfair disadavantag all competitor will have access to their algorithm and research in addit to the win algorithm this rule is in place to promot collabor those who would prefer not to share can opt out of the prize can you provid more detail clarif on the level of document requir by condit mileston winner the guidelin provid by the rule would cover a rang of detail and descript span from lectur note to detail tutori to whitepap to confer paper etc hope this was adequ dealt with in jeremi respons requot abov let me know if further clarif is need can you comment on the reproduc requir for exampl it is possibl to construct algorithm with stochast element that may not be precis reproduc even use the same random seed is it suffici for these algorithm to reproduc the submiss approxim what if they dont reproduc exact or reproduc at a predict accuraci that is wors than the submiss score possibl wors than other competitor submiss exact reproduc is requir john onli the lowest of the five entri count note for the mileston prize onli one can be select anthoni if you were per cent sure that somebodi would spend day in hospit in y and per cent sure they would spend day in hospit than you might predict that they spend would day in hospit pham you do not have enough detail in the claim data to reproduc the dih proper youv like reproduc dih from claim data as accur as is possibl sir guessalot thank for the pointer it been ad to our issu tracker i must admit we have higher prioriti issu to tackl but well get there eventu just to keep you all in the loop the plan is to announc the mileston prize winner at o reilli strataconf will let you know the exact date as soon as were told full mileston prize rank will be releas after the announc is made provision mileston prize winner will receiv an email over the weekend an announc will be made at strataconf on septemb correct congratul team market maker and willem great coverag in the wall street journal here for those interest here the footag from the award ceremoni jason the anonym guy have withheld this inform intent to make the data set more secur sorri hi all hpn are current look for data scientist heritag provid network the sponsor of the heritag health prize is look to hire data scientist to take it data and analyt depart to the next level if you are interest in healthcar join the largest physician group in california and one of the largest in the unit state and use your data mine skill to make a differ in the provis of health care to individu throughout southern california if interest pleas send an email indic your interest to datascientistheritagem com anthoni doe be a member of hpn mean you usual refer to an innetwork provid of say lab test unless obviosuli it is some specialti unavail yes can you be a member of hpn and have govt sponsor insur eg medicar medi cal yes for medicar i can follow up on medi cal if you like have pass these question onto hpn will respond as soon as i get an answer we are awar that the rule havent been as clear as we might have like pleas be remind that you cannot sign up to kaggl from multipl account and therefor you cannot submit from multipl account and privat share code or data is not permit outsid of team share data or code is permiss if made avail to all player such as on the forum weve reach out to sever team about this issu pleas let us know asap if you have multipl account and weve not reach out to you entrant are welcom to use other data to develop and test their algorithm and entri until utc on april if the data are i freeli avail to all other entrant and i publish or a link provid to the data in the “ extern data” on this forum topic within one week of an entri submiss use the other data entrant may not use ani data other than the data set after utc on april without prior approv on octob the judg in their sole discret decid whether or not the document is suffici take account of the comment made on this forum if they decid the document is not suffici they can impel the winner to address their concern in the seven day follow octob if the winner are ask to resubmit particip have anoth day from novemb to rais ani addit complaint the judg panel are experienc academ review hi all we are in the process of liais with the judg well report their decis as soon as we have everybodi feedback hi guy glad you like this dataset remind me of the rta data which was realli popular on the ip question when no rule are explicit state the kaggl term and condit prevail specif claus by accept an award you agre to grant a licens to the competit host to use ani model use or consult by you in generat your entri in ani way the competit host think fit this licens will be nonexclus unless otherwis specifi anthoni libraryrandom forestsetwd c usersantgoldbloom dropbox kaggl competit credit scoringtrain read csvcstrain csv r f random foresttrainingctrain serious dlqinyr sampsizecdo trace t r u eimport t r u entreeforest t r u etest read csvcstest csvpred data framepredict r ftestcnamespr serious dlqinyrswrit csvpredfilesampl entri csv alec set the random seed is a good idea domcastro your hypothesi is correct your correct shouldnt includ header we have made a slight chang to the term and condit ad no individu or entiti may share solut or code for ani competit or collabor in ani way with ani other individu or entiti that is particip as a separ individu or entiti for the same competit the forego shall not appli to ani public communic such as forum particip or blog post we are also awar that the rule havent been as clear as we might have like from now on befor you download the data for ani new competit you will be remind that you cannot sign up to kaggl from multipl account and therefor you cannot submit from multipl account and privat share code or data is not permit outsid of team share data or code is permiss if made avail to all player such as on the forum weve reach out to sever team about this issu pleas let us know asap if you have multipl account and weve not reach out to you it is a mistak were sorri for it but weve decid not to correct it becaus it might not be fair to some contest if we chang the data midstream shouldnt be too importanton happen to chunk it the same mistak that caus a few chunk to have some miss data within the chunk sound like there a thrive communiti in melb which look to have been the strongest perform citi congrat all donovan weve look into this and it turn out that a bug with our process meant that we hadnt receiv the past few week of queri weve found your email and you will receiv a respons short as will other who slip through the crack apolog to you and other who have not receiv a respons as a result of this error whi doe lower bound get mention so much more than upper bound thank for the thought comment first off as alway we will not make retrospect chang to how we handl past competit includ this one when issu like this come up we use it as an opportun to evalu how we might improv in the futur intern our debat focus on three issu recognit for those who complet stage one but not stage two achiev and how the competit appear on profil th out of look more impress than th out of how point are handl recognit for those who complet stage one but not stage two we need to view the stage one leaderboard as have no weight if it get a weight we incentiv overfit or hand label for stage one achiev and how the competit appear on profil if we did what julian suggest and add stage one particip to the bottom of the stage two leaderboard we undermin our rank by make it veri easi for somebodi to get an impressivelook top achiev by finish th out of with a naiv submiss how point are handl the one chang we will make in futur is the way point are handl we will add a multipli to the number of point for a twostag competit we have not settl on a formula for do this yet but commit to communic it clear in the rule of the next twostag competit these are difficult issu but we think this approach strike the best balanc between compet consider just a head up that were still work through the winner solut will need more time to befor announc the final result as offici quick updat we will announc the offici result on wednesday march at am et julian respond in the other thread hi all the result on the final leaderboard are now offici congratul to the winner and all involv this is among the hardest and most ambiti competit weve host we couldnt be prouder of the result the competit has receiv some press coverag with a chanc of more to come anthoni love it interest that for everyon other than woodrow wilson the name popular monoton declin over the cours of the presid dwight look like it increas in popular dure ww which make sens one suggest is to add year to the x axi label for each chart to make thing like this easier to spot i tweet this script and somebodi repli ask is there a correspond drop in the name frequenc of the lose presidenti candid right after the elect i was think anoth interest extens would be to answer the question what most influenti in determin babi name trend out of presid and first ladi musician that was for longest on the billboard chart in a given year best actoractress in the oscar basketbal footbal basebal m v ps nobel prize winner name time person of the year if nobodi els tackl this i might tri it this build off a convers i had with my cowork meghan who said itd be interest to see whether presid or royal babi had a bigger impact on babi name nice done and fun write style one addit conclus is that real data is messi big data borat captur it best in data scienc of time spent prepar data of time spent complain about need for prepar data ive play with pca befor but never associ plot or mca glad to see an exampl usag and be abl to add these to my toolkit thank you for the associ plot i assum the width of the box refer to the number of tweet refer that that airlin i assum is the proport of comov explain by the first dimens is that correct is it typic for the first dimens to explain so much of the comov ani thought on how to interpret this dimens small nit you might want to chang res to reason i initi assum res stood for residu and reduc the font size for the x axi label on plot that the most interest plot to me but it hard to read the label becaus they overlap from this page this is a nice notebook suggest to make this easier to follow for those who havent yet look at the data itd be great if you ad a section show a few row or possibl even a few exploratori chartshistogram perhap after the load the data section itd also be nice to see the befor and after you preprocess the data ie befor and after the use textmin to format our data section renam the use textmin to format our data to someth like clean the data great i alway look at the top rate notebook befor look at the data becaus the notebook usual give me a sens for what in the data and what i could do with it this is great im surpris north america is not higher for sugar the sweet of food was one of the first thing i notic when we move to the us from australia although it could be becaus a lot of the sweet come from high fructos corn syrup which is not captur it awesom realli nice put togeth bluefool i thought you came out realli well interest how noisi the veri earli year are i suspect the s data is veri poor qualiti realli nice script interest to see the temperatur uncertainti chart give a nice visual of when the data start becom more reliabl also nice idea to put dt into a variabl import plot to see it relat import obvious would have been more interest if wed provid more data one suggest is to better label your plot there some good stuff here but it stake a while to figur out what each chart is show i actual look at your code to figur it out i suspect this script will be more popular with some label that make it easier to follow sven have you been abl to figur out an interpret of this chart thank itd be help if you label the chart and possibl ad sub label point to your interpret it may not be use for the reason you mention but it look nice would be cool to see the by citi version i assum you didnt use it initi becaus of the size of the data set btw i assum red hot would be help to have a key is this a work in progress or is there an error the chart are show up blank for me cool as someon who live in san francisco im curious juanchaco this is neat but itd be easier to follow if you ad a descript between chart at the moment im scan the codecom to tri and figur what each chart is show ha id not known about this for other akshay this script would be more interest if you found a neat way to visual temperatur by countri love this chart and the titl is funni\n"
     ]
    }
   ],
   "source": [
    "print(forum_data_agg['clean_messages'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good. Now that all the messages are cleaned and stemmed, I'll build my pipeline and test a few different classifiers. For the training data, I will sample a percentage of the total data because it will take forever to run the whole training dataset. I get about 1-3% decrease in f1 score with just 10% sample of the total dataset depending on the classification algorithm, but I save hours of computing time. Worth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      type                                              posts  \\\n",
      "5726  ENTJ  'Enfj|||Resting Steve Job's personality type o...   \n",
      "5503  INFP  'In friendships and relationships?  Trying to ...   \n",
      "8069  INFP  'I know I said before that I wanted to stay ho...   \n",
      "611   INTP  'Nailed it.|||Bingo. From my own experience (o...   \n",
      "917   INFP  'I'm itching so hard for that 300 What's your ...   \n",
      "1978  ENTP  Just to make things clear, my ex was 100% an I...   \n",
      "7815  ENFP  'I'm with you guys...trying to figure it out t...   \n",
      "6281  ISFJ  'You're welcome. :)  I'm direct with my intere...   \n",
      "8625  INTP  'Hahaha, what is this sleep you speak of?|||Ne...   \n",
      "6940  INFP  'So true!  I said earlier that my face was ver...   \n",
      "1162  INTP  'How to know if I like you: If I choose to sit...   \n",
      "915   INFP  'I suppose Robin Hood was a Socialist since he...   \n",
      "2276  INTP  'I'm back again. Thank you all for the welcome...   \n",
      "1741  INTJ  'Well said , Codger.|||You will like it. :prou...   \n",
      "610   INFP  'difficult... draw things into reality perhaps...   \n",
      "4147  INTP  'I suppose it would feel like atheism so...I w...   \n",
      "8269  ENFP  'All the ENFPs (2 guys, 3 girls) I know are ac...   \n",
      "3064  ENFP  'Note: I haven't read the whole thread, but I ...   \n",
      "6411  INTJ  'Book is awesome!|||200506200514200522 Futurit...   \n",
      "7617  INTP  'I'm really curious as to what you do with the...   \n",
      "8101  INFJ  'Alright, I will finish the story  J     He ne...   \n",
      "3912  ISFJ  'NineTypesOfLight And hello to you, I am from ...   \n",
      "5451  ENTP  'overall (i.e. encompassing political, religio...   \n",
      "2313  INFP  'Why is it so hard for me to make friends? I c...   \n",
      "904   INTJ  'Work: Student.   Hobbies: Studying, gaming, r...   \n",
      "8060  ENTJ  'I wouldn't call it pretending..|||I started t...   \n",
      "5741  ENFP  'I'm pretty much on the side of thinking if th...   \n",
      "2897  ISFP  'Haha... :unsure: maybe you can wear them on t...   \n",
      "2385  ENFP  'Let's call it a 6.9 for me. (Mind out of the ...   \n",
      "1866  INFJ  'INTP.    Internet haters who think they're su...   \n",
      "...    ...                                                ...   \n",
      "7486  INFP  'If I'm interested in someone I'll flirt with ...   \n",
      "5608  INTJ  'Not worth it. Not worth it at all. To forsake...   \n",
      "3985  INTP  'I'm usually in my room, at the gym, at work, ...   \n",
      "3950  INFP  'I would say I'm definitely a shy extrovert, e...   \n",
      "6010  INTP  'First of all, thank you for responding. I rea...   \n",
      "8168  INFJ  'What I mean to say is our current state of bu...   \n",
      "2893  INFP  'I had a lot of difficulty determining my type...   \n",
      "2856  INTJ  'Depends on the definition of tough requiremen...   \n",
      "7353  INFP  'I very much like Syriac and Manichean.  Georg...   \n",
      "7186  ENTP  'I have found software development, business d...   \n",
      "5262  INTP  'So I know that since I am an INTP I am suppos...   \n",
      "1327  INTP  'Yeah, what Darky said, Steam always has a wid...   \n",
      "5179  ENTJ  'What E-type Sandra Maitri is? I like her book...   \n",
      "577   INTP  'Watch The Social Network and see if you relat...   \n",
      "2161  ENFP  Leahomme  he was tested for university  LemonI...   \n",
      "978   INTJ  'Measurable and observable facts are essential...   \n",
      "7286  INFP  'This thread is several years old, but I thoug...   \n",
      "4390  INFJ  'I searched the topic, clicked, saw something ...   \n",
      "1758  ISTJ  'Once I'm in one, I love it.  When I'm in a re...   \n",
      "7703  INTP  'I like the sax and piano, but I don't have th...   \n",
      "3399  INFJ  'Do you realize the hypocrisy of what you're d...   \n",
      "5139  ENFJ  I don't participate in most holidays, a big pa...   \n",
      "1300  INFP  'http://www.youtube.com/watch?v=bJGItzuFkEM  C...   \n",
      "8545  INTP  'True, but how often does that happen?  That o...   \n",
      "3708  ISFP  'Still no answers? No one has A.D.D? lol|||Lef...   \n",
      "7129  ISFP  'I was with an ENFJ, and this is extremely acc...   \n",
      "8023  INTJ  COBOL! :proud:  .|||Check out this link too......   \n",
      "4734  ISTP  'Indeed. Some tests have questions like:  Woul...   \n",
      "2476  ESTP  'her songs sound like the kind of things my IN...   \n",
      "5702  INTP  'Have any of you seen the Harry Potter posts h...   \n",
      "\n",
      "                                            clean_posts  \n",
      "5726  enfj rest steve job person type on the fact th...  \n",
      "5503  in friendship and relationship tri to understa...  \n",
      "8069  i know i said befor that i want to stay home a...  \n",
      "611   nail it bingo from my own experi other may be ...  \n",
      "917   im itch so hard for that what your profess mem...  \n",
      "1978  just to make thing clear my ex was an infj she...  \n",
      "7815  im with you guy tri to figur it out too it jus...  \n",
      "6281  your welcom im direct with my interest if i li...  \n",
      "8625  hahaha what is this sleep you speak of near fl...  \n",
      "6940  so true i said earlier that my face was veri e...  \n",
      "1162  how to know if i like you if i choos to sit wi...  \n",
      "915   i suppos robin hood was a socialist sinc he st...  \n",
      "2276  im back again thank you all for the welcom i j...  \n",
      "1741  well said codger you will like it proud never ...  \n",
      "610   difficult draw thing into realiti perhap one o...  \n",
      "4147  i suppos it would feel like atheism so i would...  \n",
      "8269  all the enfp guy girl i know are acquaint and ...  \n",
      "3064  note i havent read the whole thread but i want...  \n",
      "6411  book is awesom futur research news from top un...  \n",
      "7617  im realli curious as to what you do with them ...  \n",
      "8101  alright i will finish the stori j he never cal...  \n",
      "3912  ninetypesoflight and hello to you i am from an...  \n",
      "5451  overal i e encompass polit religi and metaphys...  \n",
      "2313  whi is it so hard for me to make friend i can ...  \n",
      "904   work student hobbi studi game read dvds anim m...  \n",
      "8060  i wouldnt call it pretend i start this a few m...  \n",
      "5741  im pretti much on the side of think if there a...  \n",
      "2897  haha unsur mayb you can wear them on the insid...  \n",
      "2385  let call it a for me mind out of the gutter fo...  \n",
      "1866  intp internet hater who think theyr super smar...  \n",
      "...                                                 ...  \n",
      "7486  if im interest in someon ill flirt with them i...  \n",
      "5608  not worth it not worth it at all to forsak kno...  \n",
      "3985  im usual in my room at the gym at work or in c...  \n",
      "3950  i would say im definit a shi extrovert either ...  \n",
      "6010  first of all thank you for respond i read up o...  \n",
      "8168  what i mean to say is our current state of bur...  \n",
      "2893  i had a lot of difficulti determin my type i t...  \n",
      "2856  depend on the definit of tough requir the more...  \n",
      "7353  i veri much like syriac and manichean georgian...  \n",
      "7186  i have found softwar develop busi develop and ...  \n",
      "5262  so i know that sinc i am an intp i am suppos t...  \n",
      "1327  yeah what darki said steam alway has a wide se...  \n",
      "5179  what etyp sandra maitri is i like her book i t...  \n",
      "577   watch the social network and see if you relat ...  \n",
      "2161  leahomm he was test for univers lemonic thank ...  \n",
      "978   measur and observ fact are essenti to understa...  \n",
      "7286  this thread is sever year old but i thought i ...  \n",
      "4390  i search the topic click saw someth i agre wit...  \n",
      "1758  onc im in one i love it when im in a relations...  \n",
      "7703  i like the sax and piano but i dont have the m...  \n",
      "3399  do you realiz the hypocrisi of what your do ri...  \n",
      "5139  i dont particip in most holiday a big part of ...  \n",
      "1300  classic intj humor right there folk xd social ...  \n",
      "8545  true but how often doe that happen that occasi...  \n",
      "3708  still no answer no one has a d d lol left hand...  \n",
      "7129  i was with an enfj and this is extrem accur fo...  \n",
      "8023  cobol proud check out this link too btw i didn...  \n",
      "4734  inde some test have question like would you ra...  \n",
      "2476  her song sound like the kind of thing my infj ...  \n",
      "5702  have ani of you seen the harri potter post her...  \n",
      "\n",
      "[868 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "subset_train = train_data.sample(frac=.1)\n",
    "\n",
    "print(subset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss': 'neg_log_loss',\n",
    "           'f1_micro': 'f1_micro'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english',\n",
    "                       lowercase = True)\n",
    "\n",
    "estimators = [('vect', vect), ('clf', MultinomialNB())]\n",
    "nb_pipe = Pipeline(estimators)\n",
    "\n",
    "nb_params = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (200, 250, 300),\n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(nb_pipe,\n",
    "                       nb_params,\n",
    "                        scoring='f1_micro',\n",
    "                        error_score=0,\n",
    "                        cv=kfolds,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(train_data['clean_posts'], train_data['type'])\n",
    "\n",
    "clf = clf_grid.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NB with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=225, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "{'vect__max_features': 225, 'vect__ngram_range': (1, 2)}\n",
      "0.566820276498\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "vect = CountVectorizer(stop_words='english',\n",
    "                       lowercase = True)\n",
    "\n",
    "estimators = [('vect', vect), ('clf', MultinomialNB())]\n",
    "nb_pipe = Pipeline(estimators)\n",
    "\n",
    "nb_params = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_features': (150, 200, 225),\n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(nb_pipe,\n",
    "                       nb_params,\n",
    "                        scoring='f1_micro',\n",
    "                        error_score=0,\n",
    "                        cv=kfolds,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(subset_train['clean_posts'], subset_train['type'])\n",
    "\n",
    "clf = clf_grid.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf seems to do worse as a preprocessor than CountVectorizer possibly due to lack of more data creating noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        ...ty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "{'clf__C': 0.003, 'clf__class_weight': 'balanced', 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "0.63133640553\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vect = CountVectorizer(\n",
    "                       stop_words='english',\n",
    "                       lowercase = True)\n",
    "\n",
    "logr = LogisticRegression()\n",
    "\n",
    "estimators = [('vect', vect), ('clf', logr)]\n",
    "log_pipe = Pipeline(estimators)\n",
    "\n",
    "log_params = {\n",
    "    'vect__ngram_range': ((1, 1),),\n",
    "    'vect__max_features': (4000, 5000, 6000),\n",
    "    'clf__C': (.003, .005, .075),\n",
    "    'clf__class_weight': ('balanced',)\n",
    "    \n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(log_pipe,\n",
    "                        log_params,\n",
    "                        scoring='f1_micro',\n",
    "                        error_score=0,\n",
    "                        cv=kfolds,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(subset_train['clean_posts'], subset_train['type'])\n",
    "\n",
    "clf = clf_grid.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression using df instead of tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "      ...ty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "{'clf__C': 0.003, 'clf__class_weight': 'balanced', 'vect__min_df': 0.1, 'vect__ngram_range': (1, 1)}\n",
      "0.624423963134\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vect = CountVectorizer(\n",
    "                       stop_words='english',\n",
    "                       lowercase = True)\n",
    "\n",
    "logr = LogisticRegression()\n",
    "\n",
    "estimators = [('vect', vect), ('clf', logr)]\n",
    "log_pipe = Pipeline(estimators)\n",
    "\n",
    "log_params = {\n",
    "    'vect__ngram_range': ((1, 1),),\n",
    "    #'vect__max_features': (4000, 5000, 6000),\n",
    "    'vect__min_df': (.1, .2, .3),\n",
    "    #'vect__binary': (True, False),\n",
    "    'clf__C': (.003, .005, .075),\n",
    "    'clf__class_weight': ('balanced',)\n",
    "    \n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(log_pipe,\n",
    "                        log_params,\n",
    "                        scoring='f1_micro',\n",
    "                        error_score=0,\n",
    "                        cv=kfolds,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(subset_train['clean_posts'], subset_train['type'])\n",
    "\n",
    "clf = clf_grid.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vect = CountVectorizer(\n",
    "                       stop_words='english',\n",
    "                       lowercase = True)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "estimators = [('vect', vect), ('clf', knn)]\n",
    "log_pipe = Pipeline(estimators)\n",
    "\n",
    "log_params = {\n",
    "    'vect__ngram_range': ((1, 1),),\n",
    "    'vect__max_features': (70, 75, 80),\n",
    "    'clf__n_neighbors': (38, 40, 42),\n",
    "    'clf__weights': ('distance',)\n",
    "    \n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(log_pipe,\n",
    "                        log_params,\n",
    "                        scoring='f1_micro',\n",
    "                        error_score=0,\n",
    "                        cv=kfolds,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(subset_train['clean_posts'], subset_train['type'])\n",
    "\n",
    "clf = clf_grid.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN with Tfidf Vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vect = TfidfVectorizer(\n",
    "                       stop_words='english',\n",
    "                       lowercase = True)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "estimators = [('vect', vect), ('clf', knn)]\n",
    "log_pipe = Pipeline(estimators)\n",
    "\n",
    "log_params = {\n",
    "    'vect__ngram_range': ((1, 1),),\n",
    "    'vect__max_features': (35, 70, 500),\n",
    "    'clf__n_neighbors': (5, 42, 100),\n",
    "    'clf__weights': ('distance',)\n",
    "    \n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(log_pipe,\n",
    "                        log_params,\n",
    "                        scoring='f1_micro',\n",
    "                        error_score=0,\n",
    "                        cv=kfolds,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(subset_train['clean_posts'], subset_train['type'])\n",
    "\n",
    "clf = clf_grid.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using Grid Search to find the best parameter tuning on Naive Bayes, Log Regression, and kNN, I found that Log Regression still provides the best scores. Second is Naive Bayes. Both the two classifiers did better with CountVectorizer rather than TfidfVectorizer. I believe this is the case because many documents are short and Tfidf could be too noisey for this specific problem. Interestingly, the kNN did better with TfidfVectorizer rather than CountVectorizer. \n",
    "\n",
    "In the process of creating these classifiers, I realized that using the full training corpus took way too long on my computer so I looked up different feature extraction and feature selection techniques for text processing. Although sampling just 10% of the full training set for training my classifier only decreased my performance on Naive Bayes classifier by about 1-3%. I found an interesting [study](http://www.surdeanu.info/mihai/teaching/ista555-spring15/readings/yang97comparative.pdf) on different feature selection methods. The study claimed that document frequency (DF) was a comparable feature selection tool to Chi^2 and Information Gain (IG) in text classification problems. Thus, I experimented with the `'min_df'` parameter in my vectorizer to see if it could improve my results. All results seem to be better without a DF threshold. I concluded that document frequency was not as good as term frequency in this particular scenario as I could not reproduce the results of the study. The study used large corpa of text whereas my current dataset was much smaller and some of the classes have very little data associated with them (refer to the graph of class distribution). \n",
    "\n",
    "I decided it was no longer necesssary for me to predict personality types of Kaggle users since I was unsuccessful at creating a classifier with better results than the forked kernel (however, I was able to improve the previous Naive Bayes classifier by about 6% through parameter tuning when trained on the full training set). My main objective in this project was to further my understand of NLP and classification problems as well as experimenting with the results of parameter tuning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
