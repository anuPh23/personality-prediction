{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f52726af-c202-451e-bf81-d4db266dc601",
    "_uuid": "f349ecc9323d6ae852a9e4fd9ef13d516d7ff381"
   },
   "source": [
    "## Summary\n",
    "I really liked this [kernel](https://www.kaggle.com/the1owl/classify-me-again). I think it is very creative and funny to create a model to predict personality from a text and to apply it over kaggle comments. This kernel is a variation of the indicated one where I calculate the accuracy of that model and try other model alternatives. At the end, we apply our best model to know what are the Kaggle community most common personalities, but don't take it too seriously :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1d634f3-8a15-49ca-b04c-3d2a78b9b59a",
    "_uuid": "4440861b925a1a1e60deca6614391070d55f01da",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56b7cee7-e051-48f3-81a9-1cae8992c275",
    "_uuid": "0090ee7b44d610b5b28d81c2c526543edf86af01",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../mbti-project/mbti_1.csv')\n",
    "us = pd.read_csv('../mbti-project/Users.csv')\n",
    "ps = pd.read_csv('../mbti-project/ForumMessages.csv')\n",
    "mbti = {'I':'Introversion', 'E':'Extroversion', 'N':'Intuition', \n",
    "        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling', \n",
    "        'J':'Judging', 'P': 'Perceiving'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ac9542c-9ea1-45f7-95f0-ce97ccf8d8ec",
    "_uuid": "91df29df60acc4c529ea35c9012a9f8484fffe92",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1d770298-0917-497d-91da-767d9a5f7431",
    "_uuid": "f0d2252b28928bedd661a5e5a0f513644b90380a"
   },
   "source": [
    "We take a look to the classes. It looks like it is a very unbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6d58e5ef-3cc3-434a-b4f8-84e7eac3db1e",
    "_uuid": "38496216d2bc92bd57160f96c971e8dcaa7ab288",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_srs = train['type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Types', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "beaa9d80-02d6-44c3-89e7-495eabe24690",
    "_uuid": "f8ed2ac97aa28198781e0fbd71f631b87e4b9618",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps['Message'] = ps['Message'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "75256a31-292e-4d24-af58-b83711daa6f5",
    "_uuid": "3bec49bca532eb74a978064493261b059c0ba82b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps_join = ps.groupby('AuthorUserId')['Message'].agg(lambda col: ' '.join(col)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2b05b1a6-13cf-4553-8e3d-476bfb387de3",
    "_uuid": "d6f0c056d85cf6d1d391cbf971d83d35d8fa8683"
   },
   "source": [
    "### ExtraTreesClassifier with SVD\n",
    "this is the model used in the  [kernel](https://www.kaggle.com/the1owl/classify-me-again). We want to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c45de79a-4c69-48a4-9ca3-ce0957c72c7c",
    "_uuid": "0a4e1fea557cb26515b536768d4c195e732dbe13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 20, max_depth=4, n_jobs = -1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "model = Pipeline([('tfidf1', tfidf), ('tsvd1', tsvd), ('etc', etc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "261fc1d2-204c-466e-bf69-819a0ccd9b8a",
    "_uuid": "da8ac5bbb30532e21dde6f8e427b68416fd6e0b4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7407ae0b-343b-42a0-a563-67a28435e0e1",
    "_uuid": "37fcf6b89d83901a8f1fb21753989196ffa49836",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss': 'neg_log_loss',\n",
    "           'f1_micro': 'f1_micro'}\n",
    "\n",
    "results = cross_validate(model, train['posts'], train['type'], cv=kfolds, \n",
    "                          scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c3bfdf28-5513-48d5-9836-a42c876285e5",
    "_uuid": "1900d1e53cb748996d1c750035fb2dc3c4fc0fb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results['test_acc']),\n",
    "                                                          np.std(results['test_acc'])))\n",
    "\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results['test_f1_micro']),\n",
    "                                                          np.std(results['test_f1_micro'])))\n",
    "\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ccb017bb-f95e-4450-aa88-e0c387eb00ab",
    "_uuid": "a87ad0739590a10dd24fbe74279076fcff86309e"
   },
   "source": [
    "As the dataset is very unbalanced F1 score is a better metric than accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ab8aa27-46f0-4590-9297-e5defc509bbf",
    "_uuid": "ec934b96fa4a2e98949250eadbeedaad0be2f774",
    "collapsed": true
   },
   "source": [
    "## Alternative models\n",
    "Let's try if we can find a more accuracy model, although we haven't got a lot of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "07980b64-22c1-4e4b-8c7c-6451d0492e35",
    "_uuid": "e72cf6748481b22bf1804cda91ebd1e34e22be67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8389d694-00a3-4e46-8d77-ef6a616988ca",
    "_uuid": "48dd4ff1d2d5546e8cda19baf5c02155cdb5f332",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['clean_posts'] = train['posts'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e204249b-a4c0-4ce2-a195-28f5bb8b4731",
    "_uuid": "92b9be0f1c3edaff08ec80ce9ce60a1d3e71692f"
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c3d7af4d-37b9-4715-9403-9ab465dd8a79",
    "_uuid": "37b9cebd34dbcf517313fca395e3f8067c4a3732",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "tfidf2 = CountVectorizer(ngram_range=(1, 1), \n",
    "                         stop_words='english',\n",
    "                         lowercase = True, \n",
    "                         max_features = 5000)\n",
    "\n",
    "model_nb = Pipeline([('tfidf1', tfidf2), ('nb', MultinomialNB())])\n",
    "\n",
    "results_nb = cross_validate(model_nb, train['clean_posts'], train['type'], cv=kfolds, \n",
    "                          scoring=scoring, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01878ba2-0403-4473-ba21-cb528e2c4030",
    "_uuid": "15254d05c861149f3332e27dd6f144a5126f0496",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_acc']),\n",
    "                                                          np.std(results_nb['test_acc'])))\n",
    "\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_f1_micro']),\n",
    "                                                          np.std(results_nb['test_f1_micro'])))\n",
    "\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_nb['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_nb['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f32ed58c-9484-47f3-bc21-65971542c4e1",
    "_uuid": "057e6abfea2ac10f2883c80a59e2ba8e1211c9bb"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89638742-3b92-4246-b02f-f1daa3ea537b",
    "_uuid": "0bb63efb6763d61b3cc7d3107b8ee88f0c2cd0ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "tfidf2 = CountVectorizer(ngram_range=(1, 1), stop_words='english',\n",
    "                                                 lowercase = True, max_features = 5000)\n",
    "\n",
    "model_lr = Pipeline([('tfidf1', tfidf2), ('lr', LogisticRegression(class_weight=\"balanced\", C=0.005))])\n",
    "\n",
    "results_lr = cross_validate(model_lr, train['clean_posts'], train['type'], cv=kfolds, \n",
    "                          scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "12cc90b3-5132-4e30-9fd0-498252525237",
    "_uuid": "b14744889e1d4d14594f27c57e3a4c33d47b445d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_acc']),\n",
    "                                                          np.std(results_lr['test_acc'])))\n",
    "\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_f1_micro']),\n",
    "                                                          np.std(results_lr['test_f1_micro'])))\n",
    "\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e54e11e9-b7bf-4c2b-9488-f196b89d71ed",
    "_uuid": "92ea4a3bc6b3d40576a63111e76b19e19082f959",
    "collapsed": true
   },
   "source": [
    "Is this model overtitting? could we have a better model with more data? Let's see the learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37ba98a5-7653-4014-8798-94a22a1cf3cd",
    "_uuid": "29b7985e4ded72f0a88df4f783d995c5a4b4d4ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = \\\n",
    "    learning_curve(model_lr, train['clean_posts'], train['type'], cv=kfolds, n_jobs=-1, \n",
    "                   scoring=\"f1_micro\", train_sizes=np.linspace(.1, 1.0, 10), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "30f1955b-db37-44c8-b98d-f5d4aeca36b3",
    "_uuid": "d475b6a10c2b6adafc56bceeddd125ff22fc89af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(X, y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c0769c1-1292-432e-8fd2-386afb28e353",
    "_uuid": "2171c7e33f3dbb68fa80afd6376c606e78c8ded8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_learning_curve(train['posts'], train['type'], train_sizes, \n",
    "                    train_scores, test_scores, ylim=(0.1, 1.01), figsize=(14,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f650510-c0d8-45c1-9add-72f562b5ba74",
    "_uuid": "713f37af2cbab4b4d48822f1fb25c938ea4d4d85"
   },
   "source": [
    "It looks like that with more data the model gets better and that it is not overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3da668d-f47f-4119-9cc9-7c2d2569c7b5",
    "_uuid": "6f28e921316e6b43bb437f8f666e14cff3f44ac4"
   },
   "source": [
    "## Kaggle users personality\n",
    "Let's apply our last model to whole kaggle users comments. Let's see what is the most common kaggle user personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "30c525f0-d92f-4789-8a3d-c502379c3e80",
    "_uuid": "969492e6e25f62e0c56b4d32faa8b78e889ade00",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps_join['clean_comments'] = ps_join['Message'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54bd1804-1d39-4917-81db-eebdbee4c198",
    "_uuid": "4f8580366f7367f92b23a774ada6ab796c61a169",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr.fit(train['clean_posts'], train['type'])\n",
    "pred_all = model_lr.predict(ps_join['clean_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d3c3cc67-f9a1-401c-b1ce-01109c78ce6a",
    "_uuid": "b6bc9d7007dc45196b418227755b6abe092418ac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_all = np.unique(pred_all, return_counts=True)\n",
    "\n",
    "pred_df = pd.DataFrame({'personality': cnt_all[0], 'count': cnt_all[1]},\n",
    "                      columns=['personality', 'count'], index=None)\n",
    "\n",
    "pred_df.sort_values('count', ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(pred_df['personality'], pred_df['count'], alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Personality', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "50de1627-13bd-48b4-8e4c-8e0e4edf7f4c",
    "_uuid": "429daf8d9d16ac54971cdcff1d2bfed1cd6f488d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['percent'] = pred_df['count']/pred_df['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "955de0ce-5ae5-4398-bb5c-43e8ee507b96",
    "_uuid": "3343c05412f2c53e73aca7e1aeb3e834f282d2d4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['description'] = pred_df['personality'].apply(lambda x: ' '.join([mbti[l] for l in list(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b987ed57-b032-4df5-a08e-b8524fa5c6cb",
    "_uuid": "1f7297123451d95c0ff43ba75100bc8da2d2c4e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "827373d4-d0d7-46cd-b8bd-07ee45f59afe",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "06f6ffb586a079e0c98584bca53a0c53266f6383",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pred_df['description']\n",
    "sizes = pred_df['percent']*100\n",
    "\n",
    "trace = go.Pie(labels=labels, values=sizes)\n",
    "layout = go.Layout(\n",
    "    title='Kaggle Personality Distribution'\n",
    ")\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9acc2f66-3e27-4c7d-9838-3832dafba930",
    "_uuid": "744341e313d4b5f5e4b9f7a194523028079f113b"
   },
   "source": [
    "## Conclusions\n",
    "Apparently the most common Kaggle users personality is ESFP (Extroversion Sensing Feeling Perceiving), but we are getting this conclusion based on users comments: it is reasonable to think that users who participate more writting comments are more extrovert. Our sample data don't came from all Kaggle user population, it comes from Kaggle users who write comments so, our conclusion can't be applied to all Kaggle users, only to those who write comments. Farthermore, more accuracy models could be obtained with more data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
